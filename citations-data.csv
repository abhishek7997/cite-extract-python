citation,citation_text,adj,pos_adj,neg_adj
Abbasi (2010),Abbasi (2010) proposed that feature selection methods should be tailored to sentiment analysis by combining syntactic properties of text features with sentiment-related semantic information.,"['syntactic', 'semantic', 'sentimentrelated']","(0, [])","(0, [])"
"Abbasi et al., 2008","Despite the low computational cost of the Na ve Bayes technique, it has not been competitive in terms of classi cation accuracy when compared to SVM (Abbasi et al., 2008; Pang et al., 2002) and therefore we only analyze the NB method comparatively in the context of our experimental results.","['computational', 'low', 'competitive', 'experimental']","(1, ['competitive'])","(0, [])"
"Abbasi et al., 2011","Usual feature selection methods are document frequency (Bai, 2011; Dang et al., 2010; Pang et al., 2002), mutual information (Li et al., 2009; Turney, 2002), information gain (Abbasi et al., 2011, 2008; Li et al., 2009; Riloff, Patwardhan, & Wiebe, 2006) and chi-square (Abbasi et al., 2011; Li et al., 2009). None of them has been widely accepted as the best feature selection method for sentiment classi cation or text categorization, however, information gain has often been competitive (Abbasi et al., 2011; Forman, 2003; Li et al., 2009; Xia & Zong, 2010; Yang & Pedersen, 1997). In summary, although reducing input features is critical to make the ANN training process practical, it does not represent a disadvantage in comparison to SVM, since SVM also bene ts from the feature selection (Abbasi et al., 2011, 2008; Dang et al., 2010; Li et al., 2009), especially in the context of large-scale sentiment classi cation tasks (Bespalov et al., 2011).","['forman', 'critical', 'largescale', 'ann', 'usual', 'mutual', 'chisquare', 'best', 'turney', 'competitive', 'document']","(2, ['best', 'competitive'])","(1, ['critical'])"
"Abbasi, 2010","The most popular sentiment learning techniques are SVM and NB, and many authors have reported better accuracy by using SVM (Abbasi, 2010; Dang et al., 2010; O Keefe & Koprinska, 2009; Pang et al., 2002; Prabowo & Thelwall, 2009; Ye, Zhang, & Law, 2009).","['popular', 'many', 'svm']","(1, ['popular'])","(0, [])"
"Abbasi, Chen, & Salem, 2008","In general, techniques in the literature can be differed in terms of the adopted approach for feature selection, since most of them agree on the learning techniques: Support Vector Machine (SVM) and Na ve Bayes (NB) (Abbasi, Chen, & Salem, 2008; Tang, Tan, & Cheng, 2009; Tsytsarau & Palpanas, 2012).","['techniques', 'adopted', 'most']","(0, [])","(0, [])"
"Abbasi, France, Zhang, & Chen, 2011","Basically, most of the methods in the literature are composed of two parts: (i) feature selection and (ii) sentiment learning/ classi cation (Abbasi, France, Zhang, & Chen, 2011; Chen, Liu, & Chiu, 2011; Li, Xia, Zong, & Huang, 2009; Pang et al., 2002).",['most'],"(0, [])","(0, [])"
"Alpaydin, 2004","In order to evaluate how different is the accuracy between SVM and ANN classi ers, we applied the t student test with 5% of signi cance (Alpaydin, 2004).","['signi', 'ann', 'different']","(0, [])","(0, [])"
"Atakulreka & Sutivong, 2007","Repeated training with random starting weights is a popular method to overcome the convergence problem (Atakulreka & Sutivong, 2007).",['popular'],"(1, ['popular'])","(0, [])"
"Baccianella & Sebastiani, 2010","Semantic information is computed by assigning weight to features according to their (i) occurrence distributions across categories in the training data and (ii) degree of subjectivity, which is derived from SentiWordNet (Baccianella & Sebastiani, 2010), a publicly available lexical resource that contains sentiment polarity scores.","['sentiment', 'semantic', 'available', 'lexical']","(1, ['available'])","(0, [])"
"Bai, 2011","Usual feature selection methods are document frequency (Bai, 2011; Dang et al., 2010; Pang et al., 2002), mutual information (Li et al., 2009; Turney, 2002), information gain (Abbasi et al., 2011, 2008; Li et al., 2009; Riloff, Patwardhan, & Wiebe, 2006) and chi-square (Abbasi et al., 2011; Li et al., 2009).","['usual', 'mutual', 'chisquare', 'turney', 'document']","(0, [])","(0, [])"
"Berry & Kogan, 2010","It ranks terms by considering their presence and absence in each class (Berry & Kogan, 2010).",[],"(0, [])","(0, [])"
"Bespalov et al., 2011","In summary, although reducing input features is critical to make the ANN training process practical, it does not represent a disadvantage in comparison to SVM, since SVM also bene ts from the feature selection (Abbasi et al., 2011, 2008; Dang et al., 2010; Li et al., 2009), especially in the context of large-scale sentiment classi cation tasks (Bespalov et al., 2011).","['critical', 'ann', 'summary', 'largescale']","(0, [])","(1, ['critical'])"
"Bespalov, Bai, Qi, & Shokoufandeh, 2011","ANN and sentiment classi cation ANN has gured rarely in the literature (Bespalov, Bai, Qi, & Shokoufandeh, 2011; Chen et al., 2011; Claster, Hung, & Shanmuganathan, 2010; Zhu, XU, & shi Wang, 2010), as can be seen in recent surveys on sentiment analysis (Pang & Lee, 2008; Tsytsarau & Palpanas, 2012).",['recent'],"(0, [])","(0, [])"
"Bishop, 2007","In order to accelerate the training process and reduce the risk of over tting, we adopted the early stopping procedure (Bishop, 2007).",['early'],"(0, [])","(0, [])"
Burges (1998),"A detailed discussion covering parameter values and their implications are beyond the scope of our work and can be found in Ben-Hur and Weston (2010), Burges (1998), Hastie et al.","['hastie', 'detailed']","(0, [])","(0, [])"
"Burges, 1998","However, it is important to note that a large set of support vectors can be needed to form the output function, making SVM computationally slow in running time (test phase) and expensive for real-time applications (Burges, 1998; Romero & Toppo, 2007).","['svm', 'realtime', 'large', 'important', 'expensive', 'slow']","(1, ['important'])","(2, ['expensive', 'slow'])"
"Burns et al., 2011","In order to approach realistic conditions of unbalanced data, we vary only the number of negative reviews in a training dataset, since in practice the number of positive reviews is substantially greater than the number of negative reviews (Burns et al., 2011; Glorot, Bordes, & Bengio, 2011).","['positive', 'unbalanced', 'negative', 'greater', 'realistic']","(2, ['positive', 'realistic'])","(1, ['negative'])"
"Burns, Bi, Wang, & Anderson, 2011","Another characteristic of the sentiment classi cation literature is that many methods have been tested only on balanced datasets and there has been little discussion on the effects of learning subjective aspects from unbalanced data, although it is typical of the product domain to have substantially more positive than negative reviews (Burns, Bi, Wang, & Anderson, 2011; Li, Wang, Zhou, & Lee, 2011a).","['typical', 'positive', 'many', 'subjective', 'unbalanced', 'negative', 'little']","(1, ['positive'])","(1, ['negative'])"
"Chang & Lin, 2011","We train the SVM classi er with an usual nonlinear kernel (radial basis function) using LIBSVM software package (Chang & Lin, 2011).","['libsvm', 'usual', 'nonlinear', 'radial']","(0, [])","(0, [])"
"Chen et al., 2011","ANN and sentiment classi cation ANN has gured rarely in the literature (Bespalov, Bai, Qi, & Shokoufandeh, 2011; Chen et al., 2011; Claster, Hung, & Shanmuganathan, 2010; Zhu, XU, & shi Wang, 2010), as can be seen in recent surveys on sentiment analysis (Pang & Lee, 2008; Tsytsarau & Palpanas, 2012).",['recent'],"(0, [])","(0, [])"
"Chen, Liu, & Chiu, 2011","Basically, most of the methods in the literature are composed of two parts: (i) feature selection and (ii) sentiment learning/ classi cation (Abbasi, France, Zhang, & Chen, 2011; Chen, Liu, & Chiu, 2011; Li, Xia, Zong, & Huang, 2009; Pang et al., 2002).",['most'],"(0, [])","(0, [])"
"Claster, Hung, & Shanmuganathan, 2010","ANN and sentiment classi cation ANN has gured rarely in the literature (Bespalov, Bai, Qi, & Shokoufandeh, 2011; Chen et al., 2011; Claster, Hung, & Shanmuganathan, 2010; Zhu, XU, & shi Wang, 2010), as can be seen in recent surveys on sentiment analysis (Pang & Lee, 2008; Tsytsarau & Palpanas, 2012).",['recent'],"(0, [])","(0, [])"
"Dang et al., 2010","The most popular sentiment learning techniques are SVM and NB, and many authors have reported better accuracy by using SVM (Abbasi, 2010; Dang et al., 2010; O Keefe & Koprinska, 2009; Pang et al., 2002; Prabowo & Thelwall, 2009; Ye, Zhang, & Law, 2009). Usual feature selection methods are document frequency (Bai, 2011; Dang et al., 2010; Pang et al., 2002), mutual information (Li et al., 2009; Turney, 2002), information gain (Abbasi et al., 2011, 2008; Li et al., 2009; Riloff, Patwardhan, & Wiebe, 2006) and chi-square (Abbasi et al., 2011; Li et al., 2009). In summary, although reducing input features is critical to make the ANN training process practical, it does not represent a disadvantage in comparison to SVM, since SVM also bene ts from the feature selection (Abbasi et al., 2011, 2008; Dang et al., 2010; Li et al., 2009), especially in the context of large-scale sentiment classi cation tasks (Bespalov et al., 2011).","['critical', 'many', 'popular', 'ann', 'usual', 'largescale', 'mutual', 'chisquare', 'svm', 'turney', 'document']","(1, ['popular'])","(1, ['critical'])"
"Dang, Zhang, and Chen (2010)","Dang, Zhang, and Chen (2010) also used various categories of features, which were re ned by applying the Information Gain (IG) technique (Yang & Pedersen, 1997).",['various'],"(0, [])","(0, [])"
"Fodslette & Mnller, 1993","Although the scaled conjugate gradient method (Fodslette & Mnller, 1993) focus on accelerating the process of convergence, the reported results showed that the method failed to converge less often than traditional conjugate gradient or back-propagation using gradient descent. Instead of adopting the traditional gradient descent method, we use the scaled conjugated gradient to speed up the convergence to a solution (Fodslette & Mnller, 1993), as implemented in the Matlab software.","['conjugate', 'scaled', 'gradient', 'traditional']","(0, [])","(0, [])"
"Forman, 2003","None of them has been widely accepted as the best feature selection method for sentiment classi cation or text categorization, however, information gain has often been competitive (Abbasi et al., 2011; Forman, 2003; Li et al., 2009; Xia & Zong, 2010; Yang & Pedersen, 1997).","['competitive', 'forman', 'best']","(2, ['competitive', 'best'])","(0, [])"
"Gabrilovich & Markovitch, 2004","On text categorization, some authors (Gabrilovich & Markovitch, 2004; Taira & Haruno, 1999) have recommended a SVM training process with all available features.","['available', 'svm']","(1, ['available'])","(0, [])"
"Glorot, Bordes, & Bengio, 2011","In order to approach realistic conditions of unbalanced data, we vary only the number of negative reviews in a training dataset, since in practice the number of positive reviews is substantially greater than the number of negative reviews (Burns et al., 2011; Glorot, Bordes, & Bengio, 2011).","['positive', 'unbalanced', 'negative', 'greater', 'realistic']","(2, ['positive', 'realistic'])","(1, ['negative'])"
"Hastie et al., 2001","Arti cial Neural Networks The central idea of a neural network is to derive features from linear combinations of the input data, and then model the output as a nonlinear function of these features (Hastie et al., 2001). Nodes are arranged in layers and the structure of the most used neural network consists of three layers: an input, a hidden and an output layer of nodes (Hastie et al., 2001). (4) From the SVM point of view M Number of support vectors h fxkgM fkkgM k 1 k 1 Kernel function Support vectors Coef cients found by the convex optimization problem From the ANN point of view Number of nodes in the hidden layer Activation function Hidden layer weights Output layer weights methods, which may not converge to the optimal/global solution (Hastie et al., 2001; Haykin, 1998).","['optimalglobal', 'fxkgm', 'nonlinear', 'used', 'ann', 'central', 'arti', 'svm', 'hidden', 'neural', 'derive', 'linear', 'cial']","(0, [])","(0, [])"
"Hastie, Tibshirani, & Friedman, 2001","As a supervised classi cation approach, SVM seeks to maximize the distance to the closest training point from either class in order to achieve better generalization/classication performance on test data (Hastie, Tibshirani, & Friedman, 2001).","['supervised', 'closest', 'better', 'svm']","(1, ['better'])","(0, [])"
"Hatzivassiloglou & McKeown, 1997","Nowadays, many people make their opinions available on the internet and researchers have been proposing methods to automate the task of classifying these textual reviews/opinions as positive or negative (Hatzivassiloglou & McKeown, 1997; Pang, Lee, & Vaithyanathan, 2002; Pang & Lee, 2008; Turney, 2002).","['positive', 'many', 'textual', 'negative', 'available']","(2, ['positive', 'available'])","(1, ['negative'])"
"Haykin, 1998","It makes possible to determine a nonlinear decision boundary, which is linear in the higher-dimensional feature space, without computing the parameters of the optimal hyperplane in a feature space of possibly high dimensionality (Haykin, 1998). Each connection has an associated weight, whose value is estimated by minimizing a global error function in a gradient descent training process (Haykin, 1998). Fundamental comparison between SVM and ANN Formally, SVM and feed-forward neural networks are structurally similar, since both of them induce an output function which is expressed as a linear combination of simple functions (Romero & Toppo, 2007): f x b M X kkh xk; x : k 1 4 The bias term b is common for both SVM and ANN (Haykin, 1998) and Table 1 explains the meaning of the remaining terms from both SVM and ANN points of view. Although the de nition of an appropriate number M of hidden nodes in designing of a neural network is not a trivial task, the model complexity is usually controlled by keeping the number of hidden nodes small (Haykin, 1998). (4) From the SVM point of view M Number of support vectors h fxkgM fkkgM k 1 k 1 Kernel function Support vectors Coef cients found by the convex optimization problem From the ANN point of view Number of nodes in the hidden layer Activation function Hidden layer weights Output layer weights methods, which may not converge to the optimal/global solution (Hastie et al., 2001; Haykin, 1998).","['nonlinear', 'high', 'possible', 'table', 'common', 'feedforward', 'bias', 'higherdimensional', 'svm', 'small', 'fxkgm', 'trivial', 'gradient', 'similar', 'hidden', 'linear', 'simple', 'optimalglobal', 'feature', 'appropriate', 'global', 'ann', 'optimal', 'neural', 'fundamental']","(2, ['appropriate', 'optimal'])","(2, ['bias', 'trivial'])"
"He et al., 2011","Second, the maximum entropy (ME) classi cation method (He et al., 2011) has shown promising results in sentiment analysis and therefore we intend to involve ME in our comparative study.","['comparative', 'promising', 'sentiment', 'maximum']","(1, ['promising'])","(0, [])"
"Huang, Kecman, & Kopriva, 2006","Usually, this transformation is achieved by using a kernel function h (Huang, Kecman, & Kopriva, 2006).",[],"(0, [])","(0, [])"
"Joachims, 1998","Our results indicated that IG (i) makes the ANN training practical in a bag-of-words approach and (ii) contribute to reduce the running time of SVM, although the complexity of the SVM solution does not necessarily depend on the number of features (Joachims, 1998; Suykens, Vandewalle, & Moor, 2001).","['running', 'ann', 'practical', 'svm', 'bagofwords']","(0, [])","(0, [])"
"Keefe & Koprinska, 2009","The most popular sentiment learning techniques are SVM and NB, and many authors have reported better accuracy by using SVM (Abbasi, 2010; Dang et al., 2010; O Keefe & Koprinska, 2009; Pang et al., 2002; Prabowo & Thelwall, 2009; Ye, Zhang, & Law, 2009).","['popular', 'many', 'svm']","(1, ['popular'])","(0, [])"
Keefe and Koprinska (2009),O Keefe and Koprinska (2009) also evaluated feature selection techniques as well as feature weighting methods.,['feature'],"(0, [])","(0, [])"
"Kok, & Brazdil, 2007","Thus, although Cristianini and Shawe-Taylor (2000) mentioned that in practice SVM frequently results in very few support vectors, our results are consistent with previous results on text categorization (Colas, Pacl k, Kok, & Brazdil, 2007) in reporting a high number of support vectors.","['high', 'consistent', 'previous', 'text', 'few']","(1, ['consistent'])","(0, [])"
"Li et al., 2009","The number of times a term occurs in a document (i.e., term frequency) is also used as a weighting scheme for textual data (Li et al., 2009; Paltoglou & Thelwall, 2010). Usual feature selection methods are document frequency (Bai, 2011; Dang et al., 2010; Pang et al., 2002), mutual information (Li et al., 2009; Turney, 2002), information gain (Abbasi et al., 2011, 2008; Li et al., 2009; Riloff, Patwardhan, & Wiebe, 2006) and chi-square (Abbasi et al., 2011; Li et al., 2009). None of them has been widely accepted as the best feature selection method for sentiment classi cation or text categorization, however, information gain has often been competitive (Abbasi et al., 2011; Forman, 2003; Li et al., 2009; Xia & Zong, 2010; Yang & Pedersen, 1997). In summary, although reducing input features is critical to make the ANN training process practical, it does not represent a disadvantage in comparison to SVM, since SVM also bene ts from the feature selection (Abbasi et al., 2011, 2008; Dang et al., 2010; Li et al., 2009), especially in the context of large-scale sentiment classi cation tasks (Bespalov et al., 2011).","['forman', 'critical', 'largescale', 'ann', 'usual', 'mutual', 'textual', 'chisquare', 'best', 'turney', 'competitive', 'document']","(2, ['best', 'competitive'])","(1, ['critical'])"
"Li, Wang, Zhou, & Lee, 2011","Another characteristic of the sentiment classi cation literature is that many methods have been tested only on balanced datasets and there has been little discussion on the effects of learning subjective aspects from unbalanced data, although it is typical of the product domain to have substantially more positive than negative reviews (Burns, Bi, Wang, & Anderson, 2011; Li, Wang, Zhou, & Lee, 2011a).","['typical', 'positive', 'many', 'subjective', 'unbalanced', 'negative', 'little']","(1, ['positive'])","(1, ['negative'])"
"Li, Xia, Zong, & Huang, 2009","Basically, most of the methods in the literature are composed of two parts: (i) feature selection and (ii) sentiment learning/ classi cation (Abbasi, France, Zhang, & Chen, 2011; Chen, Liu, & Chiu, 2011; Li, Xia, Zong, & Huang, 2009; Pang et al., 2002).",['most'],"(0, [])","(0, [])"
"Lin & He, 2009","Document-level sentiment classi cation Although some approaches have proposed using unsupervised/ semi-supervised learning methods (Lin & He, 2009; Turney, 2002), most of the work has focused on supervised learning techniques.","['documentlevel', 'supervised', 'unsupervised', 'semisupervised', 'most']","(0, [])","(0, [])"
"Liu, 2011","In this paper, we compare popular machine learning approaches (SVM and NB) with an ANN-based method in the context of document-level sentiment classi cation (Liu, 2011). Many researchers have reported that SVM is perhaps the most accurate method for text classi cation (Liu, 2011).","['accurate', 'many', 'documentlevel', 'popular', 'annbased', 'text']","(2, ['accurate', 'popular'])","(0, [])"
"Lovins, 1968","Popular stemmer algorithms for the english language are Snowball (Porter, 2001), Porter (Porter, 1980) and Lovins (Lovins, 1968).","['popular', 'snowball', 'english', 'porter']","(1, ['popular'])","(0, [])"
"Manning et al., 2008","The classic TF-IDFt,d (Manning et al., 2008) assigns to term t a weight in document d as TF (cid:2) IDFt;d TFt;d (cid:3) IDFt; where IDFt log N DFt : 1 TFt,d is the number of occurrences of term t in document d, N is the number of documents in the collection and DFt is the number of documents in the collection that contain term t. Essentially, TFIDF avoids assigning high scores to terms that occur too often in the dataset.","['classic', 'tfidf', 'tfidftd', 'high']","(1, ['classic'])","(0, [])"
"Manning, Raghavan, & Schtze, 2008","We are primarily interested in investigating the potential of an ANN-based approach for document-level sentiment classi cation and therefore we adopted classic supervised methods for feature selection and weighting in a traditional bag-of-words model (Manning, Raghavan, & Schtze, 2008).","['classic', 'documentlevel', 'interested', 'supervised', 'annbased', 'traditional']","(1, ['classic'])","(0, [])"
"Paltoglou & Thelwall, 2010","The number of times a term occurs in a document (i.e., term frequency) is also used as a weighting scheme for textual data (Li et al., 2009; Paltoglou & Thelwall, 2010).",['textual'],"(0, [])","(0, [])"
"Pang & Lee, 2004","In comparison with the sentiment classi cation literature, the main contributions of our work are: (i) a comparison of a dominant and a computationally ef cient approach (SVM and NB, respectively) with an ANN-based approach under the same context; (ii) a comparison involving realistic contexts in which the ratio of positive and negative reviews is unbalanced; (iii) a performance evaluation of ANN on a full version of the benchmark dataset of Movies reviews (Pang & Lee, 2004). Some datasets are available and have been used by many researchers in order to compare results, and the dataset of movie reviews (Pang & Lee, 2004) is the most popular benchmark dataset in the literature.1 Since the focus of our study is on the overall opinion (positive or negative) expressed in a review, we have oriented our literature review towards document-level sentiment classi cation, which assumes that a review document expresses opinions on a single product or service and was written by a single reviewer/customer. Datasets We conducted experiments on four datasets, which are the benchmark Movies review dataset (Pang & Lee, 2004) and collections of reviews extracted from amazon.com in distinct product domains: GPS, Books and Cameras. Regarding the sentiment learning literature, our main ndings/contributions are in the following points: (cid:4) In terms of classi cation accuracy on the benchmark dataset of Movies reviews (Pang & Lee, 2004), ANN outperformed signi cantly (statistically) SVM, specially in the context of unbalanced data.","['many', 'single', 'annbased', 'literature', 'realistic', 'overall', 'popular', 'following', 'distinct', 'positive', 'main', 'unbalanced', 'negative', 'available', 'documentlevel', 'signi', 'dominant', 'same', 'full']","(4, ['realistic', 'popular', 'positive', 'available'])","(1, ['negative'])"
"Pang & Lee, 2008","Nowadays, many people make their opinions available on the internet and researchers have been proposing methods to automate the task of classifying these textual reviews/opinions as positive or negative (Hatzivassiloglou & McKeown, 1997; Pang, Lee, & Vaithyanathan, 2002; Pang & Lee, 2008; Turney, 2002). ANN and sentiment classi cation ANN has gured rarely in the literature (Bespalov, Bai, Qi, & Shokoufandeh, 2011; Chen et al., 2011; Claster, Hung, & Shanmuganathan, 2010; Zhu, XU, & shi Wang, 2010), as can be seen in recent surveys on sentiment analysis (Pang & Lee, 2008; Tsytsarau & Palpanas, 2012).","['positive', 'many', 'textual', 'negative', 'recent', 'available']","(2, ['positive', 'available'])","(1, ['negative'])"
"Pang et al., 2002","Basically, most of the methods in the literature are composed of two parts: (i) feature selection and (ii) sentiment learning/ classi cation (Abbasi, France, Zhang, & Chen, 2011; Chen, Liu, & Chiu, 2011; Li, Xia, Zong, & Huang, 2009; Pang et al., 2002). The most popular sentiment learning techniques are SVM and NB, and many authors have reported better accuracy by using SVM (Abbasi, 2010; Dang et al., 2010; O Keefe & Koprinska, 2009; Pang et al., 2002; Prabowo & Thelwall, 2009; Ye, Zhang, & Law, 2009). Usual feature selection methods are document frequency (Bai, 2011; Dang et al., 2010; Pang et al., 2002), mutual information (Li et al., 2009; Turney, 2002), information gain (Abbasi et al., 2011, 2008; Li et al., 2009; Riloff, Patwardhan, & Wiebe, 2006) and chi-square (Abbasi et al., 2011; Li et al., 2009). Despite the low computational cost of the Na ve Bayes technique, it has not been competitive in terms of classi cation accuracy when compared to SVM (Abbasi et al., 2008; Pang et al., 2002) and therefore we only analyze the NB method comparatively in the context of our experimental results.","['computational', 'experimental', 'many', 'popular', 'usual', 'mutual', 'chisquare', 'svm', 'low', 'turney', 'most', 'competitive', 'document']","(2, ['popular', 'competitive'])","(0, [])"
"Pang, Lee, & Vaithyanathan, 2002","Nowadays, many people make their opinions available on the internet and researchers have been proposing methods to automate the task of classifying these textual reviews/opinions as positive or negative (Hatzivassiloglou & McKeown, 1997; Pang, Lee, & Vaithyanathan, 2002; Pang & Lee, 2008; Turney, 2002).","['positive', 'many', 'textual', 'negative', 'available']","(2, ['positive', 'available'])","(1, ['negative'])"
"Porter, 1980","Popular stemmer algorithms for the english language are Snowball (Porter, 2001), Porter (Porter, 1980) and Lovins (Lovins, 1968).","['popular', 'snowball', 'english', 'porter']","(1, ['popular'])","(0, [])"
"Porter, 2001","Popular stemmer algorithms for the english language are Snowball (Porter, 2001), Porter (Porter, 1980) and Lovins (Lovins, 1968). The preprocessing of the datasets consisted of removing stopwords and stemming by applying the Snowball stemmer (Porter, 2001), resulting in the vocabulary sizes described in Table 2.","['table', 'popular', 'english', 'vocabulary', 'snowball', 'porter']","(1, ['popular'])","(0, [])"
"Prabowo & Thelwall, 2009","The most popular sentiment learning techniques are SVM and NB, and many authors have reported better accuracy by using SVM (Abbasi, 2010; Dang et al., 2010; O Keefe & Koprinska, 2009; Pang et al., 2002; Prabowo & Thelwall, 2009; Ye, Zhang, & Law, 2009).","['popular', 'many', 'svm']","(1, ['popular'])","(0, [])"
"Recently, He, Lin, and Alani (2011)","Recently, He, Lin, and Alani (2011) proposed to detect sentiment and topic simultaneously from text and show that a state-of-the-art performance can be achieved by augmenting features with polarity word labels.","['stateoftheart', 'alani']","(0, [])","(0, [])"
"Riloff, Patwardhan, & Wiebe, 2006","Usual feature selection methods are document frequency (Bai, 2011; Dang et al., 2010; Pang et al., 2002), mutual information (Li et al., 2009; Turney, 2002), information gain (Abbasi et al., 2011, 2008; Li et al., 2009; Riloff, Patwardhan, & Wiebe, 2006) and chi-square (Abbasi et al., 2011; Li et al., 2009).","['usual', 'mutual', 'chisquare', 'turney', 'document']","(0, [])","(0, [])"
"Romero & Toppo, 2007","Fundamental comparison between SVM and ANN Formally, SVM and feed-forward neural networks are structurally similar, since both of them induce an output function which is expressed as a linear combination of simple functions (Romero & Toppo, 2007): f x b M X kkh xk; x : k 1 4 The bias term b is common for both SVM and ANN (Haykin, 1998) and Table 1 explains the meaning of the remaining terms from both SVM and ANN points of view. This property does not usually hold for ANN (Romero & Toppo, 2007) and the number M of hidden nodes in a neural network is a free parameter which is usually xed previously. However, it is important to note that a large set of support vectors can be needed to form the output function, making SVM computationally slow in running time (test phase) and expensive for real-time applications (Burges, 1998; Romero & Toppo, 2007).","['free', 'table', 'common', 'slow', 'xed', 'feedforward', 'bias', 'expensive', 'svm', 'realtime', 'similar', 'large', 'important', 'hidden', 'linear', 'simple', 'ann', 'neural', 'fundamental']","(2, ['free', 'important'])","(3, ['slow', 'bias', 'expensive'])"
"Russell et al., 2010","First, the neuron computes a weighted sum of its inputs and then applies an activation function to this sum to derive its output (Russell et al., 2010).",['weighted'],"(0, [])","(0, [])"
"Russell, Norvig, & Davis, 2010","The result is one of the most popular and effective forms of learning system (Russell, Norvig, & Davis, 2010).","['popular', 'effective']","(2, ['popular', 'effective'])","(0, [])"
"Suykens, Vandewalle, & Moor, 2001","Our results indicated that IG (i) makes the ANN training practical in a bag-of-words approach and (ii) contribute to reduce the running time of SVM, although the complexity of the SVM solution does not necessarily depend on the number of features (Joachims, 1998; Suykens, Vandewalle, & Moor, 2001).","['running', 'ann', 'practical', 'svm', 'bagofwords']","(0, [])","(0, [])"
"Taira & Haruno, 1999","On text categorization, some authors (Gabrilovich & Markovitch, 2004; Taira & Haruno, 1999) have recommended a SVM training process with all available features.","['available', 'svm']","(1, ['available'])","(0, [])"
"Tang, Tan, & Cheng, 2009","In general, techniques in the literature can be differed in terms of the adopted approach for feature selection, since most of them agree on the learning techniques: Support Vector Machine (SVM) and Na ve Bayes (NB) (Abbasi, Chen, & Salem, 2008; Tang, Tan, & Cheng, 2009; Tsytsarau & Palpanas, 2012).","['techniques', 'adopted', 'most']","(0, [])","(0, [])"
"Tsytsarau & Palpanas, 2012","In general, techniques in the literature can be differed in terms of the adopted approach for feature selection, since most of them agree on the learning techniques: Support Vector Machine (SVM) and Na ve Bayes (NB) (Abbasi, Chen, & Salem, 2008; Tang, Tan, & Cheng, 2009; Tsytsarau & Palpanas, 2012). ANN and sentiment classi cation ANN has gured rarely in the literature (Bespalov, Bai, Qi, & Shokoufandeh, 2011; Chen et al., 2011; Claster, Hung, & Shanmuganathan, 2010; Zhu, XU, & shi Wang, 2010), as can be seen in recent surveys on sentiment analysis (Pang & Lee, 2008; Tsytsarau & Palpanas, 2012). It is also widely used in sentiment classi cation (Tsytsarau & Palpanas, 2012).","['techniques', 'adopted', 'recent', 'most']","(0, [])","(0, [])"
"Turney, 2002","Nowadays, many people make their opinions available on the internet and researchers have been proposing methods to automate the task of classifying these textual reviews/opinions as positive or negative (Hatzivassiloglou & McKeown, 1997; Pang, Lee, & Vaithyanathan, 2002; Pang & Lee, 2008; Turney, 2002). Document-level sentiment classi cation Although some approaches have proposed using unsupervised/ semi-supervised learning methods (Lin & He, 2009; Turney, 2002), most of the work has focused on supervised learning techniques. Usual feature selection methods are document frequency (Bai, 2011; Dang et al., 2010; Pang et al., 2002), mutual information (Li et al., 2009; Turney, 2002), information gain (Abbasi et al., 2011, 2008; Li et al., 2009; Riloff, Patwardhan, & Wiebe, 2006) and chi-square (Abbasi et al., 2011; Li et al., 2009).","['techniques', 'positive', 'many', 'documentlevel', 'supervised', 'unsupervised', 'usual', 'mutual', 'textual', 'chisquare', 'negative', 'semisupervised', 'turney', 'most', 'available', 'document']","(2, ['positive', 'available'])","(1, ['negative'])"
"Van Hulse, Khoshgoftaar, & Napolitano, 2007","In contrast to those approaches that discuss imbalanced sentiment classi cation, we evaluate the performance of ANN as the learning approach and report results in a context in which no previous stages are considered to deal with imbalanced data, like sampling techniques (Van Hulse, Khoshgoftaar, & Napolitano, 2007).","['previous', 'imbalanced']","(0, [])","(0, [])"
"Weiss, Indurkhya, & Zhang, 2004","Pre-processing techniques are often used to remove stopwords, which are common terms like prepositions and articles, and reduce term variations to a single representation by applying stemming procedures (Weiss, Indurkhya, & Zhang, 2004).","['common', 'single']","(0, [])","(0, [])"
"Weiss, Indurkhya, & Zhang, 2010","A high score is assigned to terms that occur frequently in a class (and rarely in the others) as follows (Weiss, Indurkhya, & Zhang, 2010): IG t C X P ck log k 1 1 P ck (cid:2) X P t C X P tjck log t2ftp;tpg k 1 1 P tjck ; 2 where P(ck) is the prior probability of a document occurring in class ck,P(t) is the probability of term t occurring or not in a document, i. e. P(tp) and P tp respectively.","['prior', 'high']","(0, [])","(0, [])"
"Whitelaw, Garg, and Argamon (2005)","Whitelaw, Garg, and Argamon (2005) proposed considering adjectival expressions as an important indication of the sentiment polarity in textual reviews.","['important', 'argamon', 'adjectival', 'textual']","(1, ['important'])","(0, [])"
"Xia & Zong, 2010","None of them has been widely accepted as the best feature selection method for sentiment classi cation or text categorization, however, information gain has often been competitive (Abbasi et al., 2011; Forman, 2003; Li et al., 2009; Xia & Zong, 2010; Yang & Pedersen, 1997).","['competitive', 'forman', 'best']","(2, ['competitive', 'best'])","(0, [])"
"Xia, Zong, & Li, 2011","This ensemble learning approach can be computationally expensive (Xia, Zong, & Li, 2011) and no discussion on this issue is reported by the authors.","['ensemble', 'expensive']","(0, [])","(1, ['expensive'])"
"Yang & Pedersen, 1997","Dang, Zhang, and Chen (2010) also used various categories of features, which were re ned by applying the Information Gain (IG) technique (Yang & Pedersen, 1997). None of them has been widely accepted as the best feature selection method for sentiment classi cation or text categorization, however, information gain has often been competitive (Abbasi et al., 2011; Forman, 2003; Li et al., 2009; Xia & Zong, 2010; Yang & Pedersen, 1997).","['forman', 'various', 'pedersen', 'best', 'competitive']","(2, ['best', 'competitive'])","(0, [])"
"Ye, Zhang, & Law, 2009","The most popular sentiment learning techniques are SVM and NB, and many authors have reported better accuracy by using SVM (Abbasi, 2010; Dang et al., 2010; O Keefe & Koprinska, 2009; Pang et al., 2002; Prabowo & Thelwall, 2009; Ye, Zhang, & Law, 2009).","['popular', 'many', 'svm']","(1, ['popular'])","(0, [])"
"Zaidan, Eisner, and Piatko (2007)","Zaidan, Eisner, and Piatko (2007) proposed learning the sentiment polarity of reviews from an additional source of information.",['additional'],"(0, [])","(0, [])"
although Cristianini and Shawe-Taylor (2000),"Thus, although Cristianini and Shawe-Taylor (2000) mentioned that in practice SVM frequently results in very few support vectors, our results are consistent with previous results on text categorization (Colas, Pacl k, Kok, & Brazdil, 2007) in reporting a high number of support vectors.","['high', 'consistent', 'previous', 'text', 'few']","(1, ['consistent'])","(0, [])"
and Pang and Lee (2008),The research eld is know as opinion mining or sentiment classi cation and a complete overview on the subject is presented in Liu (2011) and Pang and Lee (2008).,"['complete', 'liu']","(0, [])","(0, [])"
in Atakulreka and Sutivong (2007),"Nevertheless, each ANN training process could run simultaneously in parallel as proposed in Atakulreka and Sutivong (2007).",['sutivong'],"(0, [])","(0, [])"
in Ben-Hur and Weston (2010),"A detailed discussion covering parameter values and their implications are beyond the scope of our work and can be found in Ben-Hur and Weston (2010), Burges (1998), Hastie et al.","['hastie', 'detailed']","(0, [])","(0, [])"
in Liu (2011),The research eld is know as opinion mining or sentiment classi cation and a complete overview on the subject is presented in Liu (2011) and Pang and Lee (2008).,"['complete', 'liu']","(0, [])","(0, [])"
in McCallum and Nigam (1998),"More details on models for text classi cation and NB classi ers can be found in McCallum and Nigam (1998), Manning et al.","['more', 'text', 'nigam']","(0, [])","(0, [])"
of 2000,Each dataset consists of 2000 reviews that were classi ed in terms of the overall orientation as being either positive or negative (1000 positive and 1000 negative reviews).,"['classi', 'positive', 'overall', 'negative']","(1, ['positive'])","(1, ['negative'])"
on 2000,"Since we conducted the validation as a 10-fold process on 2000 reviews, training time is computed by considering 1800 reviews and running time is computed on the remaining 200 reviews.",['fold'],"(0, [])","(0, [])"
"problem, Wang, Li, Zhou, Li, and Zhu (2011)","In order to overcome this problem, Wang, Li, Zhou, Li, and Zhu (2011) propose combining multiple classi ers, which are trained from multiple instances of under-sampled data.","['multiple', 'propose', 'undersampled']","(0, [])","(0, [])"
"reviews, Pang and Lee (2004)","In order to better approach sentiments in textual reviews, Pang and Lee (2004) also proposed classifying sentences as being either subjective or objective, and then apply sentiment classi cation on the subjective portion of the text.","['objective', 'subjective', 'better', 'textual']","(1, ['better'])","(0, [])"
"shi Wang, 2010","ANN and sentiment classi cation ANN has gured rarely in the literature (Bespalov, Bai, Qi, & Shokoufandeh, 2011; Chen et al., 2011; Claster, Hung, & Shanmuganathan, 2010; Zhu, XU, & shi Wang, 2010), as can be seen in recent surveys on sentiment analysis (Pang & Lee, 2008; Tsytsarau & Palpanas, 2012).",['recent'],"(0, [])","(0, [])"
"subjective, Raychev and Nakov (2009)","In addition to the probability of a term being subjective, Raychev and Nakov (2009) proposed considering the position of terms in the text as a strategy for identifying informative features.","['subjective', 'nakov', 'informative']","(0, [])","(0, [])"
"th, 2003","Therefore, the solution can be written as a weighted sum of the values of certain kernel function evaluated at the support vectors (Horv th, 2003).","['certain', 'weighted']","(0, [])","(0, [])"
Andreevskaia and Bergler (2008),"Other hybrid methods include those of Andreevskaia and Bergler (2008), Dang, Zhang, and Chen (2010), Dasgupta and Ng (2009), Goldberg and Zhu (2006), or Prabowo and Thelwall (2009). Andreevskaia and Bergler (2008) show, however, that cross-domain performance drops signi cantly. The gures in the rst section of Table 7 suggest robust performance as compared to a mostfrequent-class baseline, including modest improvement over the relevant cross-domain results of Andreevskaia and Bergler (2008).22 Moilanen, Pulman, and Zhang (2010) also use the headlines data, and obtain a polarity classi cation accuracy of 77.94% below our results excluding empty.23 21 By default, SO-CAL assigns a zero to such texts, which is usually interpreted to mean that the text is neither positive nor negative.","['empty', 'such', 'positive', 'other', 'rst', 'table', 'mostfrequentclass', 'crossdomain', 'negative', 'socal', 'modest', 'robust', 'suggest', 'default', 'hybrid', 'relevant']","(3, ['positive', 'modest', 'robust'])","(1, ['negative'])"
Andreevskaia and Bergler 2008,"One of the criticisms raised against lexicon-based methods is that the dictionaries are unreliable, as they are either built automatically or hand-ranked by humans (Andreevskaia and Bergler 2008). 2.9 Evaluation of SO-CAL in Other Domains Reference to domain portability, in this article and in other work, is usually limited to portability across different types of reviews (Aue and Gamon 2005; Blitzer, Dredze, and Pereira 2007; Andreevskaia and Bergler 2008). We tested SO-CAL with four different data sets: the Multi-Perspective Question Answering (MPQA) corpus, version 2.0 (Wiebe, Wilson, and Cardie 2005); a collection of MySpace.com comments from Mike Thelwall (Prabowo and Thelwall 2009); a set of news and blog posts from Alina Andreevskaia (Andreevskaia and Bergler 2008); and a set of headlines from Rada Mihalcea and Carlo Strappavara (Strappavara and Mihalcea 2007).20 The rst set of data is the MPQA corpus (version 2.0), a collection of news articles and other documents (texts from the American National Corpus and other sources) annotated for opinions and other private states (beliefs, emotions, speculation, etc.). Support Vector Machine (SVM) classi ers have been shown to outperform lexicon-based models within a single domain (Kennedy and Inkpen 2006); they have trouble with cross-domain tasks (Aue and Gamon 2005), however, and some researchers have argued for hybrid classi ers (Andreevskaia and Bergler 2008).","['single', 'socal', 'emotions', 'crossdomain', 'private', 'mpqa', 'hybrid', 'handranked', 'other', 'alina', 'corpus', 'unreliable', 'andreevskaia', 'etc', 'lexiconbased', 'american', 'different', 'national', 'multiperspective']","(0, [])","(1, ['unreliable'])"
Aue and Gamon 2005,"2.9 Evaluation of SO-CAL in Other Domains Reference to domain portability, in this article and in other work, is usually limited to portability across different types of reviews (Aue and Gamon 2005; Blitzer, Dredze, and Pereira 2007; Andreevskaia and Bergler 2008). Support Vector Machine (SVM) classi ers have been shown to outperform lexicon-based models within a single domain (Kennedy and Inkpen 2006); they have trouble with cross-domain tasks (Aue and Gamon 2005), however, and some researchers have argued for hybrid classi ers (Andreevskaia and Bergler 2008).","['lexiconbased', 'other', 'single', 'crossdomain', 'socal', 'different', 'hybrid']","(0, [])","(0, [])"
August 2010,Submission received: 14 December 2009; revised submission received: 22 August 2010; accepted for publication: 28 September 2010.,[],"(0, [])","(0, [])"
"Baccianella, Esuli, and Sebastiani 2010","Automatically generated dictionaries are generally much larger: SentiWordNet (Baccianella, Esuli, and Sebastiani 2010) includes 38,182 non-neutral words (when the polarity of senses is averaged see discussion in Section 3.4), and the Maryland dictionary (Mohammad, Dorr, and Dunne 2009) has 76,775 words and phrases tagged for polarity. Another publicly available corpus is SentiWordNet (Esuli and Sebastiani 2006; Baccianella, Esuli, and Sebastiani 2010), an extension of WordNet (Fellbaum 1998) where each synset is annotated with labels indicating how objective, positive, and negative the terms in the synset are. The SentiWordNet dictionary (Esuli and Sebastiani 2006; Baccianella, Esuli, and Sebastiani 2010), also used in the previous section, was built using WordNet (Fellbaum 1998), and retains its synset structure.","['available', 'dictionary', 'averaged', 'sentiwordnet', 'previous', 'much', 'negative', 'objective', 'see', 'nonneutral']","(1, ['available'])","(1, ['negative'])"
Bartlett and Albright 2008,2007; Bartlett and Albright 2008).,[],"(0, [])","(0, [])"
"Batson, Shaw, and Oleson 1992","The analysis and automatic extraction of semantic orientation can be found under different umbrella terms: sentiment analysis (Pang and Lee 2008), subjectivity (Lyons 1981; Langacker 1985), opinion mining (Pang and Lee 2008), analysis of stance (Biber and Finegan 1988; Conrad and Biber 2000), appraisal (Martin and White 2005), point of view (Wiebe 1994; Scheibman 2002), evidentiality (Chafe and Nichols 1986), and a few others, without expanding into neighboring disciplines and the study of emotion (Ketal 1975; Ortony, Clore, and Collins 1988) and affect (Batson, Shaw, and Oleson 1992).","['affect', 'semantic', 'ortony', 'scheibman', 'automatic', 'ketal', 'different', 'white', 'finegan', 'few']","(0, [])","(0, [])"
Bednarek 2009,Syntactic patterns can also be used to distinguish different types of opinion and appraisal (Bednarek 2009).,"['syntactic', 'different']","(0, [])","(0, [])"
Biber and Finegan 1988,"The analysis and automatic extraction of semantic orientation can be found under different umbrella terms: sentiment analysis (Pang and Lee 2008), subjectivity (Lyons 1981; Langacker 1985), opinion mining (Pang and Lee 2008), analysis of stance (Biber and Finegan 1988; Conrad and Biber 2000), appraisal (Martin and White 2005), point of view (Wiebe 1994; Scheibman 2002), evidentiality (Chafe and Nichols 1986), and a few others, without expanding into neighboring disciplines and the study of emotion (Ketal 1975; Ortony, Clore, and Collins 1988) and affect (Batson, Shaw, and Oleson 1992).","['affect', 'semantic', 'ortony', 'scheibman', 'automatic', 'ketal', 'different', 'white', 'finegan', 'few']","(0, [])","(0, [])"
"Blitzer, Dredze, and Pereira (2007)","(2010) use co-training to incorporate labeled and unlabeled examples, also making use of 3 Blitzer, Dredze, and Pereira (2007) do show some success in transferring knowledge across domains, so that the classi er does not have to be re-built entirely from scratch.","['unlabeled', 'rebuilt']","(0, [])","(0, [])"
"Blitzer, Dredze, and Pereira 2007","2.9 Evaluation of SO-CAL in Other Domains Reference to domain portability, in this article and in other work, is usually limited to portability across different types of reviews (Aue and Gamon 2005; Blitzer, Dredze, and Pereira 2007; Andreevskaia and Bergler 2008).","['other', 'socal', 'different']","(0, [])","(0, [])"
"Bloom, Garg, and Argamon 2007","2009), and some work relies on Appraisal Theory (Whitelaw, Garg, and Argamon 2005; Bloom, Garg, and Argamon 2007), a theory developed by Martin and White (2005).","['white', 'argamon']","(0, [])","(0, [])"
Boucher and Osgood 1969,"This markedness is true in terms of linguistic form, with negative forms being marked across languages (Greenberg 1966), and it is also manifested as (token) frequency distribution, with negatives being less frequent (Boucher and Osgood 1969).15 Negation tends to be expressed in euphemistic ways, which makes negative sentiment more dif cult to identify in general. 2.6 Text-Level Features Lexicon-based sentiment classi ers generally show a positive bias (Kennedy and Inkpen 2006), likely the result of a universal human tendency to favor positive language (Boucher and Osgood 1969).16 In order to overcome this problem, Voll and Taboada (2007) implemented normalization, shifting the numerical cut-off point between positive and negative reviews. This is mostly likely attributable to the default status of positive, and the marked character of negative expression (Boucher and Osgood 1969; Horn 1989; Jing-Schmidt 2007); neutral description might be taken as being vaguely positive, but it would not be mistaken for negative expression.26 For the word-pair task, we categorize the distribution data by the difference in SO between the two words, putting negative and positive words in separate tables.","['horn', 'neutral', 'separate', 'universal', 'wordpair', 'textlevel', 'likely', 'frequent', 'jingschmidt', 'positive', 'numerical', 'negative', 'linguistic', 'attributable', 'euphemistic', 'lexiconbased', 'true', 'general', 'dif', 'token', 'marked', 'human']","(1, ['positive'])","(1, ['negative'])"
Brill 1992,"Within each collection, the reviews were split into 25 positive and 25 4 To determine part of speech, we use the Brill tagger (Brill 1992).",['positive'],"(1, ['positive'])","(0, [])"
Brooke 2009,"In related work, we have also shown that creating a new version of SO-CAL for a new language, Spanish, is as fast as building text classi ers for the new language, and results in better performance (Brooke 2009; Brooke, To loski, and Taboada 2009).","['new', 'fast', 'socal', 'better', 'related']","(2, ['fast', 'better'])","(0, [])"
Brooke and Hurst 2009,"2008; Brooke and Hurst 2009). 2008) and video game reviews (Brooke and Hurst 2009), without any need for further development or training. SO-CAL has also been successfully deployed for the detection of sentence-level polarity (Brooke and Hurst 2009).","['video', 'sentencelevel', 'socal', 'further']","(0, [])","(0, [])"
Bruce and Wiebe 2000,Several lexiconbased approaches have adopted these assumptions (Bruce and Wiebe 2000; Hu and Liu 2004; Kim and Hovy 2004).,['several'],"(0, [])","(0, [])"
Callison-Burch 2009,2008; Callison-Burch 2009; Zaenen to appear).,['callisonburch'],"(0, [])","(0, [])"
Chafe and Nichols 1986,"The analysis and automatic extraction of semantic orientation can be found under different umbrella terms: sentiment analysis (Pang and Lee 2008), subjectivity (Lyons 1981; Langacker 1985), opinion mining (Pang and Lee 2008), analysis of stance (Biber and Finegan 1988; Conrad and Biber 2000), appraisal (Martin and White 2005), point of view (Wiebe 1994; Scheibman 2002), evidentiality (Chafe and Nichols 1986), and a few others, without expanding into neighboring disciplines and the study of emotion (Ketal 1975; Ortony, Clore, and Collins 1988) and affect (Batson, Shaw, and Oleson 1992).","['affect', 'semantic', 'ortony', 'scheibman', 'automatic', 'ketal', 'different', 'white', 'finegan', 'few']","(0, [])","(0, [])"
Chaovalit and Zhou 2005,Classi ers built using supervised methods reach quite a high accuracy in detecting the polarity of a text (Chaovalit and Zhou 2005; Kennedy and Inkpen 2006; Boiy et al.,['high'],"(0, [])","(0, [])"
Choi and Cardie 2008,"Though it seems to work well in certain cases (Choi and Cardie 2008), it fails miserably in others (Liu and Seneff 2009). We also discuss, in Section 2.4, work on incorporating linguistic insights for the treatment of negation (Moilanen and Pulman 2007; Choi and Cardie 2008).","['linguistic', 'certain']","(0, [])","(0, [])"
Conrad and Biber 2000,"The analysis and automatic extraction of semantic orientation can be found under different umbrella terms: sentiment analysis (Pang and Lee 2008), subjectivity (Lyons 1981; Langacker 1985), opinion mining (Pang and Lee 2008), analysis of stance (Biber and Finegan 1988; Conrad and Biber 2000), appraisal (Martin and White 2005), point of view (Wiebe 1994; Scheibman 2002), evidentiality (Chafe and Nichols 1986), and a few others, without expanding into neighboring disciplines and the study of emotion (Ketal 1975; Ortony, Clore, and Collins 1988) and affect (Batson, Shaw, and Oleson 1992).","['affect', 'semantic', 'ortony', 'scheibman', 'automatic', 'ketal', 'different', 'white', 'finegan', 'few']","(0, [])","(0, [])"
"Councill, McDonald, and Velikovich 2010","Another option is to use parser results to learn the scope (Councill, McDonald, and Velikovich 2010).",[],"(0, [])","(0, [])"
"Dang, Zhang, and Chen (2010)","Other hybrid methods include those of Andreevskaia and Bergler (2008), Dang, Zhang, and Chen (2010), Dasgupta and Ng (2009), Goldberg and Zhu (2006), or Prabowo and Thelwall (2009).","['other', 'hybrid']","(0, [])","(0, [])"
Dasgupta and Ng (2009),"Other hybrid methods include those of Andreevskaia and Bergler (2008), Dang, Zhang, and Chen (2010), Dasgupta and Ng (2009), Goldberg and Zhu (2006), or Prabowo and Thelwall (2009).","['other', 'hybrid']","(0, [])","(0, [])"
December 2009,Submission received: 14 December 2009; revised submission received: 22 August 2010; accepted for publication: 28 September 2010.,[],"(0, [])","(0, [])"
Devitt and Ahmad 2007,"Many other systems make use of either the Subjectivity dictionary of Wiebe and colleagues, or of SentiWordNet (Devitt and Ahmad 2007; Thet et al.","['ahmad', 'other', 'many', 'sentiwordnet']","(0, [])","(0, [])"
Esuli and Sebastiani 2006,"Lexicon-Based Methods for Sentiment Analysis and Hovy 2004; Esuli and Sebastiani 2006). Another publicly available corpus is SentiWordNet (Esuli and Sebastiani 2006; Baccianella, Esuli, and Sebastiani 2010), an extension of WordNet (Fellbaum 1998) where each synset is annotated with labels indicating how objective, positive, and negative the terms in the synset are. The SentiWordNet dictionary (Esuli and Sebastiani 2006; Baccianella, Esuli, and Sebastiani 2010), also used in the previous section, was built using WordNet (Fellbaum 1998), and retains its synset structure. Lexicon-Based Methods for Sentiment Analysis approaches have emerged: the use of machine-learning classi ers trained on n-grams or similar features (Pang, Lee, and Vaithyanathan 2002), and the use of sentiment dictionaries (Esuli and Sebastiani 2006; Taboada, Anthony, and Voll 2006).","['machinelearning', 'lexiconbased', 'structure', 'dictionary', 'similar', 'sentiwordnet', 'synset', 'previous', 'negative', 'objective', 'available']","(1, ['available'])","(1, ['negative'])"
Fellbaum 1998,"Another publicly available corpus is SentiWordNet (Esuli and Sebastiani 2006; Baccianella, Esuli, and Sebastiani 2010), an extension of WordNet (Fellbaum 1998) where each synset is annotated with labels indicating how objective, positive, and negative the terms in the synset are. The SentiWordNet dictionary (Esuli and Sebastiani 2006; Baccianella, Esuli, and Sebastiani 2010), also used in the previous section, was built using WordNet (Fellbaum 1998), and retains its synset structure.","['dictionary', 'sentiwordnet', 'previous', 'negative', 'objective', 'available']","(1, ['available'])","(1, ['negative'])"
Finn and Kushmerick 2003,"Names also gure prominently, a problem noted by other researchers (Finn and Kushmerick 2003; Kennedy and Inkpen 2006).",['other'],"(0, [])","(0, [])"
Fletcher and Patrick (2005),"Fletcher and Patrick (2005) used bags-of-words that included Appraisal features, and obtained 83.7% accuracy in that same data set, whereas Whitelaw, Garg, and Argamon (2005), using bags-of-words combined with Appraisal groups achieved 90.2%.","['argamon', 'same', 'whitelaw', 'appraisal']","(0, [])","(0, [])"
Giannakidou 1998,"NPIs occur in negative sentences, but also in nonveridical contexts (Zwarts 1995; Giannakidou 1998), which also affect semantic orientation.","['semantic', 'npis', 'nonveridical', 'negative']","(0, [])","(1, ['negative'])"
Goldberg and Zhu (2006),"Other hybrid methods include those of Andreevskaia and Bergler (2008), Dang, Zhang, and Chen (2010), Dasgupta and Ng (2009), Goldberg and Zhu (2006), or Prabowo and Thelwall (2009).","['other', 'hybrid']","(0, [])","(0, [])"
Greenberg 1966,"This markedness is true in terms of linguistic form, with negative forms being marked across languages (Greenberg 1966), and it is also manifested as (token) frequency distribution, with negatives being less frequent (Boucher and Osgood 1969).15 Negation tends to be expressed in euphemistic ways, which makes negative sentiment more dif cult to identify in general.","['euphemistic', 'true', 'frequent', 'dif', 'negative', 'linguistic', 'token']","(0, [])","(1, ['negative'])"
Greene and Resnik 2009,"Computational Linguistics Volume 37, Number 2 the sentence level, exploring the types of syntactic patterns that indicate subjectivity and sentiment is also a possibility (Greene and Resnik 2009).","['computational', 'syntactic']","(0, [])","(0, [])"
Halliday 1985,"We nd that grammatical metaphor (Halliday 1985), that is, the use of a noun to refer to an action, adds a more negative connotation to negative words.","['grammatical', 'negative']","(0, [])","(1, ['negative'])"
Hatzivassiloglou and McKeown 1997,"1966; Tong 2001), or automatically, using seed words to expand the list of words (Hatzivassiloglou and McKeown 1997; Turney 2002; Turney and Littman 2003). Much of the lexicon-based research has focused on using adjectives as indicators of the semantic orientation of text (Hatzivassiloglou and McKeown 1997; Wiebe 2000; Hu and Liu 2004; Taboada, Anthony, and Voll 2006).2 First, a list of adjectives and corresponding SO values is compiled into a dictionary. 2.1 Adjectives Much of the early research in sentiment focused on adjectives or adjective phrases as the primary source of subjective content in a document (Hatzivassiloglou and McKeown 1997; Hu and Liu 2004; Taboada, Anthony, and Voll 2006), albeit with some exceptions, especially more recently, which have also included the use of adverbs (Benamara et al.","['semantic', 'lexiconbased', 'dictionary', 'tong', 'primary', 'subjective', 'adjective', 'recently', 'early']","(0, [])","(0, [])"
Horn 1989,"The rst approach is fairly liberal, and allows us to capture the true effects of negation raising (Horn 1989), where the negator for a verb moves up and attaches to the verb in the matrix clause. One other interesting aspect of the pragmatics of negation is that negative statements tend to be perceived as more marked than their af rmative counterparts, both pragmatically and psychologically (Osgood and Richards 1973; Horn 1989, chapter 3). This is mostly likely attributable to the default status of positive, and the marked character of negative expression (Boucher and Osgood 1969; Horn 1989; Jing-Schmidt 2007); neutral description might be taken as being vaguely positive, but it would not be mistaken for negative expression.26 For the word-pair task, we categorize the distribution data by the difference in SO between the two words, putting negative and positive words in separate tables.","['jingschmidt', 'true', 'wordpair', 'horn', 'likely', 'positive', 'other', 'rst', 'liberal', 'neutral', 'negative', 'separate', 'attributable', 'marked', 'rmative']","(1, ['positive'])","(1, ['negative'])"
Hu and Liu 2004,"Much of the lexicon-based research has focused on using adjectives as indicators of the semantic orientation of text (Hatzivassiloglou and McKeown 1997; Wiebe 2000; Hu and Liu 2004; Taboada, Anthony, and Voll 2006).2 First, a list of adjectives and corresponding SO values is compiled into a dictionary. Several lexiconbased approaches have adopted these assumptions (Bruce and Wiebe 2000; Hu and Liu 2004; Kim and Hovy 2004). 2.1 Adjectives Much of the early research in sentiment focused on adjectives or adjective phrases as the primary source of subjective content in a document (Hatzivassiloglou and McKeown 1997; Hu and Liu 2004; Taboada, Anthony, and Voll 2006), albeit with some exceptions, especially more recently, which have also included the use of adverbs (Benamara et al. 1966), or semi-automatically, making use of resources like WordNet (Hu and Liu 2004; Kim 270","['semantic', 'lexiconbased', 'semiautomatically', 'dictionary', 'primary', 'subjective', 'adjective', 'several', 'recently', 'early']","(0, [])","(0, [])"
"In Taboada, Anthony, and Voll (2006)","In Taboada, Anthony, and Voll (2006) we report on experiments using different search engines and operators in trying to create dictionaries semiautomatically.","['taboada', 'different']","(0, [])","(0, [])"
"In Taboada, Brooke, and Stede (2009)","In Taboada, Brooke, and Stede (2009) we built classi ers to distinguish among paragraphs that contained mostly description, mostly comment, a combination of the two, or meta-information (such as titles, authors, review ratings, or movie ratings).","['classi', 'titles', 'such', 'stede', 'taboada']","(0, [])","(0, [])"
Jing-Schmidt 2007,"English does not make extensive use of the subjunctive for this purpose, as opposed to other languages, such as Spanish, which tend to use the subjunctive mood to indicate that what is being 15 Some researchers argue that there is a negative bias in the human representation of experience (negative events are more salient), and the positive bias found by Boucher and Osgood is the result of euphemisms and political correctness in language (Jing-Schmidt 2007). This is mostly likely attributable to the default status of positive, and the marked character of negative expression (Boucher and Osgood 1969; Horn 1989; Jing-Schmidt 2007); neutral description might be taken as being vaguely positive, but it would not be mistaken for negative expression.26 For the word-pair task, we categorize the distribution data by the difference in SO between the two words, putting negative and positive words in separate tables.","['more', 'political', 'such', 'positive', 'horn', 'likely', 'wordpair', 'extensive', 'other', 'separate', 'neutral', 'negative', 'subjunctive', 'attributable', 'jingschmidt', 'marked', 'salient', 'human']","(1, ['positive'])","(1, ['negative'])"
Kennedy and Inkpen 2006,"Classi ers built using supervised methods reach quite a high accuracy in detecting the polarity of a text (Chaovalit and Zhou 2005; Kennedy and Inkpen 2006; Boiy et al. Names also gure prominently, a problem noted by other researchers (Finn and Kushmerick 2003; Kennedy and Inkpen 2006). Some researchers in sentiment analysis (Kennedy and Inkpen 2006; Polanyi and Zaenen 2006) have implemented 274 2.6 Text-Level Features Lexicon-based sentiment classi ers generally show a positive bias (Kennedy and Inkpen 2006), likely the result of a universal human tendency to favor positive language (Boucher and Osgood 1969).16 In order to overcome this problem, Voll and Taboada (2007) implemented normalization, shifting the numerical cut-off point between positive and negative reviews. Support Vector Machine (SVM) classi ers have been shown to outperform lexicon-based models within a single domain (Kennedy and Inkpen 2006); they have trouble with cross-domain tasks (Aue and Gamon 2005), however, and some researchers have argued for hybrid classi ers (Andreevskaia and Bergler 2008). 2004; Kennedy and Inkpen 2006; Ng, Dasgupta, and Niaz Ari n 2006; Sokolova and Lapalme 2008), it nonetheless still suffers from lack of cross-domain portability.","['universal', 'lexiconbased', 'high', 'positive', 'textlevel', 'other', 'niaz', 'single', 'crossdomain', 'numerical', 'negative', 'hybrid', 'human']","(1, ['positive'])","(1, ['negative'])"
Ketal 1975,"The analysis and automatic extraction of semantic orientation can be found under different umbrella terms: sentiment analysis (Pang and Lee 2008), subjectivity (Lyons 1981; Langacker 1985), opinion mining (Pang and Lee 2008), analysis of stance (Biber and Finegan 1988; Conrad and Biber 2000), appraisal (Martin and White 2005), point of view (Wiebe 1994; Scheibman 2002), evidentiality (Chafe and Nichols 1986), and a few others, without expanding into neighboring disciplines and the study of emotion (Ketal 1975; Ortony, Clore, and Collins 1988) and affect (Batson, Shaw, and Oleson 1992).","['affect', 'semantic', 'ortony', 'scheibman', 'automatic', 'ketal', 'different', 'white', 'finegan', 'few']","(0, [])","(0, [])"
Kim and Hovy 2004,"Several lexiconbased approaches have adopted these assumptions (Bruce and Wiebe 2000; Hu and Liu 2004; Kim and Hovy 2004). 2007); adjectives and verbs (Kim and Hovy 2004); adjective phrases (Whitelaw, Garg, and Argamon 2005); two-word phrases (Turney 2002; Turney and Littman 2003); adjectives, verbs, and adverbs (Subrahmanian and Reforgiato 2008); the exclusive use of verbs (Sokolova and Lapalme 2008); the use of non-affective adjectives and adverbs (Sokolova and Lapalme 2009a, 2009b); or rationales, words and phrases selected by human annotators (Zaidan and Eisner 2008).","['twoword', 'adverbs', 'exclusive', 'nonaffective', 'adjective', 'littman', 'several', 'argamon', 'subrahmanian', 'human']","(0, [])","(0, [])"
Langacker 1985,"The analysis and automatic extraction of semantic orientation can be found under different umbrella terms: sentiment analysis (Pang and Lee 2008), subjectivity (Lyons 1981; Langacker 1985), opinion mining (Pang and Lee 2008), analysis of stance (Biber and Finegan 1988; Conrad and Biber 2000), appraisal (Martin and White 2005), point of view (Wiebe 1994; Scheibman 2002), evidentiality (Chafe and Nichols 1986), and a few others, without expanding into neighboring disciplines and the study of emotion (Ketal 1975; Ortony, Clore, and Collins 1988) and affect (Batson, Shaw, and Oleson 1992).","['affect', 'semantic', 'ortony', 'scheibman', 'automatic', 'ketal', 'different', 'white', 'finegan', 'few']","(0, [])","(0, [])"
Liu and Seneff 2009,"Though it seems to work well in certain cases (Choi and Cardie 2008), it fails miserably in others (Liu and Seneff 2009).",['certain'],"(0, [])","(0, [])"
Lyons 1981,"The analysis and automatic extraction of semantic orientation can be found under different umbrella terms: sentiment analysis (Pang and Lee 2008), subjectivity (Lyons 1981; Langacker 1985), opinion mining (Pang and Lee 2008), analysis of stance (Biber and Finegan 1988; Conrad and Biber 2000), appraisal (Martin and White 2005), point of view (Wiebe 1994; Scheibman 2002), evidentiality (Chafe and Nichols 1986), and a few others, without expanding into neighboring disciplines and the study of emotion (Ketal 1975; Ortony, Clore, and Collins 1988) and affect (Batson, Shaw, and Oleson 1992).","['affect', 'semantic', 'ortony', 'scheibman', 'automatic', 'ketal', 'different', 'white', 'finegan', 'few']","(0, [])","(0, [])"
Mann and Thompson 1988,"12 The discourse connective but plays a role in linking clauses and sentences in a rhetorical relation (Mann and Thompson 1988). For example, one module could pre-process the text and tag spans that are believed to be topic sentences, another module could provide discourse information such as rhetorical relations (Mann and Thompson 1988), and a third module could label the sentences that seem to be subjective.","['such', 'rhetorical', 'topic', 'subjective', 'third', 'discourse']","(0, [])","(1, ['rhetorical'])"
Martin and White 2005,"The analysis and automatic extraction of semantic orientation can be found under different umbrella terms: sentiment analysis (Pang and Lee 2008), subjectivity (Lyons 1981; Langacker 1985), opinion mining (Pang and Lee 2008), analysis of stance (Biber and Finegan 1988; Conrad and Biber 2000), appraisal (Martin and White 2005), point of view (Wiebe 1994; Scheibman 2002), evidentiality (Chafe and Nichols 1986), and a few others, without expanding into neighboring disciplines and the study of emotion (Ketal 1975; Ortony, Clore, and Collins 1988) and affect (Batson, Shaw, and Oleson 1992).","['affect', 'semantic', 'ortony', 'scheibman', 'automatic', 'ketal', 'different', 'white', 'finegan', 'few']","(0, [])","(0, [])"
Mohammad and Turney 2010,"2010; Mohammad and Turney 2010; Yano, Resnik, and Smith 2010), although there are mixed reports on its reliability (Snow et al.",['mixed'],"(0, [])","(0, [])"
"Mohammad, Dorr, and Dunne 2009","Automatically generated dictionaries are generally much larger: SentiWordNet (Baccianella, Esuli, and Sebastiani 2010) includes 38,182 non-neutral words (when the polarity of senses is averaged see discussion in Section 3.4), and the Maryland dictionary (Mohammad, Dorr, and Dunne 2009) has 76,775 words and phrases tagged for polarity. Computational Linguistics Volume 37, Number 2 The Maryland dictionary (Mohammad, Dorr, and Dunne 2009) is a very large collection of words and phrases (around 70,000) extracted from the Macquarie Thesaurus.","['computational', 'polarity', 'dictionary', 'averaged', 'large', 'much', 'see', 'nonneutral']","(0, [])","(0, [])"
Moilanen and Pulman 2007,"We also discuss, in Section 2.4, work on incorporating linguistic insights for the treatment of negation (Moilanen and Pulman 2007; Choi and Cardie 2008).",['linguistic'],"(0, [])","(0, [])"
"Moilanen, Pulman, and Zhang (2010)","The gures in the rst section of Table 7 suggest robust performance as compared to a mostfrequent-class baseline, including modest improvement over the relevant cross-domain results of Andreevskaia and Bergler (2008).22 Moilanen, Pulman, and Zhang (2010) also use the headlines data, and obtain a polarity classi cation accuracy of 77.94% below our results excluding empty.23 21 By default, SO-CAL assigns a zero to such texts, which is usually interpreted to mean that the text is neither positive nor negative.","['empty', 'such', 'positive', 'rst', 'table', 'mostfrequentclass', 'crossdomain', 'negative', 'socal', 'modest', 'robust', 'suggest', 'default', 'relevant']","(3, ['positive', 'modest', 'robust'])","(1, ['negative'])"
Mullen and Collier 2004,Although some of the machine-learningbased work makes use of linguistic features for training (Riloff and Wiebe 2003; Mullen and Collier 2004; Wiebe et al.,"['machinelearningbased', 'linguistic', 'collier']","(0, [])","(0, [])"
"Ortony, Clore, and Collins 1988","The analysis and automatic extraction of semantic orientation can be found under different umbrella terms: sentiment analysis (Pang and Lee 2008), subjectivity (Lyons 1981; Langacker 1985), opinion mining (Pang and Lee 2008), analysis of stance (Biber and Finegan 1988; Conrad and Biber 2000), appraisal (Martin and White 2005), point of view (Wiebe 1994; Scheibman 2002), evidentiality (Chafe and Nichols 1986), and a few others, without expanding into neighboring disciplines and the study of emotion (Ketal 1975; Ortony, Clore, and Collins 1988) and affect (Batson, Shaw, and Oleson 1992).","['affect', 'semantic', 'ortony', 'scheibman', 'automatic', 'ketal', 'different', 'white', 'finegan', 'few']","(0, [])","(0, [])"
Osgood and Richards 1973,"One other interesting aspect of the pragmatics of negation is that negative statements tend to be perceived as more marked than their af rmative counterparts, both pragmatically and psychologically (Osgood and Richards 1973; Horn 1989, chapter 3).","['horn', 'other', 'rmative', 'negative']","(0, [])","(1, ['negative'])"
"Osgood, Suci, and Tannenbaum 1957","Computational Linguistics Volume 37, Number 2 towards a subject topic, person, or idea (Osgood, Suci, and Tannenbaum 1957).",['computational'],"(0, [])","(0, [])"
Pang and Lee (2008),"However, although such classi ers perform very well in the domain that they are trained on, their performance drops precipitously (almost to chance) when the same classi er is used in 1 Pang and Lee (2008) provide an excellent recent survey of the opinion mining or sentiment analysis problem and the approaches used to tackle it.","['classi', 'such', 'excellent', 'lee', 'same', 'recent']","(1, ['excellent'])","(0, [])"
Pang and Lee 2004,"The enhanced dictionaries contain 2,252 adjective entries, 1,142 nouns, 903 verbs, and 745 adverbs.6 The SO-carrying words in these dictionaries were taken from a variety of sources, the three largest being Epinions 1, the 400-text corpus described in the previous section; a 100-text subset of the 2,000 movie reviews in the Polarity Dataset (Pang, Lee, and Vaithyanathan 2002; Pang and Lee 2004, 2005);7 and positive and negative words from the General Inquirer dictionary (Stone et al. Movie: 1,900 texts from the Polarity Dataset (Pang and Lee 2004).18 Camera: A 2,400-text corpus of camera, printer, and stroller reviews, taken from a larger set of Epinions reviews; also used in Bloom, Garg, and Argamon (2007). Pang and Lee s own results show an overall accuracy of 87.15% for polarity classi cation of whole reviews (Pang and Lee 2004).","['enhanced', 'bloom', 'positive', 'socarrying', 'general', 'dictionary', 'previous', 'text', 'nouns', 'adjective', 'lee', 'whole', 'own', 'negative', 'larger', 'argamon', 'largest', 'overall']","(3, ['enhanced', 'bloom', 'positive'])","(1, ['negative'])"
Pang and Lee 2005,"MT correspondence of 30 Distinguishing neutral and polar terms, sentences, or texts is, in general, a hard problem (Wilson, Wiebe, and Hwa 2004; Pang and Lee 2005).","['neutral', 'hard', 'polar']","(0, [])","(1, ['hard'])"
Pang and Lee 2008,"The analysis and automatic extraction of semantic orientation can be found under different umbrella terms: sentiment analysis (Pang and Lee 2008), subjectivity (Lyons 1981; Langacker 1985), opinion mining (Pang and Lee 2008), analysis of stance (Biber and Finegan 1988; Conrad and Biber 2000), appraisal (Martin and White 2005), point of view (Wiebe 1994; Scheibman 2002), evidentiality (Chafe and Nichols 1986), and a few others, without expanding into neighboring disciplines and the study of emotion (Ketal 1975; Ortony, Clore, and Collins 1988) and affect (Batson, Shaw, and Oleson 1992).","['affect', 'semantic', 'ortony', 'scheibman', 'automatic', 'ketal', 'different', 'white', 'finegan', 'few']","(0, [])","(0, [])"
"Pang, Lee, and Vaithyanathan (2002)","Pang, Lee, and Vaithyanathan (2002) found that their machine-learning classi er performed better when a binary feature was used indicating the presence of a unigram in the text, instead of a numerical feature indicating the number of appearances.","['machinelearning', 'better', 'binary', 'numerical']","(1, ['better'])","(0, [])"
"Pang, Lee, and Vaithyanathan 2002","The text classi cation approach involves building classi ers from labeled instances of texts or sentences (Pang, Lee, and Vaithyanathan 2002), essentially a supervised classi cation task. The majority of the statistical text classi cation research builds Support Vector Machine classi ers, trained on a particular data set using features such as unigrams or bigrams, and with or without part-of-speech labels, although the most successful features seem to be basic unigrams (Pang, Lee, and Vaithyanathan 2002; Salvetti, Reichenbach, and Lewis 2006). The enhanced dictionaries contain 2,252 adjective entries, 1,142 nouns, 903 verbs, and 745 adverbs.6 The SO-carrying words in these dictionaries were taken from a variety of sources, the three largest being Epinions 1, the 400-text corpus described in the previous section; a 100-text subset of the 2,000 movie reviews in the Polarity Dataset (Pang, Lee, and Vaithyanathan 2002; Pang and Lee 2004, 2005);7 and positive and negative words from the General Inquirer dictionary (Stone et al. Lexicon-Based Methods for Sentiment Analysis approaches have emerged: the use of machine-learning classi ers trained on n-grams or similar features (Pang, Lee, and Vaithyanathan 2002), and the use of sentiment dictionaries (Esuli and Sebastiani 2006; Taboada, Anthony, and Voll 2006).","['enhanced', 'previous', 'text', 'machinelearning', 'unigrams', 'labeled', 'successful', 'basic', 'partofspeech', 'positive', 'particular', 'statistical', 'similar', 'adjective', 'negative', 'lexiconbased', 'such', 'socarrying', 'general', 'dictionary', 'supervised', 'nouns', 'support', 'largest']","(4, ['enhanced', 'successful', 'positive', 'support'])","(1, ['negative'])"
Polanyi and Zaenen 2006,Some researchers in sentiment analysis (Kennedy and Inkpen 2006; Polanyi and Zaenen 2006) have implemented 274,[],"(0, [])","(0, [])"
Prabowo and Thelwall 2009,"We tested SO-CAL with four different data sets: the Multi-Perspective Question Answering (MPQA) corpus, version 2.0 (Wiebe, Wilson, and Cardie 2005); a collection of MySpace.com comments from Mike Thelwall (Prabowo and Thelwall 2009); a set of news and blog posts from Alina Andreevskaia (Andreevskaia and Bergler 2008); and a set of headlines from Rada Mihalcea and Carlo Strappavara (Strappavara and Mihalcea 2007).20 The rst set of data is the MPQA corpus (version 2.0), a collection of news articles and other documents (texts from the American National Corpus and other sources) annotated for opinions and other private states (beliefs, emotions, speculation, etc.).","['emotions', 'other', 'alina', 'american', 'corpus', 'socal', 'different', 'national', 'mpqa', 'private', 'multiperspective']","(0, [])","(0, [])"
Read and Carroll (2009),"Read and Carroll (2009), for instance, use semi-supervised methods to build domainindependent polarity classi ers.","['semisupervised', 'domainindependent']","(0, [])","(0, [])"
Riloff and Wiebe 2003,Although some of the machine-learningbased work makes use of linguistic features for training (Riloff and Wiebe 2003; Mullen and Collier 2004; Wiebe et al.,"['machinelearningbased', 'linguistic', 'collier']","(0, [])","(0, [])"
Salton and McGill 1983,"This weighting feature is used in Taboada, Brooke, and 17 One of the reviewers points out that this is similar to the use of term frequency (tf-idf) in information retrieval (Salton and McGill 1983).","['taboada', 'similar', 'weighting']","(0, [])","(0, [])"
"Salvetti, Reichenbach, and Lewis 2006","The majority of the statistical text classi cation research builds Support Vector Machine classi ers, trained on a particular data set using features such as unigrams or bigrams, and with or without part-of-speech labels, although the most successful features seem to be basic unigrams (Pang, Lee, and Vaithyanathan 2002; Salvetti, Reichenbach, and Lewis 2006).","['such', 'particular', 'statistical', 'unigrams', 'successful', 'basic', 'support', 'partofspeech']","(2, ['successful', 'support'])","(0, [])"
Saur 2008,This we may refer to as switch negation (Saur 2008).,['switch'],"(0, [])","(0, [])"
Scheibman 2002,"The analysis and automatic extraction of semantic orientation can be found under different umbrella terms: sentiment analysis (Pang and Lee 2008), subjectivity (Lyons 1981; Langacker 1985), opinion mining (Pang and Lee 2008), analysis of stance (Biber and Finegan 1988; Conrad and Biber 2000), appraisal (Martin and White 2005), point of view (Wiebe 1994; Scheibman 2002), evidentiality (Chafe and Nichols 1986), and a few others, without expanding into neighboring disciplines and the study of emotion (Ketal 1975; Ortony, Clore, and Collins 1988) and affect (Batson, Shaw, and Oleson 1992).","['affect', 'semantic', 'ortony', 'scheibman', 'automatic', 'ketal', 'different', 'white', 'finegan', 'few']","(0, [])","(0, [])"
Schilder 2002,"At the same time, we will investigate different aggregation strategies for the different types of relations in the text (see also Asher, Benamara, and Mathieu [2008, 2009] for preliminary work in this area), and build on existing discourse parsing systems and proposals (Schilder 2002; Soricut and Marcu 2003; Subba and Di Eugenio 2009).","['preliminary', 'same', 'different']","(0, [])","(0, [])"
September 2010,Submission received: 14 December 2009; revised submission received: 22 August 2010; accepted for publication: 28 September 2010.,[],"(0, [])","(0, [])"
Sokolova and Lapalme 2008,"2007); adjectives and verbs (Kim and Hovy 2004); adjective phrases (Whitelaw, Garg, and Argamon 2005); two-word phrases (Turney 2002; Turney and Littman 2003); adjectives, verbs, and adverbs (Subrahmanian and Reforgiato 2008); the exclusive use of verbs (Sokolova and Lapalme 2008); the use of non-affective adjectives and adverbs (Sokolova and Lapalme 2009a, 2009b); or rationales, words and phrases selected by human annotators (Zaidan and Eisner 2008). 2004; Kennedy and Inkpen 2006; Ng, Dasgupta, and Niaz Ari n 2006; Sokolova and Lapalme 2008), it nonetheless still suffers from lack of cross-domain portability.","['twoword', 'adverbs', 'exclusive', 'nonaffective', 'niaz', 'adjective', 'littman', 'argamon', 'subrahmanian', 'human']","(0, [])","(0, [])"
Sokolova and Lapalme 2009,"2007); adjectives and verbs (Kim and Hovy 2004); adjective phrases (Whitelaw, Garg, and Argamon 2005); two-word phrases (Turney 2002; Turney and Littman 2003); adjectives, verbs, and adverbs (Subrahmanian and Reforgiato 2008); the exclusive use of verbs (Sokolova and Lapalme 2008); the use of non-affective adjectives and adverbs (Sokolova and Lapalme 2009a, 2009b); or rationales, words and phrases selected by human annotators (Zaidan and Eisner 2008).","['twoword', 'adverbs', 'exclusive', 'nonaffective', 'adjective', 'littman', 'argamon', 'subrahmanian', 'human']","(0, [])","(0, [])"
Soricut and Marcu 2003,"At the same time, we will investigate different aggregation strategies for the different types of relations in the text (see also Asher, Benamara, and Mathieu [2008, 2009] for preliminary work in this area), and build on existing discourse parsing systems and proposals (Schilder 2002; Soricut and Marcu 2003; Subba and Di Eugenio 2009).","['preliminary', 'same', 'different']","(0, [])","(0, [])"
Stone 1997,"1966; Stone 1997).8 The sources provide a fairly good range in terms of register: The Epinions and movie reviews represent informal language, with words such as ass-kicking and nifty; at the other end of the spectrum, the General Inquirer was clearly built from much more formal texts, and contributed words such as adroit and jubilant, which may be more useful in the processing of literary reviews (Taboada, Gillies, and McFetridge 2006; Taboada et al.","['more', 'literary', 'such', 'good', 'general', 'other', 'useful', 'asskicking', 'formal', 'informal']","(2, ['good', 'useful'])","(0, [])"
Strappavara and Mihalcea 2007,"We tested SO-CAL with four different data sets: the Multi-Perspective Question Answering (MPQA) corpus, version 2.0 (Wiebe, Wilson, and Cardie 2005); a collection of MySpace.com comments from Mike Thelwall (Prabowo and Thelwall 2009); a set of news and blog posts from Alina Andreevskaia (Andreevskaia and Bergler 2008); and a set of headlines from Rada Mihalcea and Carlo Strappavara (Strappavara and Mihalcea 2007).20 The rst set of data is the MPQA corpus (version 2.0), a collection of news articles and other documents (texts from the American National Corpus and other sources) annotated for opinions and other private states (beliefs, emotions, speculation, etc.).","['emotions', 'other', 'alina', 'american', 'corpus', 'socal', 'different', 'national', 'mpqa', 'private', 'multiperspective']","(0, [])","(0, [])"
Subba and Di Eugenio 2009,"At the same time, we will investigate different aggregation strategies for the different types of relations in the text (see also Asher, Benamara, and Mathieu [2008, 2009] for preliminary work in this area), and build on existing discourse parsing systems and proposals (Schilder 2002; Soricut and Marcu 2003; Subba and Di Eugenio 2009).","['preliminary', 'same', 'different']","(0, [])","(0, [])"
Subrahmanian and Reforgiato 2008,"2007); adjectives and verbs (Kim and Hovy 2004); adjective phrases (Whitelaw, Garg, and Argamon 2005); two-word phrases (Turney 2002; Turney and Littman 2003); adjectives, verbs, and adverbs (Subrahmanian and Reforgiato 2008); the exclusive use of verbs (Sokolova and Lapalme 2008); the use of non-affective adjectives and adverbs (Sokolova and Lapalme 2009a, 2009b); or rationales, words and phrases selected by human annotators (Zaidan and Eisner 2008).","['twoword', 'adverbs', 'exclusive', 'nonaffective', 'adjective', 'littman', 'argamon', 'subrahmanian', 'human']","(0, [])","(0, [])"
Taboada and Grieve (2004),"To build the system and run our experiments, we use the corpus described in Taboada and Grieve (2004) and Taboada, Anthony, and Voll (2006), which consists of a 400-text collection of Epinions reviews extracted from eight different categories: books, cars, computers, cookware, hotels, movies, music, and phones, a corpus we named Epinions 1. Taboada and Grieve (2004) improved performance of an earlier version of the SO calculator by assigning the most weight at the two-thirds mark of a text, and signi cantly less at the beginning.","['less', 'different', 'earlier', 'twothirds', 'most', 'text']","(0, [])","(0, [])"
Taboada and Grieve 2004,"Previous versions of SO-CAL (Taboada and Grieve 2004; Taboada, Anthony, and Voll 2006) relied on an adjective dictionary to predict the overall SO of a document, using a simple aggregate-and-average method: The individual scores for each adjective in a document are added together and then divided by the total number of adjectives in that document.4 As we describe subsequently, the current version of SO-CAL takes other parts of speech into account, and makes use of more sophisticated methods to determine the true contribution of each word. 2.8 Evaluation of Features To test the performance of all of SO-CAL s features, we used the following data sets: Epinions 1: Our original collection of 400 review texts (Taboada and Grieve 2004), used in various phases of development.","['simple', 'individual', 'account', 'true', 'current', 'other', 'various', 'total', 'previous', 'following', 'adjective', 'socal', 'sophisticated', 'overall', 'original']","(1, ['sophisticated'])","(0, [])"
"Taboada, Anthony, and Voll 2006","Much of the lexicon-based research has focused on using adjectives as indicators of the semantic orientation of text (Hatzivassiloglou and McKeown 1997; Wiebe 2000; Hu and Liu 2004; Taboada, Anthony, and Voll 2006).2 First, a list of adjectives and corresponding SO values is compiled into a dictionary. 2.1 Adjectives Much of the early research in sentiment focused on adjectives or adjective phrases as the primary source of subjective content in a document (Hatzivassiloglou and McKeown 1997; Hu and Liu 2004; Taboada, Anthony, and Voll 2006), albeit with some exceptions, especially more recently, which have also included the use of adverbs (Benamara et al. Previous versions of SO-CAL (Taboada and Grieve 2004; Taboada, Anthony, and Voll 2006) relied on an adjective dictionary to predict the overall SO of a document, using a simple aggregate-and-average method: The individual scores for each adjective in a document are added together and then divided by the total number of adjectives in that document.4 As we describe subsequently, the current version of SO-CAL takes other parts of speech into account, and makes use of more sophisticated methods to determine the true contribution of each word. Our rst comparison is with the dictionary of adjectives that was derived using the SO-PMI method (Turney 2002), using Google hit counts (Taboada, Anthony, and Voll 2006). We have already discussed the Google dictionary, which contains only adjectives, and whose results are not reliable (see also Taboada, Anthony, and Voll 2006). Lexicon-Based Methods for Sentiment Analysis approaches have emerged: the use of machine-learning classi ers trained on n-grams or similar features (Pang, Lee, and Vaithyanathan 2002), and the use of sentiment dictionaries (Esuli and Sebastiani 2006; Taboada, Anthony, and Voll 2006).","['account', 'previous', 'socal', 'overall', 'machinelearning', 'current', 'sopmi', 'recently', 'sophisticated', 'semantic', 'other', 'similar', 'primary', 'taboada', 'adjective', 'reliable', 'simple', 'individual', 'lexiconbased', 'true', 'dictionary', 'total', 'subjective', 'adjectives', 'early']","(2, ['sophisticated', 'reliable'])","(0, [])"
"Taboada, Brooke, and Stede 2009","In general, there is signi cantly less positive bias in the movie review domain, most likely due to the use of negative terms in plot and character description (Taboada, Brooke, and Stede 2009), thus the negative weighting that is appropriate for other domains is often excessive for movie reviews. The main conclusion of our work is that lexicon-based methods for sentiment analysis are robust, result in good cross-domain performance, and can be easily enhanced with multiple sources of knowledge (Taboada, Brooke, and Stede 2009).","['lexiconbased', 'positive', 'good', 'likely', 'multiple', 'other', 'signi', 'due', 'appropriate', 'main', 'excessive', 'negative', 'robust']","(4, ['positive', 'good', 'appropriate', 'robust'])","(2, ['excessive', 'negative'])"
"Taboada, Gillies, and McFetridge 2006","1966; Stone 1997).8 The sources provide a fairly good range in terms of register: The Epinions and movie reviews represent informal language, with words such as ass-kicking and nifty; at the other end of the spectrum, the General Inquirer was clearly built from much more formal texts, and contributed words such as adroit and jubilant, which may be more useful in the processing of literary reviews (Taboada, Gillies, and McFetridge 2006; Taboada et al.","['more', 'literary', 'such', 'good', 'general', 'other', 'useful', 'asskicking', 'formal', 'informal']","(2, ['good', 'useful'])","(0, [])"
Tong 2001,"1966; Tong 2001), or automatically, using seed words to expand the list of words (Hatzivassiloglou and McKeown 1997; Turney 2002; Turney and Littman 2003).",['tong'],"(0, [])","(0, [])"
Turney (2002),"2 With some exceptions: Turney (2002) uses two-word phrases; Whitelaw, Garg, and Argamon (2005) adjective phrases; and Benamara et al. 5 Something that Turney (2002) already partially addressed, by extracting two-word phrases.","['argamon', 'twoword', 'adjective', 'exceptions']","(0, [])","(0, [])"
Turney 2002,"There exist two main approaches to the problem of extracting sentiment automatically.1 The lexicon-based approach involves calculating orientation for a document from the semantic orientation of words or phrases in the document (Turney 2002). 1966; Tong 2001), or automatically, using seed words to expand the list of words (Hatzivassiloglou and McKeown 1997; Turney 2002; Turney and Littman 2003). 2007); adjectives and verbs (Kim and Hovy 2004); adjective phrases (Whitelaw, Garg, and Argamon 2005); two-word phrases (Turney 2002; Turney and Littman 2003); adjectives, verbs, and adverbs (Subrahmanian and Reforgiato 2008); the exclusive use of verbs (Sokolova and Lapalme 2008); the use of non-affective adjectives and adverbs (Sokolova and Lapalme 2009a, 2009b); or rationales, words and phrases selected by human annotators (Zaidan and Eisner 2008). The association is usually calculated following Turney s method for computing mutual information (Turney 2002; Turney and Littman 2003), but see also Rao and Ravichandran (2009) and Velikovich et al. As noted already by Boucher and Osgood (1969), there is a strong preference for avoiding negation and negative terms even when expressing negative opinions, making the detection of text sentiment dif cult for systems which depend solely on these indicators (also see results in Dave, Lawrence, and Pennock 2003, Turney 2002). Our rst comparison is with the dictionary of adjectives that was derived using the SO-PMI method (Turney 2002), using Google hit counts (Taboada, Anthony, and Voll 2006).","['adverbs', 'text', 'sopmi', 'semantic', 'exclusive', 'nonaffective', 'tong', 'taboada', 'main', 'adjective', 'littman', 'velikovich', 'negative', 'argamon', 'lexiconbased', 'twoword', 'strong', 'dave', 'mutual', 'subrahmanian', 'human']","(1, ['strong'])","(1, ['negative'])"
Turney and Littman 2003,"1966; Tong 2001), or automatically, using seed words to expand the list of words (Hatzivassiloglou and McKeown 1997; Turney 2002; Turney and Littman 2003). 2007); adjectives and verbs (Kim and Hovy 2004); adjective phrases (Whitelaw, Garg, and Argamon 2005); two-word phrases (Turney 2002; Turney and Littman 2003); adjectives, verbs, and adverbs (Subrahmanian and Reforgiato 2008); the exclusive use of verbs (Sokolova and Lapalme 2008); the use of non-affective adjectives and adverbs (Sokolova and Lapalme 2009a, 2009b); or rationales, words and phrases selected by human annotators (Zaidan and Eisner 2008). The association is usually calculated following Turney s method for computing mutual information (Turney 2002; Turney and Littman 2003), but see also Rao and Ravichandran (2009) and Velikovich et al.","['twoword', 'adverbs', 'exclusive', 'nonaffective', 'tong', 'adjective', 'mutual', 'littman', 'velikovich', 'argamon', 'subrahmanian', 'human']","(0, [])","(0, [])"
Voll and Taboada 2007,"In previous work (Voll and Taboada 2007), we showed a prototype for extracting topic sentences, and performing sentiment analysis on those only.",['previous'],"(0, [])","(0, [])"
Wan (2009),Wan (2009) uses co-training in a method that uses English labeled data and an English classi er to learn a classi er for Chinese.,['english'],"(0, [])","(0, [])"
"Whitelaw, Garg, and Argamon (2005)","2 With some exceptions: Turney (2002) uses two-word phrases; Whitelaw, Garg, and Argamon (2005) adjective phrases; and Benamara et al. Fletcher and Patrick (2005) used bags-of-words that included Appraisal features, and obtained 83.7% accuracy in that same data set, whereas Whitelaw, Garg, and Argamon (2005), using bags-of-words combined with Appraisal groups achieved 90.2%.","['twoword', 'exceptions', 'adjective', 'appraisal', 'argamon', 'same', 'whitelaw']","(0, [])","(0, [])"
"Whitelaw, Garg, and Argamon 2005","2007); adjectives and verbs (Kim and Hovy 2004); adjective phrases (Whitelaw, Garg, and Argamon 2005); two-word phrases (Turney 2002; Turney and Littman 2003); adjectives, verbs, and adverbs (Subrahmanian and Reforgiato 2008); the exclusive use of verbs (Sokolova and Lapalme 2008); the use of non-affective adjectives and adverbs (Sokolova and Lapalme 2009a, 2009b); or rationales, words and phrases selected by human annotators (Zaidan and Eisner 2008). 2009), and some work relies on Appraisal Theory (Whitelaw, Garg, and Argamon 2005; Bloom, Garg, and Argamon 2007), a theory developed by Martin and White (2005).","['twoword', 'adverbs', 'exclusive', 'nonaffective', 'adjective', 'littman', 'white', 'argamon', 'subrahmanian', 'human']","(0, [])","(0, [])"
Wiebe 1994,"The analysis and automatic extraction of semantic orientation can be found under different umbrella terms: sentiment analysis (Pang and Lee 2008), subjectivity (Lyons 1981; Langacker 1985), opinion mining (Pang and Lee 2008), analysis of stance (Biber and Finegan 1988; Conrad and Biber 2000), appraisal (Martin and White 2005), point of view (Wiebe 1994; Scheibman 2002), evidentiality (Chafe and Nichols 1986), and a few others, without expanding into neighboring disciplines and the study of emotion (Ketal 1975; Ortony, Clore, and Collins 1988) and affect (Batson, Shaw, and Oleson 1992).","['affect', 'semantic', 'ortony', 'scheibman', 'automatic', 'ketal', 'different', 'white', 'finegan', 'few']","(0, [])","(0, [])"
Wiebe 2000,"Much of the lexicon-based research has focused on using adjectives as indicators of the semantic orientation of text (Hatzivassiloglou and McKeown 1997; Wiebe 2000; Hu and Liu 2004; Taboada, Anthony, and Voll 2006).2 First, a list of adjectives and corresponding SO values is compiled into a dictionary. Several lexiconbased approaches have adopted these assumptions (Bruce and Wiebe 2000; Hu and Liu 2004; Kim and Hovy 2004).","['semantic', 'lexiconbased', 'dictionary', 'several']","(0, [])","(0, [])"
"Wiebe, Wilson, and Cardie 2005","We tested SO-CAL with four different data sets: the Multi-Perspective Question Answering (MPQA) corpus, version 2.0 (Wiebe, Wilson, and Cardie 2005); a collection of MySpace.com comments from Mike Thelwall (Prabowo and Thelwall 2009); a set of news and blog posts from Alina Andreevskaia (Andreevskaia and Bergler 2008); and a set of headlines from Rada Mihalcea and Carlo Strappavara (Strappavara and Mihalcea 2007).20 The rst set of data is the MPQA corpus (version 2.0), a collection of news articles and other documents (texts from the American National Corpus and other sources) annotated for opinions and other private states (beliefs, emotions, speculation, etc.).","['emotions', 'other', 'alina', 'american', 'corpus', 'socal', 'different', 'national', 'mpqa', 'private', 'multiperspective']","(0, [])","(0, [])"
"Wilson, Wiebe, and Hoffmann (2005)","Wilson, Wiebe, and Hoffmann (2005) provide a list of subjectivity cues with over 8,000 entries; there are many more neutral, repeated, and in ectionally related entries than in our dictionaries, however, as well as many more nouns, and far fewer adjectives. Our next comparison is with the Subjectivity dictionary of Wilson, Wiebe, and Hoffmann (2005). The Subjectivity dictionary is the collection of subjective expressions compiled by Wilson, Wiebe, and Hoffmann (2005), also used in our Mechanical Turk experiments in the previous section.","['more', 'mechanical', 'next', 'many', 'fewer', 'previous', 'subjective', 'neutral', 'related']","(0, [])","(0, [])"
"Wilson, Wiebe, and Hwa 2004","MT correspondence of 30 Distinguishing neutral and polar terms, sentences, or texts is, in general, a hard problem (Wilson, Wiebe, and Hwa 2004; Pang and Lee 2005).","['neutral', 'hard', 'polar']","(0, [])","(1, ['hard'])"
"Yano, Resnik, and Smith 2010","2010; Mohammad and Turney 2010; Yano, Resnik, and Smith 2010), although there are mixed reports on its reliability (Snow et al.",['mixed'],"(0, [])","(0, [])"
Zaidan and Eisner 2008,"2007); adjectives and verbs (Kim and Hovy 2004); adjective phrases (Whitelaw, Garg, and Argamon 2005); two-word phrases (Turney 2002; Turney and Littman 2003); adjectives, verbs, and adverbs (Subrahmanian and Reforgiato 2008); the exclusive use of verbs (Sokolova and Lapalme 2008); the use of non-affective adjectives and adverbs (Sokolova and Lapalme 2009a, 2009b); or rationales, words and phrases selected by human annotators (Zaidan and Eisner 2008).","['twoword', 'adverbs', 'exclusive', 'nonaffective', 'adjective', 'littman', 'argamon', 'subrahmanian', 'human']","(0, [])","(0, [])"
Zwarts 1995,"NPIs occur in negative sentences, but also in nonveridical contexts (Zwarts 1995; Giannakidou 1998), which also affect semantic orientation.","['semantic', 'npis', 'nonveridical', 'negative']","(0, [])","(1, ['negative'])"
also Paltoglou and Thelwall (2010),See also Paltoglou and Thelwall (2010) for a use of information retrieval techniques in sentiment analysis.,[],"(0, [])","(0, [])"
also Rao and Ravichandran (2009),"The association is usually calculated following Turney s method for computing mutual information (Turney 2002; Turney and Littman 2003), but see also Rao and Ravichandran (2009) and Velikovich et al.","['mutual', 'littman', 'velikovich']","(0, [])","(0, [])"
"also Taboada, Anthony, and Voll 2006","We have already discussed the Google dictionary, which contains only adjectives, and whose results are not reliable (see also Taboada, Anthony, and Voll 2006).","['taboada', 'reliable', 'adjectives']","(1, ['reliable'])","(0, [])"
and Pang and Lee (2005),"Notable exceptions include Koppel and Schler (2005) and Pang and Lee (2005), who each adapted relevant SVM machinelearning algorithms to sentiment classi cation with a threeand four-class system, respectively.","['classi', 'lee', 'notable', 'relevant']","(0, [])","(0, [])"
"and Taboada, Anthony, and Voll (2006)","To build the system and run our experiments, we use the corpus described in Taboada and Grieve (2004) and Taboada, Anthony, and Voll (2006), which consists of a 400-text collection of Epinions reviews extracted from eight different categories: books, cars, computers, cookware, hotels, movies, music, and phones, a corpus we named Epinions 1.","['different', 'text']","(0, [])","(0, [])"
as Turney (2006),"An alternative would be to use a suf ciently large static corpus, as Turney (2006) does to measure relational similarity across word pairs.","['large', 'static', 'relational']","(0, [])","(1, ['static'])"
but Brooke (2009),"Space precludes a full discussion of SO-CAL s measure of strength, but Brooke (2009) shows that SO-CAL s output correlates well with star ratings in reviews.","['socal', 'full']","(0, [])","(0, [])"
by Boucher and Osgood (1969),"As noted already by Boucher and Osgood (1969), there is a strong preference for avoiding negation and negative terms even when expressing negative opinions, making the detection of text sentiment dif cult for systems which depend solely on these indicators (also see results in Dave, Lawrence, and Pennock 2003, Turney 2002).","['text', 'strong', 'dave', 'negative']","(1, ['strong'])","(1, ['negative'])"
by Horn (1989),"Polarity shifts seem to better re ect the pragmatic reality of negation, and is supported by Horn (1989), who suggests that af rmative and negative sentences are not symmetrical.","['horn', 'symmetrical', 'negative', 'better', 'pragmatic']","(1, ['better'])","(1, ['negative'])"
by Kennedy and Inkpen (2006),"Research by Kennedy and Inkpen (2006) concentrated on implementing those insights. A related problem for the polarity ip model, as noted by Kennedy and Inkpen (2006), is that negative polarity items interact with intensi ers in undesirable ways. SO-CAL options Percent correct by corpus All words (nouns, verbs, adjectives, adverbs) All words + negation (shift) All words + neg (shift) + intensi cation All words + neg (shift) + int + irrealis blocking All words + neg (shift) + int + irrealis + neg w All words + neg (shift) + int + modals + neg w + rep w All words + neg (switch) + int + modals + neg w + rep w Epinions 1 Epinions 2 Movie Camera Overall 65.50 67.75 69.25 71.00 81.50* 80.25 65.25 67.25 71.50 71.25 68.05 64.70 66.04 70.10 73.47* 67.25* 70.00* 68.35* 71.35* 74.95 71.37 72.66* 78.25* 75.08 78.24* 77.32* 80.00 76.37 80.16* 78.74* 80.00 80.00 75.57 80.04 78.37 *Statistically signi cant compared to the preceding set of options (Table 4) p < 0.05. intensi cation, as also shown by Kennedy and Inkpen (2006).","['intensi', 'ways', 'inkpen', 'table', 'interact', 'signi', 'socal', 'neg', 'negative', 'undesirable', 'related', 'overall']","(0, [])","(2, ['negative', 'undesirable'])"
by Martin and White (2005),"2009), and some work relies on Appraisal Theory (Whitelaw, Garg, and Argamon 2005; Bloom, Garg, and Argamon 2007), a theory developed by Martin and White (2005).","['white', 'argamon']","(0, [])","(0, [])"
by Soricut and Marcu (2003),"We also showed how a sentence-level discourse parser, developed by Soricut and Marcu (2003), could be used to differentiate between main and secondary parts of the text.","['sentencelevel', 'main', 'secondary']","(0, [])","(0, [])"
"by Wilson, Wiebe, and Hoffmann (2005)","The Subjectivity dictionary is the collection of subjective expressions compiled by Wilson, Wiebe, and Hoffmann (2005), also used in our Mechanical Turk experiments in the previous section.","['previous', 'subjective', 'mechanical']","(0, [])","(0, [])"
"evaluation, Strappavara and Mihalcea (2007)","In addition to the full evaluation, Strappavara and Mihalcea (2007) also propose a coarse evaluation, where headlines with scores 100 to 50 are classi ed as negative, and those 50 to 100 as positive.","['classi', 'full']","(0, [])","(0, [])"
following Polanyi and Zaenen (2006),"These results indicate a clear bene t The Simple dictionary is a version of our main dictionary that has been simpli ed to 2/ 2 values, switch negation, and 1/ 1 intensi cation, following Polanyi and Zaenen (2006).","['simple', 'intensi', 'simpli', 'main', 'clear']","(1, ['clear'])","(0, [])"
for Sentiment Analysis Stede (2009),"Lexicon-Based Methods for Sentiment Analysis Stede (2009) to lower the weight of descriptive paragraphs, as opposed to paragraphs that contain mostly commentary.","['descriptive', 'lexiconbased']","(0, [])","(0, [])"
for Sentiment Analysis and Hovy 2004,Lexicon-Based Methods for Sentiment Analysis and Hovy 2004; Esuli and Sebastiani 2006).,['lexiconbased'],"(0, [])","(0, [])"
from Polanyi and Zaenen (2006),"2.2 Nouns, Verbs, and Adverbs In the following example, adapted from Polanyi and Zaenen (2006), we see that lexical items other than adjectives can carry important semantic polarity information.","['semantic', 'other', 'following', 'important', 'nouns', 'lexical']","(1, ['important'])","(0, [])"
"in Bloom, Garg, and Argamon (2007)","Movie: 1,900 texts from the Polarity Dataset (Pang and Lee 2004).18 Camera: A 2,400-text corpus of camera, printer, and stroller reviews, taken from a larger set of Epinions reviews; also used in Bloom, Garg, and Argamon (2007).","['larger', 'text', 'bloom']","(1, ['bloom'])","(0, [])"
in Brooke (2009),"This allows SO-CAL to identify, for instance, the star rating that would be assigned to a consumer review, as shown in Brooke (2009).",['socal'],"(0, [])","(0, [])"
"in Dave, Lawrence, and Pennock 2003","As noted already by Boucher and Osgood (1969), there is a strong preference for avoiding negation and negative terms even when expressing negative opinions, making the detection of text sentiment dif cult for systems which depend solely on these indicators (also see results in Dave, Lawrence, and Pennock 2003, Turney 2002).","['text', 'strong', 'dave', 'negative']","(1, ['strong'])","(1, ['negative'])"
in Taboada and Grieve (2004),"To build the system and run our experiments, we use the corpus described in Taboada and Grieve (2004) and Taboada, Anthony, and Voll (2006), which consists of a 400-text collection of Epinions reviews extracted from eight different categories: books, cars, computers, cookware, hotels, movies, music, and phones, a corpus we named Epinions 1.","['different', 'text']","(0, [])","(0, [])"
"in Taboada, Anthony, and Voll (2006)","The rst dictionary that we incorporated into SO-CAL was the Google-generated PMI-based dictionary described in Taboada, Anthony, and Voll (2006), and mentioned earlier in this article.","['rst', 'dictionary', 'taboada', 'socal', 'googlegenerated', 'pmibased']","(0, [])","(0, [])"
include Koppel and Schler (2005),"Notable exceptions include Koppel and Schler (2005) and Pang and Lee (2005), who each adapted relevant SVM machinelearning algorithms to sentiment classi cation with a threeand four-class system, respectively.","['classi', 'lee', 'notable', 'relevant']","(0, [])","(0, [])"
"instance, Choi and Cardie (2008)","For instance, Choi and Cardie (2008) present a classi er that treats negation from a compositional point of view by rst calculating polarity of terms independently, and then applying inference rules to arrive at a combined polarity score.","['instance', 'rst', 'compositional', 'combined']","(0, [])","(0, [])"
"loski, and Taboada 2009","Comparing the performance of various dictionaries with or without SO-CAL features, two facts are apparent: First, SO-CAL features are generally bene cial no matter what dictionary is used (in fact, all Overall improvements from Basic to Full in Table 10 are statistically signi cant); the only exceptions are due to negative weighting in the movie domain, which for most of the dictionaries causes a drop in performance.35 Second, the bene t provided by SO-CAL seems to be somewhat dependent on the reliability of the dictionary; in general, automatically derived SO dictionaries derive less bene t from the use of linguistic features, and the effects are, on the whole, much less consistent; this is in fact the same conclusion we reached in other work where we compared automatically translated dictionaries to manually built ones for Spanish (Brooke, To loski, and Taboada 2009). In related work, we have also shown that creating a new version of SO-CAL for a new language, Spanish, is as fast as building text classi ers for the new language, and results in better performance (Brooke 2009; Brooke, To loski, and Taboada 2009).","['less', 'related', 'fast', 'consistent', 'spanish', 'table', 'due', 'dictionaries', 'bene', 'socal', 'overall', 'various', 'basic', 'most', 'new', 'apparent', 'other', 'same', 'negative', 'linguistic', 'only', 'translated', 'signi', 'dependent', 'first', 'better', 'full', 'cial']","(3, ['fast', 'consistent', 'better'])","(1, ['negative'])"
of Andreevskaia and Bergler (2008),"Other hybrid methods include those of Andreevskaia and Bergler (2008), Dang, Zhang, and Chen (2010), Dasgupta and Ng (2009), Goldberg and Zhu (2006), or Prabowo and Thelwall (2009). The gures in the rst section of Table 7 suggest robust performance as compared to a mostfrequent-class baseline, including modest improvement over the relevant cross-domain results of Andreevskaia and Bergler (2008).22 Moilanen, Pulman, and Zhang (2010) also use the headlines data, and obtain a polarity classi cation accuracy of 77.94% below our results excluding empty.23 21 By default, SO-CAL assigns a zero to such texts, which is usually interpreted to mean that the text is neither positive nor negative.","['empty', 'such', 'positive', 'other', 'rst', 'table', 'mostfrequentclass', 'crossdomain', 'negative', 'socal', 'modest', 'robust', 'suggest', 'default', 'hybrid', 'relevant']","(3, ['positive', 'modest', 'robust'])","(1, ['negative'])"
of Polanyi and Zaenen (2006),"Other Related Work The SO-CAL improvements described in this article have been directly inspired by the work of Polanyi and Zaenen (2006), who proposed that valence shifters change the base value of a word.","['other', 'socal', 'related']","(0, [])","(0, [])"
of Wiebe and Riloff (2005),"The bulk of the work in sentiment analysis has focused on classi cation at either the sentence level, for example, the subjectivity/polarity detection of Wiebe and Riloff (2005), or alternatively at the level of the entire text.",['entire'],"(0, [])","(0, [])"
"of Wilson, Wiebe, and Hoffmann (2005)","Our next comparison is with the Subjectivity dictionary of Wilson, Wiebe, and Hoffmann (2005).",['next'],"(0, [])","(0, [])"
or Moilanen and Pulman (2007),"When they occur in a sentence, aggregation with other sentiment words in the sentence would probably yield a result similar to the compositional approach of Choi and Cardie or Moilanen and Pulman (2007).","['other', 'compositional', 'similar', 'sentence']","(0, [])","(0, [])"
or Prabowo and Thelwall (2009),"Other hybrid methods include those of Andreevskaia and Bergler (2008), Dang, Zhang, and Chen (2010), Dasgupta and Ng (2009), Goldberg and Zhu (2006), or Prabowo and Thelwall (2009).","['other', 'hybrid']","(0, [])","(0, [])"
"problem, Voll and Taboada (2007)","2.6 Text-Level Features Lexicon-based sentiment classi ers generally show a positive bias (Kennedy and Inkpen 2006), likely the result of a universal human tendency to favor positive language (Boucher and Osgood 1969).16 In order to overcome this problem, Voll and Taboada (2007) implemented normalization, shifting the numerical cut-off point between positive and negative reviews.","['universal', 'lexiconbased', 'positive', 'textlevel', 'numerical', 'negative', 'human']","(1, ['positive'])","(1, ['negative'])"
see Brooke (2009),"Space considerations preclude a full discussion of the contribution of each part of speech and sub-feature, but see Brooke (2009) for a full range of tests using these data.","['subfeature', 'brooke', 'full']","(0, [])","(0, [])"
su (2010),"26 This is the opposite result from the impressions reported by Cabral and Hortac su (2010), where, in an evaluation of comments for eBay sellers, neutral comments were perceived as close to negative.","['sellers', 'ebay', 'hortac', 'opposite', 'neutral', 'cabral']","(0, [])","(0, [])"
that Kilgarriff (2007),"When rerun, the results for each word were subject to change, sometimes by extreme amounts, something that Kilgarriff (2007) also notes, arguing against the use of Google for linguistic research of this type.","['linguistic', 'extreme', 'subject']","(0, [])","(0, [])"
that Polanyi and Zaenen (2006),"On reading any document, it becomes apparent that aspects of the local context of a word need to be taken into account in SO assessment, such as negation (e.g., not good) and intensi cation (e.g., very good), aspects that Polanyi and Zaenen (2006) named contextual valence shifters.","['intensi', 'apparent', 'such', 'good', 'local', 'contextual', 'assessment']","(1, ['good'])","(0, [])"
that Turney (2002),"5 Something that Turney (2002) already partially addressed, by extracting two-word phrases.",['twoword'],"(0, [])","(0, [])"
the 2007,The Affective Text data from Rada Mihalcea and Carlo Strappavara was used in the 2007 SemEval task.,['affective'],"(0, [])","(0, [])"
"the Semantic Orientation CALculator Following Osgood, Suci, and Tannenbaum (1957)","SO-CAL, the Semantic Orientation CALculator Following Osgood, Suci, and Tannenbaum (1957), the calculation of sentiment in SO-CAL begins with two assumptions: that individual words have what is referred to as prior polarity, that is, a semantic orientation that is independent of context; and that said semantic orientation can be expressed as a numerical value.","['individual', 'semantic', 'prior', 'independent', 'socal', 'osgood', 'numerical']","(0, [])","(0, [])"
what Choi and Cardie (2008),"Similarly, negation calculation does not include what Choi and Cardie (2008) term content word negators, words such as eliminate.","['such', 'similarly']","(0, [])","(0, [])"
"whereas Whitelaw, Garg, and Argamon (2005)","Fletcher and Patrick (2005) used bags-of-words that included Appraisal features, and obtained 83.7% accuracy in that same data set, whereas Whitelaw, Garg, and Argamon (2005), using bags-of-words combined with Appraisal groups achieved 90.2%.","['argamon', 'same', 'whitelaw', 'appraisal']","(0, [])","(0, [])"
which Brooke (2009),"Lexicon-Based Methods for Sentiment Analysis a different domain (Aue and Gamon [2005]; see also the discussion about domain speci city in Pang and Lee [2008, section 4.4]).3 Consider, for example, an experiment using the Polarity Dataset, a corpus containing 2,000 movie reviews, in which Brooke (2009) extracted the 100 most positive and negative unigram features from an SVM classi er that reached 85.1% accuracy.","['lexiconbased', 'positive', 'speci', 'gamon', 'unigram', 'different', 'negative', 'lee']","(1, ['positive'])","(1, ['negative'])"
Author Objectives N-gram Gamon (2004),"Author Objectives N-gram Gamon (2004) Assign docs sentiments using 4-point scale Model SVM Pang and Lee (2005) Assign docs sentiments using 3or 4-point scale SVM, regression, metric labeling Movie reviews Choi et al.","['point', 'metric', 'gamon', 'ngram', 'lee']","(0, [])","(0, [])"
"Cochran, 1954","Otherwise, it tends to underestimate small probabilities, which incorrectly results in accepting H1 (Cochran, 1954).",['small'],"(0, [])","(0, [])"
"Cohen, 1995","In contrast, ID3 (Quinlan, 1986) and RIPPER (Cohen, 1995) focus on reducing an initial large set of rules to improve the ef ciency of a rule-based classi er by sacri cing a degree of effectiveness if necessary. We also examined the effectiveness of two induction algorithms, ID3 (Quinlan, 1986) and RIPPER (Cohen, 1995). Induction rule-based classi er (IRBC) Given the two rule sets generated by the rule-based classi er (RBC) and Statistics Based Classi er (SBC), we applied two existing induction algorithms, ID3 (Quinlan, 1986) and RIPPER (Cohen, 1995) provided by Weka (Witten, & Frank, 2005), to generate two induced rule sets, and built a classi er that could use the two induced rule sets to classify a document collection.","['induced', 'rulebased', 'large', 'initial', 'contrast', 'ripper']","(0, [])","(0, [])"
"Dave, Lawrence, and Pennock (2003)","Dave, Lawrence, and Pennock (2003) Assign docs sentiments Uni-, biand trigrams Scoring, smoothing, NB, ME, SVM Product reviews Hiroshi et al.","['smoothing', 'uni', 'hiroshi', 'svm']","(0, [])","(0, [])"
"Dubitzky, 1997","In the case where the number of rules required is large, the process of acquiring and de ning rules can be laborious and unreliable (Dubitzky, 1997).","['large', 'laborious', 'unreliable']","(0, [])","(1, ['unreliable'])"
"Dunning, 1993","Log likelihood ratio (Dunning, 1993) follows the (cid:2)2 hypothesis, i.e., the larger a log likelihood ratio value, the stronger the evidence to reject the null hypothesis, which means that word and antecedent are dependent on each other.","['larger', 'cid', 'dependent', 'stronger']","(1, ['stronger'])","(0, [])"
"Hatzivassiloglou & McKeown, 1997","Existing work in sentiment analysis Whilst most researchers focus on assigning sentiments to documents, others focus on more speci c tasks: nding the sentiments of words (Hatzivassiloglou & McKeown, 1997), subjective expressions (Kim & Hovy, 2004; Wilson, Wiebe, & Hoffmann, 2005), subjective sentences (Pang & Lee, 2004) and topics (Hiroshi, Tetsuya, & Hideo, 2004; Nasukawa & Yi, 2003; Yi, Nasukawa, Niblack, & Bunescu, 2003).","['more', 'subjective', 'most', 'speci']","(0, [])","(0, [])"
Hatzivassiloglou and McKeown (1997),"method Data set Tr Te Accuracy Precision Recall N/A 36,796 4084 77.5 N/A N/A F 1 N/A Customer feedback Ten-fold cross validation (1 vs 4) Ten-fold cross validation (1, 2 vs 3, 4) Ten-fold cross validation (3 point scale) Ten-fold cross validation (4-point scale) Ten-fold cross validation N/A 36,796 4084 69.5 N/A N/A N/A 5006 N/A N/A 66.3 N/A N/A N/A 5006 N/A N/A 54.6 N/A N/A N/A N/A 135 400 N/A 70.2 82.4 41.9 60.6 59.2 69.4 Ten-fold cross validation: polar/neutral Ten-fold cross validation: +/ /both/neutral 13,183 expressions 13,183 expressions N/A N/A 73.6 75.9 68.6 72.2/ 74.0 77.7 45.3 56.8/ 85.7 89.9 55.7 63.4/ 80.7 82.1 N/A N/A 61.7 65.7 1000( ) N/A 30,000 10,000 >91 <72 657adj(+) N/A N/A 78.1 92.4 N/A 55.3 63.4/ 64.7 72.9/ 28.4 35.2/ 50.1 52.4 N/A 59.3 69.4/ 80.4 83.9/ 9.2 11.2/ 30.2 41.4 N/A 61.2 65.1/ 73.1 77.2/ 14.6 16.1/ 37.7 46.2 N/A N/A N/A N/A N/A N/A K nig and Brill (2006) Assign docs sentiments Pattern-based, SVM, hybrid Movie reviews Five-fold cross validation 1000(+) N/A N/A Hatzivassiloglou and McKeown (1997) Assign adjectives +/ N/A Nonhierarchical clustering NB, ME, SVM Customer feedback WSJ corpus Five-fold cross validation N/A Movie reviews Three-fold cross validation Uniand bigrams Pang, Lee, and Vaithyanathan (2002) Turney (2002) Assign docs sentiments Assign docs sentiments Yi et al.","['tenfold', 'point', 'cross', 'scale', 'fivefold', 'nonhierarchical', 'threefold', 'docs', 'polarneutral', 'mckeown', 'svm', 'patternbased', 'hybrid', 'validation']","(0, [])","(0, [])"
"Hiroshi et al., 2004","These are Natural Language Processing (NLP) and pattern-based (Hiroshi et al., 2004; K nig & Brill, 2006; Nasukawa & Yi, 2003; Yi et al., 2003), machine learning algorithms, such as Naive Bayes (NB), Maximum Entropy (ME), Support Vector Machine (SVM) (Joachims, 1998), and unsupervised learning (Turney, 2002).","['such', 'unsupervised', 'naive', 'maximum', 'patternbased', 'natural']","(0, [])","(1, ['naive'])"
"Hiroshi, Tetsuya, & Hideo, 2004","Existing work in sentiment analysis Whilst most researchers focus on assigning sentiments to documents, others focus on more speci c tasks: nding the sentiments of words (Hatzivassiloglou & McKeown, 1997), subjective expressions (Kim & Hovy, 2004; Wilson, Wiebe, & Hoffmann, 2005), subjective sentences (Pang & Lee, 2004) and topics (Hiroshi, Tetsuya, & Hideo, 2004; Nasukawa & Yi, 2003; Yi, Nasukawa, Niblack, & Bunescu, 2003).","['more', 'subjective', 'most', 'speci']","(0, [])","(0, [])"
"Ishibuchi, Nakashima, & Kuroda, 2000","Fuzzy hybrid classi cation has been achieved before (Ishibuchi, Nakashima, & Kuroda, 2000) and so this should be possible for our system.","['hybrid', 'possible', 'fuzzy']","(0, [])","(1, ['fuzzy'])"
"Ittner, Lewis, & Ahn, 1995","In contrast, a SVM classi er, like other parametric approaches, such as Naive Bayes (G vert, Lalmas, & Fuhr, 1999), Rocchio (Ittner, Lewis, & Ahn, 1995), and Neural network (Yin and Savio, 1996) classi ers, regards a document collection as a set of signi cant features, each of which is assigned a weight, and each document is represented by a feature set.","['such', 'features', 'other', 'cant', 'parametric', 'naive', 'neural']","(0, [])","(1, ['naive'])"
January 2009,"c o m / l o c a t e / j o i Sentiment analysis: A combined approach Rudy Prabowo 1, Mike Thelwall School of Computing and Information Technology, University of Wolverhampton, Wulfruna Street, WV1 1SB Wolverhampton, UK a r t i c l e i n f o a b s t r a c t Article history: Received 31 July 2008 Received in revised form 21 January 2009 Accepted 22 January 2009 Keywords: Sentiment analysis Unsupervised learning Machine learning Hybrid classi cation 1.","['combined', 'classi', 'wolverhampton', 'learning', 'keywords', 'thelwall', 'january', 'hybrid', 'revised']","(0, [])","(0, [])"
"Joachims, 1998","These are Natural Language Processing (NLP) and pattern-based (Hiroshi et al., 2004; K nig & Brill, 2006; Nasukawa & Yi, 2003; Yi et al., 2003), machine learning algorithms, such as Naive Bayes (NB), Maximum Entropy (ME), Support Vector Machine (SVM) (Joachims, 1998), and unsupervised learning (Turney, 2002). We used Support Vector Machines (SVM) (Joachims, 1998), the most widely used machine learning algorithm, to measure the effectiveness of machine learning approaches. Support vector machines r = r = (cid:12)n (cid:12)n (cid:12)n (cid:12)n We used Support Vector Machine (SVMlight) V6.01 (Joachims, 1998).","['approaches', 'such', 'unsupervised', 'naive', 'maximum', 'patternbased', 'turney', 'natural']","(0, [])","(1, ['naive'])"
July 2008,"c o m / l o c a t e / j o i Sentiment analysis: A combined approach Rudy Prabowo 1, Mike Thelwall School of Computing and Information Technology, University of Wolverhampton, Wulfruna Street, WV1 1SB Wolverhampton, UK a r t i c l e i n f o a b s t r a c t Article history: Received 31 July 2008 Received in revised form 21 January 2009 Accepted 22 January 2009 Keywords: Sentiment analysis Unsupervised learning Machine learning Hybrid classi cation 1.","['combined', 'classi', 'wolverhampton', 'learning', 'keywords', 'thelwall', 'january', 'hybrid', 'revised']","(0, [])","(0, [])"
"Kim & Hovy, 2004","Existing work in sentiment analysis Whilst most researchers focus on assigning sentiments to documents, others focus on more speci c tasks: nding the sentiments of words (Hatzivassiloglou & McKeown, 1997), subjective expressions (Kim & Hovy, 2004; Wilson, Wiebe, & Hoffmann, 2005), subjective sentences (Pang & Lee, 2004) and topics (Hiroshi, Tetsuya, & Hideo, 2004; Nasukawa & Yi, 2003; Yi, Nasukawa, Niblack, & Bunescu, 2003).","['more', 'subjective', 'most', 'speci']","(0, [])","(0, [])"
"Kuncheva, 2000","A further extension of the system would be to use it to create fuzzy classi cations (Kuncheva, 2000), i.e., assigning sentiment on a probability rather than a binary basis.","['further', 'classi', 'fuzzy', 'binary']","(0, [])","(1, ['fuzzy'])"
LLR 2033,Micro-averaged F1; macro-averaged F1 Google DF MI (cid:2)2 LLR Yahoo DF MI (cid:2)2 LLR 2033 rules of S2 439 rules of S3 373 rules of S4 67.29; 67.11 73.02; 71.16 64.63; 62.53 57.85; 54.99 64.40; 64.36 60.90; 60.34 56.47; 54.81 64.85; 64.83 64.36; 64.13 75.41; 75.20 79.59; 79.22 71.04; 70.32 65.42; 65.36 74.60; 73.37 64.63; 62.53 67.09; 63.62 66.89; 66.89 60.37; 59.85 63.65; 62.23 63.04; 63.01 63.83; 63.63 83.33; 82.29 78.68; 78.42 70.41; 69.79,"['macroaveraged', 'yahoo', 'microaveraged']","(0, [])","(0, [])"
"Liu, 2004","In our setting, we used the Montylingua (Liu, 2004) parser to produce a collection of parsed sentences that can be further processed to form a set of rules (Section 4.1). The Montylingua (Liu, 2004) chunker was used to parse all the sentences found in the document set.",['parsed'],"(0, [])","(0, [])"
"Manber & Myers, 1990","A suf x array (Manber & Myers, 1990) was then built to speed up antecedent matching.",[],"(0, [])","(0, [])"
"Miller, 1995","To reduce the error rate of parsing, we automatically scanned and tested all the proper nouns identi ed by Montylingua against all the nouns (NN and NNS) in WordNet 2.0 (Miller, 1995).","['nouns', 'proper']","(1, ['proper'])","(0, [])"
"Nasukawa & Yi, 2003","Existing work in sentiment analysis Whilst most researchers focus on assigning sentiments to documents, others focus on more speci c tasks: nding the sentiments of words (Hatzivassiloglou & McKeown, 1997), subjective expressions (Kim & Hovy, 2004; Wilson, Wiebe, & Hoffmann, 2005), subjective sentences (Pang & Lee, 2004) and topics (Hiroshi, Tetsuya, & Hideo, 2004; Nasukawa & Yi, 2003; Yi, Nasukawa, Niblack, & Bunescu, 2003). These are Natural Language Processing (NLP) and pattern-based (Hiroshi et al., 2004; K nig & Brill, 2006; Nasukawa & Yi, 2003; Yi et al., 2003), machine learning algorithms, such as Naive Bayes (NB), Maximum Entropy (ME), Support Vector Machine (SVM) (Joachims, 1998), and unsupervised learning (Turney, 2002).","['more', 'such', 'speci', 'subjective', 'unsupervised', 'naive', 'natural', 'patternbased', 'maximum', 'most']","(0, [])","(1, ['naive'])"
"Pang & Lee, 2004","Existing work in sentiment analysis Whilst most researchers focus on assigning sentiments to documents, others focus on more speci c tasks: nding the sentiments of words (Hatzivassiloglou & McKeown, 1997), subjective expressions (Kim & Hovy, 2004; Wilson, Wiebe, & Hoffmann, 2005), subjective sentences (Pang & Lee, 2004) and topics (Hiroshi, Tetsuya, & Hideo, 2004; Nasukawa & Yi, 2003; Yi, Nasukawa, Niblack, & Bunescu, 2003).","['more', 'subjective', 'most', 'speci']","(0, [])","(0, [])"
Pang and Lee (2004),"These tasks analyse sentiment at a ne-grained level and can be used to improve the effectiveness of sentiment classi cation, as shown in Pang and Lee (2004). (2004) Pang and Lee (2004) Assign topics sentiments Assign docs sentiments Unigrams NLP, pattern-based NB, SVM Camera reviews Movie reviews Kim and Hovy (2004) Assign expressions sentiments Probabilistic based DUC corpus Macro-averaged N/A 13,832(+) 25,910(+) 88.9 N/A N/A N/A N/A 200 4389( ) 2016(+) 2016( ) N/A 5664( ) 224(+) 224( ) N/A 85.8 89 100 N/A N/A Ten-fold cross validation Ten-fold cross validation 1000(+) N/A N/A 86.4 87.2 N/A 1000( ) N/A 231 adjectives 251 verbs N/A N/A 75.6 77.9 N/A N/A 100 sentences 79.1 81.2 81 N/A N/A N/A 43 N/A 97.8 93.2 N/A N/A N/A N/A N/A N/A N/A R .","['probabilistic', 'tenfold', 'docs', 'negrained', 'unigrams', 'nlp', 'macroaveraged', 'patternbased', 'lee']","(0, [])","(0, [])"
"Quinlan, 1986","In contrast, ID3 (Quinlan, 1986) and RIPPER (Cohen, 1995) focus on reducing an initial large set of rules to improve the ef ciency of a rule-based classi er by sacri cing a degree of effectiveness if necessary. We also examined the effectiveness of two induction algorithms, ID3 (Quinlan, 1986) and RIPPER (Cohen, 1995). Induction rule-based classi er (IRBC) Given the two rule sets generated by the rule-based classi er (RBC) and Statistics Based Classi er (SBC), we applied two existing induction algorithms, ID3 (Quinlan, 1986) and RIPPER (Cohen, 1995) provided by Weka (Witten, & Frank, 2005), to generate two induced rule sets, and built a classi er that could use the two induced rule sets to classify a document collection.","['induced', 'rulebased', 'large', 'initial', 'contrast', 'ripper']","(0, [])","(0, [])"
Sebastiani (2002),Sebastiani (2002) states that machine learning based classi cation is practical since automatic classi ers can achieve a level of accuracy comparable to that achieved by human experts.,"['classi', 'comparable', 'automatic', 'practical', 'human']","(0, [])","(0, [])"
"Sebastiani, 2002","The results are a set of pairs, such that each pair contains a document, di, and a class, cj, where {di, cj} D C. di, cj means that di D is assigned with (or is classi ed into) cj C (Sebastiani, 2002).","['classi', 'such']","(0, [])","(0, [])"
"Stone, Dunphy, Smith, & Ogilvie, 1966","General inquirer based classi er (GIBC) The rst, simplest rule set was based on 3672 pre-classi ed words found in the General Inquirer Lexicon (Stone, Dunphy, Smith, & Ogilvie, 1966), 1598 of which were pre-classi ed as positive and 2074 of which were pre-classi ed as negative.","['preclassi', 'general', 'positive', 'simplest']","(2, ['positive', 'simplest'])","(0, [])"
Turney (2002),"This focuses on exploiting a search engine corpus to determine the sentiment of an expression, as demonstrated in Turney (2002). method Data set Tr Te Accuracy Precision Recall N/A 36,796 4084 77.5 N/A N/A F 1 N/A Customer feedback Ten-fold cross validation (1 vs 4) Ten-fold cross validation (1, 2 vs 3, 4) Ten-fold cross validation (3 point scale) Ten-fold cross validation (4-point scale) Ten-fold cross validation N/A 36,796 4084 69.5 N/A N/A N/A 5006 N/A N/A 66.3 N/A N/A N/A 5006 N/A N/A 54.6 N/A N/A N/A N/A 135 400 N/A 70.2 82.4 41.9 60.6 59.2 69.4 Ten-fold cross validation: polar/neutral Ten-fold cross validation: +/ /both/neutral 13,183 expressions 13,183 expressions N/A N/A 73.6 75.9 68.6 72.2/ 74.0 77.7 45.3 56.8/ 85.7 89.9 55.7 63.4/ 80.7 82.1 N/A N/A 61.7 65.7 1000( ) N/A 30,000 10,000 >91 <72 657adj(+) N/A N/A 78.1 92.4 N/A 55.3 63.4/ 64.7 72.9/ 28.4 35.2/ 50.1 52.4 N/A 59.3 69.4/ 80.4 83.9/ 9.2 11.2/ 30.2 41.4 N/A 61.2 65.1/ 73.1 77.2/ 14.6 16.1/ 37.7 46.2 N/A N/A N/A N/A N/A N/A K nig and Brill (2006) Assign docs sentiments Pattern-based, SVM, hybrid Movie reviews Five-fold cross validation 1000(+) N/A N/A Hatzivassiloglou and McKeown (1997) Assign adjectives +/ N/A Nonhierarchical clustering NB, ME, SVM Customer feedback WSJ corpus Five-fold cross validation N/A Movie reviews Three-fold cross validation Uniand bigrams Pang, Lee, and Vaithyanathan (2002) Turney (2002) Assign docs sentiments Assign docs sentiments Yi et al.","['tenfold', 'point', 'cross', 'scale', 'fivefold', 'nonhierarchical', 'threefold', 'docs', 'polarneutral', 'mckeown', 'svm', 'patternbased', 'hybrid', 'validation']","(0, [])","(0, [])"
"Turney, 2002","These are Natural Language Processing (NLP) and pattern-based (Hiroshi et al., 2004; K nig & Brill, 2006; Nasukawa & Yi, 2003; Yi et al., 2003), machine learning algorithms, such as Naive Bayes (NB), Maximum Entropy (ME), Support Vector Machine (SVM) (Joachims, 1998), and unsupervised learning (Turney, 2002). Bad expressions co-occur more frequently with the word poor , and good expressions with the word excellent (Turney, 2002).","['poor', 'bad', 'such', 'good', 'unsupervised', 'naive', 'maximum', 'patternbased', 'natural']","(1, ['good'])","(3, ['poor', 'bad', 'naive'])"
"Wilson, Wiebe, & Hoffmann, 2005","Existing work in sentiment analysis Whilst most researchers focus on assigning sentiments to documents, others focus on more speci c tasks: nding the sentiments of words (Hatzivassiloglou & McKeown, 1997), subjective expressions (Kim & Hovy, 2004; Wilson, Wiebe, & Hoffmann, 2005), subjective sentences (Pang & Lee, 2004) and topics (Hiroshi, Tetsuya, & Hideo, 2004; Nasukawa & Yi, 2003; Yi, Nasukawa, Niblack, & Bunescu, 2003).","['more', 'subjective', 'most', 'speci']","(0, [])","(0, [])"
"Witten, & Frank, 2005","Induction rule-based classi er (IRBC) Given the two rule sets generated by the rule-based classi er (RBC) and Statistics Based Classi er (SBC), we applied two existing induction algorithms, ID3 (Quinlan, 1986) and RIPPER (Cohen, 1995) provided by Weka (Witten, & Frank, 2005), to generate two induced rule sets, and built a classi er that could use the two induced rule sets to classify a document collection.","['ripper', 'induced', 'rulebased']","(0, [])","(0, [])"
"Yi et al., 2003","These are Natural Language Processing (NLP) and pattern-based (Hiroshi et al., 2004; K nig & Brill, 2006; Nasukawa & Yi, 2003; Yi et al., 2003), machine learning algorithms, such as Naive Bayes (NB), Maximum Entropy (ME), Support Vector Machine (SVM) (Joachims, 1998), and unsupervised learning (Turney, 2002).","['such', 'unsupervised', 'naive', 'maximum', 'patternbased', 'natural']","(0, [])","(1, ['naive'])"
"Yi, Nasukawa, Niblack, & Bunescu, 2003","Existing work in sentiment analysis Whilst most researchers focus on assigning sentiments to documents, others focus on more speci c tasks: nding the sentiments of words (Hatzivassiloglou & McKeown, 1997), subjective expressions (Kim & Hovy, 2004; Wilson, Wiebe, & Hoffmann, 2005), subjective sentences (Pang & Lee, 2004) and topics (Hiroshi, Tetsuya, & Hideo, 2004; Nasukawa & Yi, 2003; Yi, Nasukawa, Niblack, & Bunescu, 2003).","['more', 'subjective', 'most', 'speci']","(0, [])","(0, [])"
"Yin and Savio, 1996","In contrast, a SVM classi er, like other parametric approaches, such as Naive Bayes (G vert, Lalmas, & Fuhr, 1999), Rocchio (Ittner, Lewis, & Ahn, 1995), and Neural network (Yin and Savio, 1996) classi ers, regards a document collection as a set of signi cant features, each of which is assigned a weight, and each document is represented by a feature set.","['such', 'features', 'other', 'cant', 'parametric', 'naive', 'neural']","(0, [])","(1, ['naive'])"
and 2074,"General inquirer based classi er (GIBC) The rst, simplest rule set was based on 3672 pre-classi ed words found in the General Inquirer Lexicon (Stone, Dunphy, Smith, & Ogilvie, 1966), 1598 of which were pre-classi ed as positive and 2074 of which were pre-classi ed as negative.","['preclassi', 'general', 'positive', 'simplest']","(2, ['positive', 'simplest'])","(0, [])"
and Belew (2000),"Here, the independence of features is assumed, which is not always true, as explained in Lewis (1998) and Belew (2000).","['lewis', 'assumed']","(0, [])","(0, [])"
and Calvo and Ceccatto (2000),"Hence, it is common that macro-averaged performance is lower than micro-averaged performance, as shown in a classi cation performance evaluation conducted by Yang and Liu (1999) and Calvo and Ceccatto (2000).","['classi', 'lower', 'microaveraged', 'macroaveraged', 'common']","(0, [])","(0, [])"
and Church and Hanks (1989),Two examples of the use of this method for measuring the strength of two terms association can be found in Conrad and Utt (1994) and Church and Hanks (1989).,['utt'],"(0, [])","(0, [])"
and Mettrop and Nieuwenhuysen (2001),"The coverage issues are discussed in Bar-Ilan (2001) and Thelwall (2000), and the uctuation issue in Bar-Ilan (1999) and Mettrop and Nieuwenhuysen (2001).","['uctuation', 'nieuwenhuysen', 'barilan']","(0, [])","(0, [])"
and Swan and Allan (2000),"The (cid:2)2 calculation used in this experiment does not approximate the (cid:2)2 value, such as described in Yang and Pedersen (1997) and Swan and Allan (2000).","['cid', 'such']","(0, [])","(0, [])"
and Thelwall (2000),"The coverage issues are discussed in Bar-Ilan (2001) and Thelwall (2000), and the uctuation issue in Bar-Ilan (1999) and Mettrop and Nieuwenhuysen (2001).","['uctuation', 'nieuwenhuysen', 'barilan']","(0, [])","(0, [])"
and Yang (1999),The use of DF in the context of automatic classi cation can be found in Yang and Pedersen (1997) and Yang (1999).,['automatic'],"(0, [])","(0, [])"
"bigrams Pang, Lee, and Vaithyanathan (2002)","method Data set Tr Te Accuracy Precision Recall N/A 36,796 4084 77.5 N/A N/A F 1 N/A Customer feedback Ten-fold cross validation (1 vs 4) Ten-fold cross validation (1, 2 vs 3, 4) Ten-fold cross validation (3 point scale) Ten-fold cross validation (4-point scale) Ten-fold cross validation N/A 36,796 4084 69.5 N/A N/A N/A 5006 N/A N/A 66.3 N/A N/A N/A 5006 N/A N/A 54.6 N/A N/A N/A N/A 135 400 N/A 70.2 82.4 41.9 60.6 59.2 69.4 Ten-fold cross validation: polar/neutral Ten-fold cross validation: +/ /both/neutral 13,183 expressions 13,183 expressions N/A N/A 73.6 75.9 68.6 72.2/ 74.0 77.7 45.3 56.8/ 85.7 89.9 55.7 63.4/ 80.7 82.1 N/A N/A 61.7 65.7 1000( ) N/A 30,000 10,000 >91 <72 657adj(+) N/A N/A 78.1 92.4 N/A 55.3 63.4/ 64.7 72.9/ 28.4 35.2/ 50.1 52.4 N/A 59.3 69.4/ 80.4 83.9/ 9.2 11.2/ 30.2 41.4 N/A 61.2 65.1/ 73.1 77.2/ 14.6 16.1/ 37.7 46.2 N/A N/A N/A N/A N/A N/A K nig and Brill (2006) Assign docs sentiments Pattern-based, SVM, hybrid Movie reviews Five-fold cross validation 1000(+) N/A N/A Hatzivassiloglou and McKeown (1997) Assign adjectives +/ N/A Nonhierarchical clustering NB, ME, SVM Customer feedback WSJ corpus Five-fold cross validation N/A Movie reviews Three-fold cross validation Uniand bigrams Pang, Lee, and Vaithyanathan (2002) Turney (2002) Assign docs sentiments Assign docs sentiments Yi et al.","['tenfold', 'point', 'cross', 'scale', 'fivefold', 'nonhierarchical', 'threefold', 'docs', 'polarneutral', 'mckeown', 'svm', 'patternbased', 'hybrid', 'validation']","(0, [])","(0, [])"
by Dumais and Chen (2000),As observed by Dumais and Chen (2000) and Pang et al.,[],"(0, [])","(0, [])"
by Market-Sentinel (2007),The third data set was proprietary data provided by Market-Sentinel (2007).,"['proprietary', 'third']","(0, [])","(1, ['proprietary'])"
by Thelwall (2008),"The fourth data set was also proprietary, provided by Thelwall (2008), extracted from MySpace (2007), and pre-classi ed by three assessors with kappa ((cid:4)) = 100%, i.e., the three assessors completely agreed with each other.","['preclassi', 'kappa', 'thelwall', 'fourth']","(0, [])","(0, [])"
by Yang and Liu (1999),"Hence, it is common that macro-averaged performance is lower than micro-averaged performance, as shown in a classi cation performance evaluation conducted by Yang and Liu (1999) and Calvo and Ceccatto (2000).","['classi', 'lower', 'microaveraged', 'macroaveraged', 'common']","(0, [])","(0, [])"
code NEST-2003,Acknowledgements The work was supported by a European Union grant for activity code NEST-2003-Path-1 and the Future & Emerging Technologies scheme.,['european'],"(0, [])","(0, [])"
"extraction, Choi, Cardie, Riloff, and Patwardhan (2005)","Instead of carrying out a sentiment classi cation or an opinion extraction, Choi, Cardie, Riloff, and Patwardhan (2005) focus on extracting the sources of opinions, e.g., the persons or organizations who play a crucial role in in uencing other individuals opinions.","['other', 'crucial']","(0, [])","(0, [])"
from MySpace (2007),"The fourth data set was also proprietary, provided by Thelwall (2008), extracted from MySpace (2007), and pre-classi ed by three assessors with kappa ((cid:4)) = 100%, i.e., the three assessors completely agreed with each other.","['preclassi', 'kappa', 'thelwall', 'fourth']","(0, [])","(0, [])"
from Pang (2007),The rst data set was downloaded from Pang (2007).,['rst'],"(0, [])","(0, [])"
in Bar-Ilan (1999),"The coverage issues are discussed in Bar-Ilan (2001) and Thelwall (2000), and the uctuation issue in Bar-Ilan (1999) and Mettrop and Nieuwenhuysen (2001).","['uctuation', 'nieuwenhuysen', 'barilan']","(0, [])","(0, [])"
in Bar-Ilan (2001),"The coverage issues are discussed in Bar-Ilan (2001) and Thelwall (2000), and the uctuation issue in Bar-Ilan (1999) and Mettrop and Nieuwenhuysen (2001).","['uctuation', 'nieuwenhuysen', 'barilan']","(0, [])","(0, [])"
in Conrad and Utt (1994),Two examples of the use of this method for measuring the strength of two terms association can be found in Conrad and Utt (1994) and Church and Hanks (1989).,['utt'],"(0, [])","(0, [])"
in Dumais and Chen (2000),As explained in Dumais and Chen (2000) and Pang et al.,[],"(0, [])","(0, [])"
in Lewis (1998),"Here, the independence of features is assumed, which is not always true, as explained in Lewis (1998) and Belew (2000).","['lewis', 'assumed']","(0, [])","(0, [])"
in Pang and Lee (2004),"These tasks analyse sentiment at a ne-grained level and can be used to improve the effectiveness of sentiment classi cation, as shown in Pang and Lee (2004).",['negrained'],"(0, [])","(0, [])"
in Turney (2002),"This focuses on exploiting a search engine corpus to determine the sentiment of an expression, as demonstrated in Turney (2002).",[],"(0, [])","(0, [])"
in Yang and Pedersen (1997),"The use of DF in the context of automatic classi cation can be found in Yang and Pedersen (1997) and Yang (1999). The (cid:2)2 calculation used in this experiment does not approximate the (cid:2)2 value, such as described in Yang and Pedersen (1997) and Swan and Allan (2000).","['automatic', 'such', 'cid']","(0, [])","(0, [])"
matter 2009,1751-1577/$ see front matter 2009 Elsevier Ltd. All rights reserved.,"['front', 'elsevier']","(0, [])","(0, [])"
"nig & Brill, 2006","These are Natural Language Processing (NLP) and pattern-based (Hiroshi et al., 2004; K nig & Brill, 2006; Nasukawa & Yi, 2003; Yi et al., 2003), machine learning algorithms, such as Naive Bayes (NB), Maximum Entropy (ME), Support Vector Machine (SVM) (Joachims, 1998), and unsupervised learning (Turney, 2002).","['such', 'unsupervised', 'naive', 'maximum', 'patternbased', 'natural']","(0, [])","(1, ['naive'])"
nig and Brill (2006),"Hybrid classi cation The idea of hybrid classi cation was used in K nig and Brill (2006). method Data set Tr Te Accuracy Precision Recall N/A 36,796 4084 77.5 N/A N/A F 1 N/A Customer feedback Ten-fold cross validation (1 vs 4) Ten-fold cross validation (1, 2 vs 3, 4) Ten-fold cross validation (3 point scale) Ten-fold cross validation (4-point scale) Ten-fold cross validation N/A 36,796 4084 69.5 N/A N/A N/A 5006 N/A N/A 66.3 N/A N/A N/A 5006 N/A N/A 54.6 N/A N/A N/A N/A 135 400 N/A 70.2 82.4 41.9 60.6 59.2 69.4 Ten-fold cross validation: polar/neutral Ten-fold cross validation: +/ /both/neutral 13,183 expressions 13,183 expressions N/A N/A 73.6 75.9 68.6 72.2/ 74.0 77.7 45.3 56.8/ 85.7 89.9 55.7 63.4/ 80.7 82.1 N/A N/A 61.7 65.7 1000( ) N/A 30,000 10,000 >91 <72 657adj(+) N/A N/A 78.1 92.4 N/A 55.3 63.4/ 64.7 72.9/ 28.4 35.2/ 50.1 52.4 N/A 59.3 69.4/ 80.4 83.9/ 9.2 11.2/ 30.2 41.4 N/A 61.2 65.1/ 73.1 77.2/ 14.6 16.1/ 37.7 46.2 N/A N/A N/A N/A N/A N/A K nig and Brill (2006) Assign docs sentiments Pattern-based, SVM, hybrid Movie reviews Five-fold cross validation 1000(+) N/A N/A Hatzivassiloglou and McKeown (1997) Assign adjectives +/ N/A Nonhierarchical clustering NB, ME, SVM Customer feedback WSJ corpus Five-fold cross validation N/A Movie reviews Three-fold cross validation Uniand bigrams Pang, Lee, and Vaithyanathan (2002) Turney (2002) Assign docs sentiments Assign docs sentiments Yi et al.","['svm', 'tenfold', 'point', 'cross', 'scale', 'fivefold', 'nonhierarchical', 'threefold', 'docs', 'polarneutral', 'validation', 'patternbased', 'mckeown', 'hybrid']","(0, [])","(0, [])"
reviews Kim and Hovy (2004),"(2004) Pang and Lee (2004) Assign topics sentiments Assign docs sentiments Unigrams NLP, pattern-based NB, SVM Camera reviews Movie reviews Kim and Hovy (2004) Assign expressions sentiments Probabilistic based DUC corpus Macro-averaged N/A 13,832(+) 25,910(+) 88.9 N/A N/A N/A N/A 200 4389( ) 2016(+) 2016( ) N/A 5664( ) 224(+) 224( ) N/A 85.8 89 100 N/A N/A Ten-fold cross validation Ten-fold cross validation 1000(+) N/A N/A 86.4 87.2 N/A 1000( ) N/A 231 adjectives 251 verbs N/A N/A 75.6 77.9 N/A N/A 100 sentences 79.1 81.2 81 N/A N/A N/A 43 N/A 97.8 93.2 N/A N/A N/A N/A N/A N/A N/A R .","['probabilistic', 'tenfold', 'docs', 'unigrams', 'nlp', 'macroaveraged', 'patternbased', 'lee']","(0, [])","(0, [])"
scale Model SVM Pang and Lee (2005),"Author Objectives N-gram Gamon (2004) Assign docs sentiments using 4-point scale Model SVM Pang and Lee (2005) Assign docs sentiments using 3or 4-point scale SVM, regression, metric labeling Movie reviews Choi et al.","['point', 'metric', 'gamon', 'ngram', 'lee']","(0, [])","(0, [])"
sentiments Nasukawa and Yi (2003),"(2003) Assign topics sentiments Nasukawa and Yi (2003) Assign topics sentiments N/A PMI-IR NLP, pattern-based NLP, pattern-based Automobile, bank, movie, travel reviews Digital camera, music reviews Petroleum, pharmaceutical Web pages Web pages Camera reviews N/A N/A N/A N/A N/A 679adj( ) 700(+) 700( ) 240(+) 170( ) 735(+) 4227( ) N/A N/A N/A 77 82.9 N/A N/A N/A N/A N/A 65.8 84 N/A N/A N/A N/A N/A 85.6 87 56 N/A N/A N/A 90 93 86 91 N/A N/A 118(+) N/A N/A 94.3 N/A 28.6 N/A 58( ) 255 N/A N/A 94.5 N/A 24 N/A 1 4 6 R .","['petroleum', 'digital', 'pmiir', 'nlp', 'patternbased', 'pharmaceutical']","(0, [])","(0, [])"
"vert, Lalmas, & Fuhr, 1999","In contrast, a SVM classi er, like other parametric approaches, such as Naive Bayes (G vert, Lalmas, & Fuhr, 1999), Rocchio (Ittner, Lewis, & Ahn, 1995), and Neural network (Yin and Savio, 1996) classi ers, regards a document collection as a set of signi cant features, each of which is assigned a weight, and each document is represented by a feature set.","['such', 'features', 'other', 'cant', 'parametric', 'naive', 'neural']","(0, [])","(1, ['naive'])"
Andrea Esuli and Fabrizio Sebastiani (2005),"Andrea Esuli and Fabrizio Sebastiani (2005) proposed semi-supervised learning method started from expanding an initial seed set using 2012, IJARCSSE All Rights Reserved Page | 285 Negation is a very common linguistic construction that affects polarity and therefore, needs to be taken into consideration in sentiment analysis.","['andrea', 'common', 'initial', 'semisupervised', 'linguistic']","(0, [])","(0, [])"
August 2014,"See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/265163299 Sentiment Analysis and Opinion Mining: A Survey Article June 2012 CITATIONS 469 2 authors: Vinodhini G Annamalai University 37 PUBLICATIONS 770 CITATIONS SEE PROFILE Some of the authors of this publication are also working on these related projects: Sentiment mining View project READS 16,505 Dr. RM Chandrasekaran Annamalai University 74 PUBLICATIONS 1,210 CITATIONS SEE PROFILE All content following this page was uploaded by Vinodhini G on 30 August 2014.","['httpswwwresearchgatenetpublication', 'discussions', 'august']","(0, [])","(0, [])"
"Bing Liu, 2005","Volume 2, Issue 6, June 2012 www.ijarcsse.com system shows the results in a graph format showing opinion of the product feature by feature (Bing Liu, 2005).",[],"(0, [])","(0, [])"
Chaovalit and Zhou (2005),Chaovalit and Zhou (2005) compared the Semantic Orientation approach with the N-gram model machine learning approach by applying to movie reviews.,"['ngram', 'semantic']","(0, [])","(0, [])"
"Chau & Xu, 2007","Bloggers record the daily events in their lives and express their opinions, feelings, and emotions in a blog (Chau & Xu, 2007).",['daily'],"(0, [])","(0, [])"
"Christopher Scaffidi, 2007","It scores each product based on features from the customer reviews (Christopher Scaffidi, 2007).",['christopher'],"(0, [])","(0, [])"
"Etzioni ,2005","Other than these the available are professional review sites such as www.dpreview.com , www.zdnet.com and consumer opinion sites on broad topics and products such as www .consumerreview.com, (Popescu& www.epinions.com, Etzioni ,2005 ; Hu,B.Liu ,2006 ; Qinliang Mia, 2009; Gamgaran Somprasertsi ,2010).","['such', 'www', 'other', 'etzioni', 'broad', 'professional', 'available']","(1, ['available'])","(0, [])"
"Gamgaran Somprasertsi ,2010","Other than these the available are professional review sites such as www.dpreview.com , www.zdnet.com and consumer opinion sites on broad topics and products such as www .consumerreview.com, (Popescu& www.epinions.com, Etzioni ,2005 ; Hu,B.Liu ,2006 ; Qinliang Mia, 2009; Gamgaran Somprasertsi ,2010).","['such', 'www', 'other', 'etzioni', 'broad', 'professional', 'available']","(1, ['available'])","(0, [])"
Gamgarn Somprasertsri (2010),Gamgarn Somprasertsri (2010) dedicated their work to properly identify the semantic relationships between product features and opinions.,['semantic'],"(0, [])","(0, [])"
Gang Li & Fei Liu (2010),Gang Li & Fei Liu (2010) developed an approach based on the k-means clustering algorithm.,[],"(0, [])","(0, [])"
"Hu, 2005","Hu s work in (Hu, 2005) can be considered as the pioneer work on feature-based opinion summarization.",['featurebased'],"(0, [])","(0, [])"
"Jian ,2010","Last section concludes our study and Jian ,2010 ; Pang and Lee ,2004; Bai et al.","['lee', 'last', 'jian']","(0, [])","(0, [])"
Jin-Cheon Na (2005),"Jin-Cheon Na (2005), reported a study in automatically classifying documents as expressing positive or negative.He investigated the use of simple linguistic processing to address the problems of negation phrase.","['simple', 'linguistic', 'negativehe', 'positive']","(1, ['positive'])","(0, [])"
June 2012,"See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/265163299 Sentiment Analysis and Opinion Mining: A Survey Article June 2012 CITATIONS 469 2 authors: Vinodhini G Annamalai University 37 PUBLICATIONS 770 CITATIONS SEE PROFILE Some of the authors of this publication are also working on these related projects: Sentiment mining View project READS 16,505 Dr. RM Chandrasekaran Annamalai University 74 PUBLICATIONS 1,210 CITATIONS SEE PROFILE All content following this page was uploaded by Vinodhini G on 30 August 2014. Volume 2, Issue 6, June 2012 ISSN: 2277 128X International Journal of Advanced Research in Computer Science and Software Engineering Research Paper Available online at: www.ijarcsse.com Sentiment Analysis and Opinion Mining: A Survey G.Vinodhini* Assistant Professor, Department of Computer Science and Engineering, Annamalai University, Annamalai Nagar-608002. Volume 2, Issue 6, June 2012 www.ijarcsse.com Electronics and Kitchen appliances, with 1000 positive sources used for opinion mining. Volume 2, Issue 6, June 2012 www.ijarcsse.com performance for sentiment classification. the naive Bayes classifier surprisingly Volume 2, Issue 6, June 2012 www.ijarcsse.com WordNet. Volume 2, Issue 6, June 2012 www.ijarcsse.com unsupervised information extraction system called shown that there are many other words that invert the OPINE, which extracted product features and opinions polarity of an opinion expressed, such as valence shifters, from reviews. Volume 2, Issue 6, June 2012 www.ijarcsse.com system shows the results in a graph format showing opinion of the product feature by feature (Bing Liu, 2005). Volume 2, Issue 6, June 2012 www.ijarcsse.com 6. Volume 2, Issue 6, June 2012 www.ijarcsse.com Table 1. Volume 2, Issue 6, June 2012 www.ijarcsse.com Table 1. Volume 2, Issue 6, June 2012 www.ijarcsse.com Competitive Intelligence , Decision Support Systems 50","['many', 'table', 'naive', 'online', 'liu', 'university', 'nagar', 'discussions', 'annamalai', 'positive', 'other', 'international', 'available', 'httpswwwresearchgatenetpublication', 'such', 'unsupervised', 'august', 'advanced', 'competitive']","(4, ['positive', 'available', 'advanced', 'competitive'])","(1, ['naive'])"
"Kaiquan Xu , 2011","Sentiment analysis find a major role in competitive intelligence (Kaiquan Xu , 2011) to extract and visualize comparative relations between products from customer reviews, with the interdependencies into consideration, to help enterprises discover potential risks and further design new products and marketing strategies.","['new', 'major', 'kaiquan', 'potential', 'comparative', 'discover', 'competitive']","(1, ['competitive'])","(0, [])"
"Kaiquan Xu, 2011","Multiple variants of SVM have been developed in which Multi class SVM is used for Sentiment classification (Kaiquan Xu, 2011).","['multiple', 'multi']","(0, [])","(0, [])"
Kamps et al (2004),Kamps et al (2004) focused on the use of lexical relations in sentiment classification.,['lexical'],"(0, [])","(0, [])"
Kennedy and Inkpen (2005),(2004) Kennedy and Inkpen (2005) evaluate a negation model which is fairly identical to the one proposed by Polanyi and Zaenen in document-level polarity classification.,"['inkpen', 'identical', 'documentlevel']","(0, [])","(0, [])"
"Kennedy and Inkpen ,2006","Kennedy and Inkpen ,2006; Zhou and Chaovalit ,2008; Yulan He 2010; Rudy Prabowo ,2009; Rui Xia ,2011).",['inkpen'],"(0, [])","(0, [])"
Khairullah Khan et al (2010),"Khairullah Khan et al (2010) developed a method to find features of product from user review in an efficient way from text through auxiliary verbs (AV) {is, was, are, the were, has, have, had}.","['auxiliary', 'efficient', 'user']","(1, ['efficient'])","(0, [])"
"Konig & Brill ,2006","The fifth section is about the performance Liu ,2006; Konig & Brill ,2006 ; Long Sheng ,2011; Zhu evaluation done.","['fifth', 'long']","(0, [])","(0, [])"
"Ku, Liang, and Chen (2006)","Ku, Liang, and Chen (2006) investigated both news and web blog articles.",[],"(0, [])","(0, [])"
"Liu ,2006","The fifth section is about the performance Liu ,2006; Konig & Brill ,2006 ; Long Sheng ,2011; Zhu evaluation done. Other than these the available are professional review sites such as www.dpreview.com , www.zdnet.com and consumer opinion sites on broad topics and products such as www .consumerreview.com, (Popescu& www.epinions.com, Etzioni ,2005 ; Hu,B.Liu ,2006 ; Qinliang Mia, 2009; Gamgaran Somprasertsi ,2010).","['long', 'such', 'www', 'other', 'fifth', 'etzioni', 'broad', 'professional', 'available']","(1, ['available'])","(0, [])"
"Long Sheng ,2011","The fifth section is about the performance Liu ,2006; Konig & Brill ,2006 ; Long Sheng ,2011; Zhu evaluation done.","['fifth', 'long']","(0, [])","(0, [])"
Long-Sheng Chen (2011),"Long-Sheng Chen (2011) proposed a neural network based approach, which combines the advantages of the machine learning techniques and the information retrieval techniques.","['neural', 'longsheng']","(0, [])","(0, [])"
"Martin, 2005","Blogs are used as a source of opinion in many of the studies related to sentiment analysis (Martin, 2005; Murphy, 2006; Tang et al., 2009).","['many', 'sentiment']","(0, [])","(0, [])"
"Melville et al., 2009","The Naive Bayes algorithm is widely used algorithm for document classification (Melville et al., 2009; Rui Xia, 2011; Ziqiong, 2011; Songho tan, 2008 2012, IJARCSSE All Rights Reserved Page | 283",['naive'],"(0, [])","(1, ['naive'])"
"Murphy, 2006","Blogs are used as a source of opinion in many of the studies related to sentiment analysis (Martin, 2005; Murphy, 2006; Tang et al., 2009).","['many', 'sentiment']","(0, [])","(0, [])"
Nan Li (2010),"Nan Li (2010) used sentiment analysis approach to provide a comprehensive and timely description of the interacting structural natural groupings of various forums, which will dynamically enable efficient detection of hotspot forums.","['structural', 'comprehensive', 'various', 'nan', 'natural', 'timely', 'efficient']","(3, ['comprehensive', 'timely', 'efficient'])","(0, [])"
"Pang and Lee ,2004","Last section concludes our study and Jian ,2010 ; Pang and Lee ,2004; Bai et al.","['lee', 'last', 'jian']","(0, [])","(0, [])"
Popescu et al (2005),"Popescu et al (2005) developed an Kunpeng Zhang (2009), proposed a work which used a keyword matching strategy to identify and tag product features in sentences.",[],"(0, [])","(0, [])"
"Qinliang Mia, 2009","Other than these the available are professional review sites such as www.dpreview.com , www.zdnet.com and consumer opinion sites on broad topics and products such as www .consumerreview.com, (Popescu& www.epinions.com, Etzioni ,2005 ; Hu,B.Liu ,2006 ; Qinliang Mia, 2009; Gamgaran Somprasertsi ,2010).","['such', 'www', 'other', 'etzioni', 'broad', 'professional', 'available']","(1, ['available'])","(0, [])"
"Rudy Prabowo ,2009","Kennedy and Inkpen ,2006; Zhou and Chaovalit ,2008; Yulan He 2010; Rudy Prabowo ,2009; Rui Xia ,2011).",['inkpen'],"(0, [])","(0, [])"
"Rudy Prabowo, 2009","Support vector machines (SVM), a discriminative classifier is considered the best text classification method (Rui Xia, 2011; Ziqiong, 2011; Songho tan, 2008 and Rudy Prabowo, 2009). Besides these classifiers other classifiers like ID3 and C5 are also investigated (Rudy Prabowo, 2009).","['other', 'discriminative', 'best', 'prabowo', 'text']","(1, ['best'])","(0, [])"
Rui Xia (2011),Rui Xia (2011) used this approach and made a comparative study of the effectiveness of technique for sentiment classification by ensemble efficiently sets and classification algorithms to synthesize a more accurate classification procedure.,"['accurate', 'comparative', 'ensemble']","(1, ['accurate'])","(0, [])"
"Rui Xia ,2011","Kennedy and Inkpen ,2006; Zhou and Chaovalit ,2008; Yulan He 2010; Rudy Prabowo ,2009; Rui Xia ,2011).",['inkpen'],"(0, [])","(0, [])"
"Rui Xia, 2011","The Naive Bayes algorithm is widely used algorithm for document classification (Melville et al., 2009; Rui Xia, 2011; Ziqiong, 2011; Songho tan, 2008 2012, IJARCSSE All Rights Reserved Page | 283 Support vector machines (SVM), a discriminative classifier is considered the best text classification method (Rui Xia, 2011; Ziqiong, 2011; Songho tan, 2008 and Rudy Prabowo, 2009).","['discriminative', 'text', 'naive', 'best']","(1, ['best'])","(1, ['naive'])"
Songbo Tan (2008),Songbo Tan (2008) presents an empirical study of sentiment categorization on Chinese documents.,"['chinese', 'empirical']","(0, [])","(0, [])"
Survey Article June 2012,"See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/265163299 Sentiment Analysis and Opinion Mining: A Survey Article June 2012 CITATIONS 469 2 authors: Vinodhini G Annamalai University 37 PUBLICATIONS 770 CITATIONS SEE PROFILE Some of the authors of this publication are also working on these related projects: Sentiment mining View project READS 16,505 Dr. RM Chandrasekaran Annamalai University 74 PUBLICATIONS 1,210 CITATIONS SEE PROFILE All content following this page was uploaded by Vinodhini G on 30 August 2014.","['httpswwwresearchgatenetpublication', 'discussions', 'august']","(0, [])","(0, [])"
"Tang et al., 2009","Blogs are used as a source of opinion in many of the studies related to sentiment analysis (Martin, 2005; Murphy, 2006; Tang et al., 2009).","['many', 'sentiment']","(0, [])","(0, [])"
"Teng-Kai Fan, Chia-Hui Chang ,2011","Sentiment analysis find its recent application in Dissatisfaction oriented online advertising Guang Qiu(2010) and Blogger-Centric Contextual Advertising (Teng-Kai Fan, Chia-Hui Chang ,2011), which refers to the assignment of personal ads to any blog page, chosen in according to bloggers interests.","['bloggercentric', 'personal', 'contextual', 'fan', 'tengkai', 'recent', 'online']","(0, [])","(0, [])"
"Weitong Huang, 2008","The rules generated from all the categories separately are combined together to form the classifier (Weitong Huang, 2008).",[],"(0, [])","(0, [])"
"Yi and Niblack, 2005","The sentiment lexicon defines the polarity of terms and sentiment pattern database defines sentiment extraction patterns for a sentence predicates (Yi and Niblack, 2005).",['sentiment'],"(0, [])","(0, [])"
Yulan He (2010),Yulan He (2010) attempted to create a novel framework from unlabeled documents.,"['unlabeled', 'novel']","(0, [])","(0, [])"
Yulan He 2010,"Kennedy and Inkpen ,2006; Zhou and Chaovalit ,2008; Yulan He 2010; Rudy Prabowo ,2009; Rui Xia ,2011).",['inkpen'],"(0, [])","(0, [])"
"Zhou and Chaovalit ,2008","Kennedy and Inkpen ,2006; Zhou and Chaovalit ,2008; Yulan He 2010; Rudy Prabowo ,2009; Rui Xia ,2011).",['inkpen'],"(0, [])","(0, [])"
Zhu Jian (2010),"Zhu Jian (2010) proposed an individual model based on Artificial neural networks to divide the movie review corpus into positive , negative and fuzzy tone which is based on the advanced recursive least squares back propagation training algorithm.","['individual', 'positive', 'jian', 'least', 'fuzzy', 'neural', 'negative', 'advanced', 'artificial', 'recursive']","(2, ['positive', 'advanced'])","(2, ['fuzzy', 'negative'])"
Ziqiong Zhang (2011),Ziqiong Zhang (2011) showed a contradiction in the performance of SVM.,[],"(0, [])","(0, [])"
"Ziqiong, 2011","The Naive Bayes algorithm is widely used algorithm for document classification (Melville et al., 2009; Rui Xia, 2011; Ziqiong, 2011; Songho tan, 2008 2012, IJARCSSE All Rights Reserved Page | 283 Support vector machines (SVM), a discriminative classifier is considered the best text classification method (Rui Xia, 2011; Ziqiong, 2011; Songho tan, 2008 and Rudy Prabowo, 2009).","['discriminative', 'text', 'naive', 'best']","(1, ['best'])","(1, ['naive'])"
advertising Guang Qiu(2010),"Sentiment analysis find its recent application in Dissatisfaction oriented online advertising Guang Qiu(2010) and Blogger-Centric Contextual Advertising (Teng-Kai Fan, Chia-Hui Chang ,2011), which refers to the assignment of personal ads to any blog page, chosen in according to bloggers interests.","['bloggercentric', 'personal', 'contextual', 'fan', 'tengkai', 'recent', 'online']","(0, [])","(0, [])"
an Kunpeng Zhang (2009),"Popescu et al (2005) developed an Kunpeng Zhang (2009), proposed a work which used a keyword matching strategy to identify and tag product features in sentences.",[],"(0, [])","(0, [])"
"and Rudy Prabowo, 2009","Support vector machines (SVM), a discriminative classifier is considered the best text classification method (Rui Xia, 2011; Ziqiong, 2011; Songho tan, 2008 and Rudy Prabowo, 2009).","['discriminative', 'text', 'best']","(1, ['best'])","(0, [])"
"applying and Qiang Ye, 2009","When applying and Qiang Ye, 2009).",['qiang'],"(0, [])","(0, [])"
best Rudy Prabowo (2009),"From the results he concludes that, IG performs the best for sentimental terms selection and SVM exhibits the best Rudy Prabowo (2009) described an extension by combining rule-based classification, supervised learning and machine learning into a new combined method.","['new', 'rulebased', 'that', 'sentimental', 'best']","(1, ['best'])","(0, [])"
by Ting-Chun Peng and Chia-Chun Shih (2010),judge to learning An unsupervised algorithm by extracting the sentiment phrases of each review by rules of part-of-speech (POS) patterns was investigated by Ting-Chun Peng and Chia-Chun Shih (2010).,"['unsupervised', 'tingchun', 'chiachun', 'partofspeech']","(0, [])","(0, [])"
from 2000,"The emergence of sentiment analysis dates back to late 1990 s, but becomes a major emerging sub field of information management discipline only from 2000, especially from 2004 onwards, which this survey focuses.","['sub', 'major']","(0, [])","(0, [])"
from 2004,"The emergence of sentiment analysis dates back to late 1990 s, but becomes a major emerging sub field of information management discipline only from 2000, especially from 2004 onwards, which this survey focuses.","['sub', 'major']","(0, [])","(0, [])"
independence 2012,"Despite its unrealistic independence 2012, IJARCSSE All Rights Reserved Page | 284",['unrealistic'],"(0, [])","(1, ['unrealistic'])"
late 1990,"The emergence of sentiment analysis dates back to late 1990 s, but becomes a major emerging sub field of information management discipline only from 2000, especially from 2004 onwards, which this survey focuses.","['sub', 'major']","(0, [])","(0, [])"
of Yongyong Zhail (2010),"the results of Yongyong Zhail (2010) proposed a approach of Opinion Feature Extraction based on Sentiment Patterns, which takes into account the structure characteristics of reviews for higher values of precision and recall.","['higher', 'yongyong']","(0, [])","(0, [])"
"opinion, Chunxu Wu(2009)","When the review where an opinion lies in, cannot provide enough contextual information to determine the orientation of opinion, Chunxu Wu(2009) proposed an approach which resort to other reviews discussing the same topic to mine useful contextual information, then use semantic similarity measures to judge the orientation of opinion.","['opinion', 'semantic', 'other', 'cannot', 'useful', 'contextual', 'same']","(1, ['useful'])","(0, [])"
"tan, 2008","The Naive Bayes algorithm is widely used algorithm for document classification (Melville et al., 2009; Rui Xia, 2011; Ziqiong, 2011; Songho tan, 2008 2012, IJARCSSE All Rights Reserved Page | 283 Support vector machines (SVM), a discriminative classifier is considered the best text classification method (Rui Xia, 2011; Ziqiong, 2011; Songho tan, 2008 and Rudy Prabowo, 2009). The idea behind the centroid classification algorithm is extremely simple and straightforward (Songho tan, 2008). The similarity score of each nearest neighbor document to the test document is used as the weight of the classes of the neighbor document (Songho tan, 2008). During the training phase, with a collection of training data, this process is repeated several times by iterating on the data (Songho tan, 2008).","['simple', 'nearest', 'centroid', 'discriminative', 'naive', 'best', 'several', 'straightforward', 'text']","(2, ['best', 'straightforward'])","(1, ['naive'])"
using 2012,"Andrea Esuli and Fabrizio Sebastiani (2005) proposed semi-supervised learning method started from expanding an initial seed set using 2012, IJARCSSE All Rights Reserved Page | 285 Negation is a very common linguistic construction that affects polarity and therefore, needs to be taken into consideration in sentiment analysis.","['andrea', 'common', 'initial', 'semisupervised', 'linguistic']","(0, [])","(0, [])"
xu (2010),"Bing xu (2010) , presented a Conditional Random Fields model based Chinese product features identification approach, integrating the chunk features and heuristic position information in addition to the word features, part-of-speech features and context features.","['heuristic', 'conditional', 'chinese', 'partofspeech']","(0, [])","(0, [])"
"Abbasi et al., 2008","In terms of classi cation algorithms, support vector machines (SVMs) are widely used (Abbasi et al., 2008; Abbasi et al., 2008; Argamon et al., 2007; Gamon, 2004; Mishne, 2005; Wilson, Wiebe, & Hwa, 2006) because they seem to perform as well or better than other methods in most machine learning contexts.","['argamon', 'most', 'better', 'other']","(1, ['better'])","(0, [])"
"Abbasi, Chen, & Salem, 2008","An entropy-weighted genetic algorithm can also perform better than standard feature reduction approaches (Abbasi, Chen, & Salem, 2008).","['entropyweighted', 'better', 'genetic', 'standard']","(1, ['better'])","(0, [])"
"Abbasi, Chen, Thoms, & Fu, 2008","Opinion mining algorithms often use machine learning to identify general features associated with positive and negative sentiment, where these features could be a subset of the words in the document, parts of speech or n-grams (i.e., the frequency of occurrence of all n consecutive words, where n is typically 1, 2, or 3; Abbasi, Chen, Thoms, & Fu, 2008; Ng, Dasgupta, & Ari n, 2006; Tang, Tan, & Cheng, 2009).","['positive', 'general', 'abbasi', 'negative', 'ngrams', 'consecutive']","(1, ['positive'])","(1, ['negative'])"
"Argamon et al., 2007","In terms of classi cation algorithms, support vector machines (SVMs) are widely used (Abbasi et al., 2008; Abbasi et al., 2008; Argamon et al., 2007; Gamon, 2004; Mishne, 2005; Wilson, Wiebe, & Hwa, 2006) because they seem to perform as well or better than other methods in most machine learning contexts. This did not perform as well as unigrams, but the combined performance was better than that of unigrams alone (Argamon et al., 2007).","['combined', 'other', 'alone', 'unigrams', 'argamon', 'most', 'better']","(1, ['better'])","(0, [])"
"Artstein & Poesio, 2008","The appropriate type of intercoder reliability statistic for this kind of data with multiple coders and varying differences between categories is Krippendorff s (Artstein & Poesio, 2008; Krippendorff, 2004). In contrast, SentiStrength was able to identify negative sentiment little better (1.8%) than the baseline, probably due to creativity in expressing negative comments or due to the dif culty in getting signi cantly above the baseline when one category dominates (Artstein & Poesio, 2008; Krippendorff, 2004).","['krippendorff', 'multiple', 'appropriate', 'due', 'signi', 'able', 'negative', 'little', 'better']","(2, ['appropriate', 'better'])","(1, ['negative'])"
August 2010,"For instance, programs to monitor sentiment in Received September 25, 2009; revised May 25, 2010; accepted July 6, 2010 2010 ASIS&T Published online 17 August 2010 in Wiley Online Library (wileyonlinelibrary.com).","['instance', 'wiley', 'august', 'received', 'online']","(0, [])","(0, [])"
"Baccianella, Esuli, & Sebastiani, 2010","One is to have a dictionary of positive and negative words (e.g., love, hate), such as that found in General Inquirer (Stone, Dunphy, Smith, & Ogilvie, 1966), WordNet Affect (Strapparava & Valitutti, 2004), SentiWordNet (Baccianella, Esuli, & Sebastiani, 2010; Esuli & Sebastiani, 2006) or Q-WordNet (Agerri & Garc a-Serrano, 2010), and to count how often they occur.","['such', 'love', 'positive', 'general', 'negative', 'aserrano', 'qwordnet']","(2, ['love', 'positive'])","(1, ['negative'])"
"Balahur et al., 2010","Opinion mining typically occurs in two or three stages, although more may be needed for some tasks (e.g., Balahur et al., 2010).","['more', 'balahur']","(0, [])","(0, [])"
"Balahur, Kozareva, & Montoyo, 2009","In addition, basic research to understand the role of emotion in online communication (e.g., Derks, Fischer, & Bos, 2008; e.g., Hancock, Gee, Ciaccio, & Lin, 2008; Nardi, 2005) would also bene t from ne-grained sentiment detection, as would the growing body of psychology and other social science research into the role of sentiment in various types of discussion or general discourse (Balahur, Kozareva, & Montoyo, 2009; Pennebaker, Mehl, & Niederhoffer, 2003; Short & Palmer, 2008).","['addition', 'niederhoffer', 'short', 'general', 'other', 'negrained', 'various', 'nardi', 'social', 'basic', 'palmer', 'online']","(0, [])","(0, [])"
"Baron, 2003","Perhaps most famous is mobile phone text language with its abbreviations, emoticons, and truncated sentences (Grinter & Eldridge, 2003; Thurlow, 2003), but similar styles are evident in many other forms of computer-mediated communication, including chatrooms, bulletin boards, and social network sites (Baron, 2003; Crystal, 2006). Although sometimes seen as poor language use, these are a natural response to the technological affordances and social factors associated with a system (Baron, 2003; Walther & Parks, 2002).","['poor', 'thurlow', 'use', 'famous', 'technological', 'mobile', 'truncated', 'many', 'similar', 'other', 'social', 'evident', 'natural', 'computermediated']","(1, ['famous'])","(1, ['poor'])"
"Barrett, 2006","Emotions are perceived differently by individuals, partly because of their life experiences and partly because of personality issues (Barrett, 2006) and gender (Stoppard & Gunn Gruchy, 1993).",[],"(0, [])","(0, [])"
"Brill, 1992","These variations cause problems because typical linguistic sentiment analysis programs start with part of speech tagging (e.g., Brill, 1992), which is reliant upon standard spelling and grammar, and/or apply rules that assume at least correct spelling, if not correct grammar.","['typical', 'correct', 'standard', 'reliant', 'least', 'linguistic']","(1, ['correct'])","(0, [])"
"Chaumartin, 2007","The best system (for ne-grained evaluation) was one previously designed for newspaper headlines, UPAR7 (Chaumartin, 2007), which used linguistic parsing and tagging as well as WordNet, SentiWordNet, and WordNet Affect, hence relying upon reasonably correct standard grammar and spelling.","['correct', 'upar', 'negrained', 'for', 'best', 'linguistic']","(2, ['correct', 'best'])","(0, [])"
"Choi & Cardie, 2008","For example, phrase analysis techniques could be applied to identify both positive and negative sentiment even within individual sentences (Choi & Cardie, 2008; Wilson, 2008; Wilson, Wiebe, & Hoffman, 2009). An alternative opinion mining technique has used a primarily linguistic approach: simple rules based upon compositional semantics (information about likely meanings of a word based upon the surrounding text) to detect the polarity of an expression (Choi & Cardie, 2008).","['individual', 'alternative', 'simple', 'positive', 'likely', 'example', 'compositional', 'negative', 'linguistic']","(1, ['positive'])","(1, ['negative'])"
"Cohen, 1995","Here, SVM regression was outperformed by both the rule-based learning Ripper (Cohen, 1995) and BoosTexter, a boosting algorithm combining multiple weak classi ers (Schapire & Singer, 2000).","['multiple', 'rulebased', 'weak']","(0, [])","(1, ['weak'])"
"Cornelius, 1996","Detecting Multiple Emotions Psychology of emotion research argues that though positive and negative sentiment are important dimensions, there are many different widely socially recognized types of emotion and the strength of emotions (arousal level) can vary (e.g., Cornelius, 1996; Fox, 2008).","['positive', 'multiple', 'many', 'important', 'different', 'negative']","(2, ['positive', 'important'])","(1, ['negative'])"
"Crystal, 2006","Perhaps most famous is mobile phone text language with its abbreviations, emoticons, and truncated sentences (Grinter & Eldridge, 2003; Thurlow, 2003), but similar styles are evident in many other forms of computer-mediated communication, including chatrooms, bulletin boards, and social network sites (Baron, 2003; Crystal, 2006).","['thurlow', 'famous', 'mobile', 'truncated', 'many', 'similar', 'other', 'social', 'evident', 'computermediated']","(1, ['famous'])","(0, [])"
"Das & Chen, 2001","Modi cations of this approach include the identi cation of negating terms (Das & Chen, 2001), words that enhance sentiment in other words (e.g., really love, absolutely hate) and overall sentence structures (Turney, 2002).","['love', 'modi', 'other', 'identi', 'overall']","(1, ['love'])","(0, [])"
"Denecke & Nejdl, 2009","There are also applications unrelated to marketing, such as differentiating between emotional and informative social media content (Denecke & Nejdl, 2009).","['such', 'informative', 'social', 'emotional', 'content']","(0, [])","(0, [])"
"Derks, Fischer, & Bos, 2008","In addition, basic research to understand the role of emotion in online communication (e.g., Derks, Fischer, & Bos, 2008; e.g., Hancock, Gee, Ciaccio, & Lin, 2008; Nardi, 2005) would also bene t from ne-grained sentiment detection, as would the growing body of psychology and other social science research into the role of sentiment in various types of discussion or general discourse (Balahur, Kozareva, & Montoyo, 2009; Pennebaker, Mehl, & Niederhoffer, 2003; Short & Palmer, 2008).","['addition', 'niederhoffer', 'short', 'general', 'other', 'negrained', 'various', 'nardi', 'social', 'basic', 'palmer', 'online']","(0, [])","(0, [])"
"Diener & Emmons, 1984","Although this model is useful, other research has shown that positive and negative sentiment can coexist (e.g., Fox, 2008, p. 127) and are relatively independent in many contexts particularly when sentiment levels are not extreme and over longer time periods (Diener & Emmons, 1984; Huppert & Whittington, 2003; Watson, 1988; Watson, Clark, & Tellegen, 1988) and so it also seems reasonable to conceive sentiment as separately measurable positive and negative components, as encoded in a popular psychology research instrument (Watson et al., 1988).","['reasonable', 'positive', 'conceive', 'other', 'many', 'independent', 'popular', 'useful', 'longer', 'negative', 'measurable', 'extreme']","(4, ['reasonable', 'positive', 'popular', 'useful'])","(1, ['negative'])"
Each JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY December 2010,Each JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY December 2010 DOI: 10.1002/asi 2549,['american'],"(0, [])","(0, [])"
"Ekman, 1992","One computer science initiative has attempted to identify various emotions in text, focusing on the six so-called basic emotions (Ekman, 1992; Fox, 2008) of anger, disgust, fear, joy, sadness, and surprise (Strapparava & Mihalcea, 2008).","['fox', 'various', 'basic', 'socalled']","(0, [])","(0, [])"
"Esuli & Sebastiani, 2006","One is to have a dictionary of positive and negative words (e.g., love, hate), such as that found in General Inquirer (Stone, Dunphy, Smith, & Ogilvie, 1966), WordNet Affect (Strapparava & Valitutti, 2004), SentiWordNet (Baccianella, Esuli, & Sebastiani, 2010; Esuli & Sebastiani, 2006) or Q-WordNet (Agerri & Garc a-Serrano, 2010), and to count how often they occur.","['such', 'love', 'positive', 'general', 'negative', 'aserrano', 'qwordnet']","(2, ['love', 'positive'])","(1, ['negative'])"
"Fox, 2008","Detecting Multiple Emotions Psychology of emotion research argues that though positive and negative sentiment are important dimensions, there are many different widely socially recognized types of emotion and the strength of emotions (arousal level) can vary (e.g., Cornelius, 1996; Fox, 2008). Although this model is useful, other research has shown that positive and negative sentiment can coexist (e.g., Fox, 2008, p. 127) and are relatively independent in many contexts particularly when sentiment levels are not extreme and over longer time periods (Diener & Emmons, 1984; Huppert & Whittington, 2003; Watson, 1988; Watson, Clark, & Tellegen, 1988) and so it also seems reasonable to conceive sentiment as separately measurable positive and negative components, as encoded in a popular psychology research instrument (Watson et al., 1988). One computer science initiative has attempted to identify various emotions in text, focusing on the six so-called basic emotions (Ekman, 1992; Fox, 2008) of anger, disgust, fear, joy, sadness, and surprise (Strapparava & Mihalcea, 2008).","['conceive', 'many', 'longer', 'measurable', 'various', 'independent', 'popular', 'basic', 'positive', 'multiple', 'other', 'important', 'negative', 'fox', 'reasonable', 'useful', 'different', 'extreme', 'socalled']","(5, ['popular', 'positive', 'important', 'reasonable', 'useful'])","(1, ['negative'])"
"Fox, 2008, p. 127","Although this model is useful, other research has shown that positive and negative sentiment can coexist (e.g., Fox, 2008, p. 127) and are relatively independent in many contexts particularly when sentiment levels are not extreme and over longer time periods (Diener & Emmons, 1984; Huppert & Whittington, 2003; Watson, 1988; Watson, Clark, & Tellegen, 1988) and so it also seems reasonable to conceive sentiment as separately measurable positive and negative components, as encoded in a popular psychology research instrument (Watson et al., 1988).","['reasonable', 'positive', 'conceive', 'other', 'many', 'independent', 'popular', 'useful', 'longer', 'negative', 'measurable', 'extreme']","(4, ['reasonable', 'positive', 'popular', 'useful'])","(1, ['negative'])"
"Fullwood & Martino, 2007","Widely recognized innovations include emoticons like :-) that are reasonably effective in conveying emotion (Derks, Bos, & von Grumbkow, 2008; Fullwood & Martino, 2007) and word abbreviations like m8 (mate) and u (you) (Thurlow, 2003).",['effective'],"(1, ['effective'])","(0, [])"
"Gamon, 2004","information gain (Riloff, Patwardhan, & Wiebe, 2006), or log likelihood (Gamon, 2004). In terms of classi cation algorithms, support vector machines (SVMs) are widely used (Abbasi et al., 2008; Abbasi et al., 2008; Argamon et al., 2007; Gamon, 2004; Mishne, 2005; Wilson, Wiebe, & Hwa, 2006) because they seem to perform as well or better than other methods in most machine learning contexts. Nevertheless, a study of poor grammatical quality texts in online customer feedback showed that linguistic approaches could improve classi cation slightly when added to bag of words (1-grams) approaches, although aggressive feature reduction had a similar impact to adding linguistic features (Gamon, 2004). Previous work has shown that this approach is promising, particularly via dependency trees (Wilson et al., 2009) and that, given a large enough training sample, improvements may be possible even in poor-quality text (Gamon, 2004).","['poor', 'promising', 'possible', 'grams', 'previous', 'online', 'grammatical', 'most', 'sample', 'other', 'similar', 'large', 'linguistic', 'log', 'argamon', 'enough', 'approaches', 'aggressive', 'contexts', 'better']","(3, ['promising', 'enough', 'better'])","(2, ['poor', 'aggressive'])"
"Gamon, Aue, CorstonOliver, & Ringger, 2005","Finally, the object about which the opinion is expressed may be extracted (e.g., Gamon, Aue, CorstonOliver, & Ringger, 2005).",[],"(0, [])","(0, [])"
"Gill, Gergle, French, & Oberlander, 2008","Moreover, one previous article noted that intercoder agreement was higher on longer (blog) texts (Gill, Gergle, French, & Oberlander, 2008), suggesting that obtaining agreement on the short texts here would be dif cult.","['short', 'dif', 'previous', 'higher', 'longer']","(0, [])","(0, [])"
"Grinter & Eldridge, 2003","Perhaps most famous is mobile phone text language with its abbreviations, emoticons, and truncated sentences (Grinter & Eldridge, 2003; Thurlow, 2003), but similar styles are evident in many other forms of computer-mediated communication, including chatrooms, bulletin boards, and social network sites (Baron, 2003; Crystal, 2006).","['thurlow', 'famous', 'mobile', 'truncated', 'many', 'similar', 'other', 'social', 'evident', 'computermediated']","(1, ['famous'])","(0, [])"
"Hancock, Gee, Ciaccio, & Lin, 2008","In addition, basic research to understand the role of emotion in online communication (e.g., Derks, Fischer, & Bos, 2008; e.g., Hancock, Gee, Ciaccio, & Lin, 2008; Nardi, 2005) would also bene t from ne-grained sentiment detection, as would the growing body of psychology and other social science research into the role of sentiment in various types of discussion or general discourse (Balahur, Kozareva, & Montoyo, 2009; Pennebaker, Mehl, & Niederhoffer, 2003; Short & Palmer, 2008).","['addition', 'niederhoffer', 'short', 'general', 'other', 'negrained', 'various', 'nardi', 'social', 'basic', 'palmer', 'online']","(0, [])","(0, [])"
"Hopkins & King, 2010","A similar aggregation approach has been applied subsequently in a range of social science contexts (Hopkins & King, 2010).","['social', 'similar']","(0, [])","(0, [])"
"Huang, Goh, & Liew, 2007","DOI: 10.1002/asi.21416 online communication, perhaps designed to identify and intervene when inappropriate emotions are used or to identify at risk users (e.g., Huang, Goh, & Liew, 2007), would need to be sensitive to the strength of sentiment expressed and whether participants were appropriately balancing positive and negative sentiment.","['positive', 'sensitive', 'negative', 'huang', 'inappropriate']","(2, ['positive', 'sensitive'])","(2, ['negative', 'inappropriate'])"
"Huppert & Whittington, 2003","Although this model is useful, other research has shown that positive and negative sentiment can coexist (e.g., Fox, 2008, p. 127) and are relatively independent in many contexts particularly when sentiment levels are not extreme and over longer time periods (Diener & Emmons, 1984; Huppert & Whittington, 2003; Watson, 1988; Watson, Clark, & Tellegen, 1988) and so it also seems reasonable to conceive sentiment as separately measurable positive and negative components, as encoded in a popular psychology research instrument (Watson et al., 1988).","['reasonable', 'positive', 'conceive', 'other', 'many', 'independent', 'popular', 'useful', 'longer', 'negative', 'measurable', 'extreme']","(4, ['reasonable', 'positive', 'popular', 'useful'])","(1, ['negative'])"
JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY December 2010,"Feature selection, data processing to remove the least useful n-grams, has been shown to slightly improve classi cation performance, for example, by choosing a restricted set of features (e.g., 5,000) that score highest on a measure like JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY December 2010 DOI: 10.1002/asi 2545 Linguistic Inquiry and Word Count has been used by psychology 2546 JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY December 2010 DOI: 10.1002/asi JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY December 2010 DOI: 10.1002/asi 2547 These values 2548 JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY December 2010 DOI: 10.1002/asi Each JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY December 2010 DOI: 10.1002/asi 2549 Hence, 2550 JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY December 2010 DOI: 10.1002/asi The feature sets are 1-3-grams; 1-3-grams with emoticons; 1-3-grams with punctuation; 1-3grams with misspellings (i.e., including terms before spelling JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY December 2010 DOI: 10.1002/asi 2551 For instance, the trigram I love you will also 2552 JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY December 2010 DOI: 10.1002/asi Nevertheless, its accuracy is lower than the SentiStrength standard version, although the difference is not statistically signi cant (accuracy = 59.42%, accuracy 1 = 96.60%, correlation = 0.5822, mean absolute error = 22.65%; only the mean absolute error difference is statistically signi cant from SentiStrength standard JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY December 2010 DOI: 10.1002/asi 2553 Perhaps comments using nonstandard features tend to use 2554 JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY December 2010 DOI: 10.1002/asi It seems that both positive and negative sentiment detection in informal text language like MySpace comments is challenging because of several factors: language creativity, expressions of sentiment without emotion-bearing words, and differences between human JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY December 2010 DOI: 10.1002/asi 2555","['sentistrength', 'highest', 'emoticons', 'lower', 'grams', 'emotionbearing', 'text', 'punctuation', 'positive', 'standard', 'creativity', 'cant', 'negative', 'linguistic', 'several', 'nonstandard', 'mean', 'american', 'signi', 'useful', 'restricted', 'least', 'informal', 'factors', 'human']","(2, ['positive', 'useful'])","(2, ['negative', 'restricted'])"
"Kaji & Kitsuregawa, 2007","Opinion mining normally deals with only positive and negative sentiment rather than discrete emotions (e.g., happiness, surprise), does not detect sentiment strength (but sometimes uses the strength of association of words with positive or negative sentiment, e.g., Kaji & Kitsuregawa, 2007), and does not simultaneously identify both positive and negative emotions.","['happiness', 'discrete', 'positive', 'negative']","(2, ['happiness', 'positive'])","(1, ['negative'])"
"Krippendorff, 2004","The appropriate type of intercoder reliability statistic for this kind of data with multiple coders and varying differences between categories is Krippendorff s (Artstein & Poesio, 2008; Krippendorff, 2004). In contrast, SentiStrength was able to identify negative sentiment little better (1.8%) than the baseline, probably due to creativity in expressing negative comments or due to the dif culty in getting signi cantly above the baseline when one category dominates (Artstein & Poesio, 2008; Krippendorff, 2004).","['krippendorff', 'multiple', 'appropriate', 'due', 'signi', 'able', 'negative', 'little', 'better']","(2, ['appropriate', 'better'])","(1, ['negative'])"
"Kukich, 1992","but this is based upon the assumption that spelling deviations are likely to be accidental mistakes (Kukich, 1992; Pollock & Zamora, 1984) and so current algorithms are unlikely to work well with deliberately nonstandard spellings.","['likely', 'current', 'accidental', 'nonstandard', 'unlikely']","(0, [])","(2, ['accidental', 'unlikely'])"
"Liu, Lieberman, & Selker, 2003","Linguistic processing has also been combined with a preexisting large collection of subjective common sense statement patterns and applied to relatively informal and domain-independent in e-mail messages to detect multiple emotions (Liu, Lieberman, & Selker, 2003).","['multiple', 'domainindependent', 'large', 'subjective', 'common', 'linguistic', 'informal', 'email']","(0, [])","(0, [])"
"Mauss & Robinson, 2009","Although there are many ways to measure emotion (Mauss & Robinson, 2009; Wiebe, Wilson, & Cardie, 2005), human coder subjective judgments were used as an appropriate way to gather suf cient results.","['suf', 'many', 'appropriate', 'subjective', 'human']","(1, ['appropriate'])","(0, [])"
"Mishne, 2005","In terms of classi cation algorithms, support vector machines (SVMs) are widely used (Abbasi et al., 2008; Abbasi et al., 2008; Argamon et al., 2007; Gamon, 2004; Mishne, 2005; Wilson, Wiebe, & Hwa, 2006) because they seem to perform as well or better than other methods in most machine learning contexts. The improvement was probably due to the large data set available (40,884 documents with an average of 2.26 sentences each), as has been previously claimed for an analysis of informal text (Mishne, 2005). This is probably because the texts analyzed are typically short (average 200 words) and there are many moods, some of which are very similar to each other, although even a binary categorization task also had limited success (Mishne, 2005).","['short', 'other', 'many', 'similar', 'due', 'large', 'binary', 'informal', 'argamon', 'most', 'better', 'available']","(2, ['better', 'available'])","(0, [])"
"Nardi, 2005","In addition, basic research to understand the role of emotion in online communication (e.g., Derks, Fischer, & Bos, 2008; e.g., Hancock, Gee, Ciaccio, & Lin, 2008; Nardi, 2005) would also bene t from ne-grained sentiment detection, as would the growing body of psychology and other social science research into the role of sentiment in various types of discussion or general discourse (Balahur, Kozareva, & Montoyo, 2009; Pennebaker, Mehl, & Niederhoffer, 2003; Short & Palmer, 2008).","['addition', 'niederhoffer', 'short', 'general', 'other', 'negrained', 'various', 'nardi', 'social', 'basic', 'palmer', 'online']","(0, [])","(0, [])"
"Neviarouskaya, Prendinger, & Ishizuka, 2007","), emoticons, and capital letters as well as translating abbreviations (Neviarouskaya, Prendinger, & Ishizuka, 2007).",[],"(0, [])","(0, [])"
"Ng et al., 2006","Other features used with some success include emoticons in online movie reviews (Read, 2005), which seem so be more domain-independent than words; lexico-syntactic patterns (e.g., Riloff & Wiebe, 2003); and arti cial features derived from adjective polarity lists (Ng et al., 2006).","['more', 'other', 'lexicosyntactic', 'domainindependent', 'adjective', 'arti', 'online', 'words', 'cial']","(0, [])","(0, [])"
"Pang & Lee, 2004","First, the input text is split into sections, such as sentences, and each section tested to see if it contains any sentiment: if it is subjective or objective (Pang & Lee, 2004).","['objective', 'subjective', 'such']","(0, [])","(0, [])"
"Pang & Lee, 2005","One previous study used modi ed sentiment analysis techniques to predict the strength of human ratings on a scale of 1 to 5 for movie reviews (Pang & Lee, 2005).","['previous', 'human']","(0, [])","(0, [])"
"Pang & Lee, 2008","Opinion Mining Opinion mining, also known as sentiment analysis, is the extraction of positive or negative opinions from (unstructured) text (Pang & Lee, 2008). Although sentiment analysis is normally concerned with opinions (Pang & Lee, 2008), Wilson (2008) has generalized this to the psychological task of identifying the author s hidden internal state from their text.","['internal', 'positive', 'hidden', 'negative', 'psychological']","(1, ['positive'])","(1, ['negative'])"
"Pennebaker et al., 2003","researchers to investigate the connection between language and psychology (Pennebaker et al., 2003) and also as a practical tool, for example, to detect how well people are likely to cope with bereavement based upon their language use (Pennebaker, Mayne, & Francis, 1997).","['likely', 'practical']","(0, [])","(0, [])"
"Pennebaker, Mayne, & Francis, 1997","researchers to investigate the connection between language and psychology (Pennebaker et al., 2003) and also as a practical tool, for example, to detect how well people are likely to cope with bereavement based upon their language use (Pennebaker, Mayne, & Francis, 1997).","['likely', 'practical']","(0, [])","(0, [])"
"Pennebaker, Mehl, & Niederhoffer, 2003","In addition, basic research to understand the role of emotion in online communication (e.g., Derks, Fischer, & Bos, 2008; e.g., Hancock, Gee, Ciaccio, & Lin, 2008; Nardi, 2005) would also bene t from ne-grained sentiment detection, as would the growing body of psychology and other social science research into the role of sentiment in various types of discussion or general discourse (Balahur, Kozareva, & Montoyo, 2009; Pennebaker, Mehl, & Niederhoffer, 2003; Short & Palmer, 2008).","['addition', 'niederhoffer', 'short', 'general', 'other', 'negrained', 'various', 'nardi', 'social', 'basic', 'palmer', 'online']","(0, [])","(0, [])"
"Pollock & Zamora, 1984","but this is based upon the assumption that spelling deviations are likely to be accidental mistakes (Kukich, 1992; Pollock & Zamora, 1984) and so current algorithms are unlikely to work well with deliberately nonstandard spellings. Formal spelling correction algorithms (see Pollock & Zamora, 1984) were tried but not used as they made very few corrections and had problems with names and slang.","['likely', 'current', 'accidental', 'formal', 'nonstandard', 'unlikely', 'few']","(0, [])","(2, ['accidental', 'unlikely'])"
"Prabowo & Thelwall, 2009","Rules-based methods have also been used to identify structures in sentences associated with sentiment (Prabowo & Thelwall, 2009; Wu, Chuang, & Lin, 2006).",['rulesbased'],"(0, [])","(0, [])"
"Read, 2005","Other features used with some success include emoticons in online movie reviews (Read, 2005), which seem so be more domain-independent than words; lexico-syntactic patterns (e.g., Riloff & Wiebe, 2003); and arti cial features derived from adjective polarity lists (Ng et al., 2006). Nevertheless, with a few exceptions (Read, 2005; Wilson et al., 2006), explicit comparisons with other methods have not been included in opinion mining publications.","['more', 'other', 'lexicosyntactic', 'few', 'domainindependent', 'adjective', 'arti', 'online', 'explicit', 'words', 'cial']","(0, [])","(0, [])"
"Riloff & Wiebe, 2003","Other features used with some success include emoticons in online movie reviews (Read, 2005), which seem so be more domain-independent than words; lexico-syntactic patterns (e.g., Riloff & Wiebe, 2003); and arti cial features derived from adjective polarity lists (Ng et al., 2006).","['more', 'other', 'lexicosyntactic', 'domainindependent', 'adjective', 'arti', 'online', 'words', 'cial']","(0, [])","(0, [])"
"Riloff et al., 2006","When using n-grams (and lexico-syntactic patterns) small improvements can also be made by pruning the feature set of features that are subsumed by simpler features that have stronger information gain values (Riloff et al., 2006).","['stronger', 'lexicosyntactic', 'small', 'ngrams']","(1, ['stronger'])","(0, [])"
"Riloff, Patwardhan, & Wiebe, 2006","information gain (Riloff, Patwardhan, & Wiebe, 2006), or log likelihood (Gamon, 2004).",['log'],"(0, [])","(0, [])"
"Russell, 1979","In the dimensional model of emotion from psychology (Russell, 1979), sentiment can always be fundamentally split into two axes: arousal (low to high) and valence (positive to negative).","['axes', 'dimensional', 'positive']","(1, ['positive'])","(0, [])"
"Schapire & Singer, 2000","Here, SVM regression was outperformed by both the rule-based learning Ripper (Cohen, 1995) and BoosTexter, a boosting algorithm combining multiple weak classi ers (Schapire & Singer, 2000).","['multiple', 'rulebased', 'weak']","(0, [])","(1, ['weak'])"
"Short & Palmer, 2008","In addition, basic research to understand the role of emotion in online communication (e.g., Derks, Fischer, & Bos, 2008; e.g., Hancock, Gee, Ciaccio, & Lin, 2008; Nardi, 2005) would also bene t from ne-grained sentiment detection, as would the growing body of psychology and other social science research into the role of sentiment in various types of discussion or general discourse (Balahur, Kozareva, & Montoyo, 2009; Pennebaker, Mehl, & Niederhoffer, 2003; Short & Palmer, 2008).","['addition', 'niederhoffer', 'short', 'general', 'other', 'negrained', 'various', 'nardi', 'social', 'basic', 'palmer', 'online']","(0, [])","(0, [])"
"Snyder & Barzilay, 2007","Linguistic features have also been successfully used to extend opinion mining to a multiaspect variant that is able to detect opinions about different aspects of a topic (Snyder & Barzilay, 2007).","['linguistic', 'able', 'different']","(0, [])","(0, [])"
"Stone, Dunphy, Smith, & Ogilvie, 1966","One is to have a dictionary of positive and negative words (e.g., love, hate), such as that found in General Inquirer (Stone, Dunphy, Smith, & Ogilvie, 1966), WordNet Affect (Strapparava & Valitutti, 2004), SentiWordNet (Baccianella, Esuli, & Sebastiani, 2010; Esuli & Sebastiani, 2006) or Q-WordNet (Agerri & Garc a-Serrano, 2010), and to count how often they occur.","['such', 'love', 'positive', 'general', 'negative', 'aserrano', 'qwordnet']","(2, ['love', 'positive'])","(1, ['negative'])"
"Stoppard & Gunn Gruchy, 1993","Emotions are perceived differently by individuals, partly because of their life experiences and partly because of personality issues (Barrett, 2006) and gender (Stoppard & Gunn Gruchy, 1993).",[],"(0, [])","(0, [])"
"Strapparava & Mihalcea, 2008","One computer science initiative has attempted to identify various emotions in text, focusing on the six so-called basic emotions (Ekman, 1992; Fox, 2008) of anger, disgust, fear, joy, sadness, and surprise (Strapparava & Mihalcea, 2008). Sentiment Strength Detection In addition to the research discussed above concerning strength detection for multiple emotions (Strapparava & Mihalcea, 2008), there is some work on positive negative sentiment strength detection.","['fox', 'positive', 'multiple', 'various', 'basic', 'negative', 'socalled']","(1, ['positive'])","(1, ['negative'])"
"Strapparava & Valitutti, 2004","One is to have a dictionary of positive and negative words (e.g., love, hate), such as that found in General Inquirer (Stone, Dunphy, Smith, & Ogilvie, 1966), WordNet Affect (Strapparava & Valitutti, 2004), SentiWordNet (Baccianella, Esuli, & Sebastiani, 2010; Esuli & Sebastiani, 2006) or Q-WordNet (Agerri & Garc a-Serrano, 2010), and to count how often they occur.","['such', 'love', 'positive', 'general', 'negative', 'aserrano', 'qwordnet']","(2, ['love', 'positive'])","(1, ['negative'])"
"Tang, Tan, & Cheng, 2009","Opinion mining algorithms often use machine learning to identify general features associated with positive and negative sentiment, where these features could be a subset of the words in the document, parts of speech or n-grams (i.e., the frequency of occurrence of all n consecutive words, where n is typically 1, 2, or 3; Abbasi, Chen, Thoms, & Fu, 2008; Ng, Dasgupta, & Ari n, 2006; Tang, Tan, & Cheng, 2009).","['positive', 'general', 'abbasi', 'negative', 'ngrams', 'consecutive']","(1, ['positive'])","(1, ['negative'])"
"Thelwall, 2009","Probably as a result of these factors 95% of English public comments exchanged between friends contain at least one abbreviation from standard English (Thelwall, 2009). Comments are typically short (mean 18.7 words, median 13 words, 68 characters; Thelwall, 2009), but positive emotion is common (Thelwall, Wilkinson, & Uppal, 2010). Rules-based methods have also been used to identify structures in sentences associated with sentiment (Prabowo & Thelwall, 2009; Wu, Chuang, & Lin, 2006).","['uppal', 'short', 'median', 'positive', 'standard', 'public', 'rulesbased', 'least', 'common', 'english', 'mean']","(1, ['positive'])","(0, [])"
"Thelwall, Wilkinson, & Uppal, 2010","Comments are typically short (mean 18.7 words, median 13 words, 68 characters; Thelwall, 2009), but positive emotion is common (Thelwall, Wilkinson, & Uppal, 2010).","['uppal', 'short', 'median', 'positive', 'common', 'mean']","(1, ['positive'])","(0, [])"
"Thurlow, 2003","Perhaps most famous is mobile phone text language with its abbreviations, emoticons, and truncated sentences (Grinter & Eldridge, 2003; Thurlow, 2003), but similar styles are evident in many other forms of computer-mediated communication, including chatrooms, bulletin boards, and social network sites (Baron, 2003; Crystal, 2006). Widely recognized innovations include emoticons like :-) that are reasonably effective in conveying emotion (Derks, Bos, & von Grumbkow, 2008; Fullwood & Martino, 2007) and word abbreviations like m8 (mate) and u (you) (Thurlow, 2003).","['thurlow', 'famous', 'mobile', 'truncated', 'many', 'similar', 'other', 'social', 'effective', 'evident', 'computermediated']","(2, ['famous', 'effective'])","(0, [])"
"Turney, 2002","Modi cations of this approach include the identi cation of negating terms (Das & Chen, 2001), words that enhance sentiment in other words (e.g., really love, absolutely hate) and overall sentence structures (Turney, 2002).","['love', 'modi', 'other', 'identi', 'overall']","(1, ['love'])","(0, [])"
"Walther & Parks, 2002","Although sometimes seen as poor language use, these are a natural response to the technological affordances and social factors associated with a system (Baron, 2003; Walther & Parks, 2002).","['poor', 'use', 'social', 'natural', 'technological']","(0, [])","(1, ['poor'])"
"Watson et al., 1988","Although this model is useful, other research has shown that positive and negative sentiment can coexist (e.g., Fox, 2008, p. 127) and are relatively independent in many contexts particularly when sentiment levels are not extreme and over longer time periods (Diener & Emmons, 1984; Huppert & Whittington, 2003; Watson, 1988; Watson, Clark, & Tellegen, 1988) and so it also seems reasonable to conceive sentiment as separately measurable positive and negative components, as encoded in a popular psychology research instrument (Watson et al., 1988).","['reasonable', 'positive', 'conceive', 'other', 'many', 'independent', 'popular', 'useful', 'longer', 'negative', 'measurable', 'extreme']","(4, ['reasonable', 'positive', 'popular', 'useful'])","(1, ['negative'])"
"Watson, 1988","Although this model is useful, other research has shown that positive and negative sentiment can coexist (e.g., Fox, 2008, p. 127) and are relatively independent in many contexts particularly when sentiment levels are not extreme and over longer time periods (Diener & Emmons, 1984; Huppert & Whittington, 2003; Watson, 1988; Watson, Clark, & Tellegen, 1988) and so it also seems reasonable to conceive sentiment as separately measurable positive and negative components, as encoded in a popular psychology research instrument (Watson et al., 1988).","['reasonable', 'positive', 'conceive', 'other', 'many', 'independent', 'popular', 'useful', 'longer', 'negative', 'measurable', 'extreme']","(4, ['reasonable', 'positive', 'popular', 'useful'])","(1, ['negative'])"
"Watson, Clark, & Tellegen, 1988","Although this model is useful, other research has shown that positive and negative sentiment can coexist (e.g., Fox, 2008, p. 127) and are relatively independent in many contexts particularly when sentiment levels are not extreme and over longer time periods (Diener & Emmons, 1984; Huppert & Whittington, 2003; Watson, 1988; Watson, Clark, & Tellegen, 1988) and so it also seems reasonable to conceive sentiment as separately measurable positive and negative components, as encoded in a popular psychology research instrument (Watson et al., 1988).","['reasonable', 'positive', 'conceive', 'other', 'many', 'independent', 'popular', 'useful', 'longer', 'negative', 'measurable', 'extreme']","(4, ['reasonable', 'positive', 'popular', 'useful'])","(1, ['negative'])"
"Wiebe et al., 2005","The coders were given verbal instructions for coding each text as well as a booklet explaining the task (motivated by Wiebe et al., 2005), with the key instructions reproduced in the Appendix here. Previous emotion judgment/annotation tasks have obtained higher intercoder scores, but without strength measures and therefore having fewer categories (e.g., Wiebe et al., 2005).","['key', 'fewer', 'verbal', 'previous', 'higher', 'wiebe']","(0, [])","(0, [])"
"Wiebe, Wilson, & Cardie, 2005","Although there are many ways to measure emotion (Mauss & Robinson, 2009; Wiebe, Wilson, & Cardie, 2005), human coder subjective judgments were used as an appropriate way to gather suf cient results.","['suf', 'many', 'appropriate', 'subjective', 'human']","(1, ['appropriate'])","(0, [])"
"Wiebe, Wilson, Bruce, Bell, & Martin, 2004","A more sophisticated approach is to identify text features that could potentially be subjective in some contexts and then use contextual information to decide whether they are subjective in each new context (Wiebe, Wilson, Bruce, Bell, & Martin, 2004).","['new', 'subjective', 'contextual', 'sophisticated', 'text']","(1, ['sophisticated'])","(0, [])"
Wilson (2008),"Although sentiment analysis is normally concerned with opinions (Pang & Lee, 2008), Wilson (2008) has generalized this to the psychological task of identifying the author s hidden internal state from their text.","['internal', 'hidden', 'psychological']","(0, [])","(0, [])"
"Wilson et al., 2006","Nevertheless, with a few exceptions (Read, 2005; Wilson et al., 2006), explicit comparisons with other methods have not been included in opinion mining publications. Sentiment strength classi cation has also been developed for a three-level scheme (low, medium, and high or extreme) for subjective sentences or clauses in newswire texts using a linguistic analysis converting sentences into dependency trees re ecting their structure (Wilson et al., 2006). SentiStrength was able to identify the strength of positive sentiment on a scale of 1 to 5 in 60.6% of the time in informal MySpace language, signi cantly above the best standard machine-learning approaches, which had a performance of up to 58.5% in line with those for a previous four-category opinion intensity classi cation task (Wilson et al., 2006).","['publications', 'high', 'positive', 'standard', 'other', 'previous', 'subjective', 'able', 'threelevel', 'best', 'linguistic', 'informal', 'fourcategory', 'explicit', 'few']","(2, ['positive', 'best'])","(0, [])"
"Wilson et al., 2009","Previous work has shown that this approach is promising, particularly via dependency trees (Wilson et al., 2009) and that, given a large enough training sample, improvements may be possible even in poor-quality text (Gamon, 2004).","['enough', 'promising', 'sample', 'possible', 'previous', 'large']","(2, ['enough', 'promising'])","(0, [])"
"Wilson, 2008","For example, phrase analysis techniques could be applied to identify both positive and negative sentiment even within individual sentences (Choi & Cardie, 2008; Wilson, 2008; Wilson, Wiebe, & Hoffman, 2009). A promising future approach is the incorporation of context about the reasons why sentiment is used, such as differentiating between intention, arguments, and speculation (Wilson, 2008).","['individual', 'promising', 'such', 'positive', 'intention', 'example', 'used', 'negative']","(2, ['promising', 'positive'])","(1, ['negative'])"
"Wilson, Wiebe, & Hoffman, 2009","For example, phrase analysis techniques could be applied to identify both positive and negative sentiment even within individual sentences (Choi & Cardie, 2008; Wilson, 2008; Wilson, Wiebe, & Hoffman, 2009).","['individual', 'example', 'positive', 'negative']","(1, ['positive'])","(1, ['negative'])"
"Wilson, Wiebe, & Hwa, 2006","In terms of classi cation algorithms, support vector machines (SVMs) are widely used (Abbasi et al., 2008; Abbasi et al., 2008; Argamon et al., 2007; Gamon, 2004; Mishne, 2005; Wilson, Wiebe, & Hwa, 2006) because they seem to perform as well or better than other methods in most machine learning contexts.","['argamon', 'most', 'better', 'other']","(1, ['better'])","(0, [])"
"Witten & Frank, 2005","SentiStrength was also compared to a range of standard machine-learning classi cation algorithms in Weka (Witten & Frank, 2005) using the frequencies of each word in the sentiment word list as the feature set.","['machinelearning', 'standard']","(0, [])","(0, [])"
"Wu et al., 2006","and neutral states based upon words used by students describing their daily lives (Wu et al., 2006).","['daily', 'neutral']","(0, [])","(0, [])"
"Wu, Chuang, & Lin, 2006","Rules-based methods have also been used to identify structures in sentences associated with sentiment (Prabowo & Thelwall, 2009; Wu, Chuang, & Lin, 2006).",['rulesbased'],"(0, [])","(0, [])"
"a-Serrano, 2010","One is to have a dictionary of positive and negative words (e.g., love, hate), such as that found in General Inquirer (Stone, Dunphy, Smith, & Ogilvie, 1966), WordNet Affect (Strapparava & Valitutti, 2004), SentiWordNet (Baccianella, Esuli, & Sebastiani, 2010; Esuli & Sebastiani, 2006) or Q-WordNet (Agerri & Garc a-Serrano, 2010), and to count how often they occur.","['such', 'love', 'positive', 'general', 'negative', 'aserrano', 'qwordnet']","(2, ['love', 'positive'])","(1, ['negative'])"
"boyd, 2008","The social network site MySpace, the source of the data used in the current study, is known for its young members, its musical orientation, and its informal communication patterns (boyd, 2008a, 2008b).","['current', 'musical', 'young', 'social', 'informal']","(0, [])","(0, [])"
"by Wiebe et al., 2005","The coders were given verbal instructions for coding each text as well as a booklet explaining the task (motivated by Wiebe et al., 2005), with the key instructions reproduced in the Appendix here.","['key', 'verbal']","(0, [])","(0, [])"
"de Rijke, 2006","A follow up project attempted to derive the proportion of posts with a given mood within a speci c time period using 199 words (1-grams) and word pairs (2-grams) derived from the aggregate of all texts, rather than by classifying individual texts (Mishne & de Rijke, 2006).","['individual', 'speci', 'grams']","(0, [])","(0, [])"
human JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY December 2010,"It seems that both positive and negative sentiment detection in informal text language like MySpace comments is challenging because of several factors: language creativity, expressions of sentiment without emotion-bearing words, and differences between human JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY December 2010 DOI: 10.1002/asi 2555","['positive', 'creativity', 'american', 'negative', 'emotionbearing', 'several', 'informal', 'text', 'factors', 'human']","(1, ['positive'])","(1, ['negative'])"
in 2009,Data Set and Human Judgment of Sentiment Strength MySpace was chosen as a source of test data for this study because it is a public environment containing a large quantity of informal text language and is important in its own right as one of the most visited Web sites in the world in 2009.,"['public', 'large', 'important', 'own', 'visited', 'informal', 'text', 'human']","(1, ['important'])","(0, [])"
in December 2008,The comments were extracted in December 2008.,[],"(0, [])","(0, [])"
like JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY December 2010,"Feature selection, data processing to remove the least useful n-grams, has been shown to slightly improve classi cation performance, for example, by choosing a restricted set of features (e.g., 5,000) that score highest on a measure like JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY December 2010 DOI: 10.1002/asi 2545","['highest', 'american', 'useful', 'restricted', 'least']","(1, ['useful'])","(1, ['restricted'])"
"see Pollock & Zamora, 1984","Formal spelling correction algorithms (see Pollock & Zamora, 1984) were tried but not used as they made very few corrections and had problems with names and slang.","['formal', 'few']","(0, [])","(0, [])"
spelling JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY December 2010,"The feature sets are 1-3-grams; 1-3-grams with emoticons; 1-3-grams with punctuation; 1-3grams with misspellings (i.e., including terms before spelling JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY December 2010 DOI: 10.1002/asi 2551","['emoticons', 'punctuation', 'grams', 'american']","(0, [])","(0, [])"
standard JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY December 2010,"Nevertheless, its accuracy is lower than the SentiStrength standard version, although the difference is not statistically signi cant (accuracy = 59.42%, accuracy 1 = 96.60%, correlation = 0.5822, mean absolute error = 22.65%; only the mean absolute error difference is statistically signi cant from SentiStrength standard JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY December 2010 DOI: 10.1002/asi 2553","['sentistrength', 'standard', 'cant', 'lower', 'american', 'signi', 'mean']","(0, [])","(0, [])"
"von Grumbkow, 2008","Widely recognized innovations include emoticons like :-) that are reasonably effective in conveying emotion (Derks, Bos, & von Grumbkow, 2008; Fullwood & Martino, 2007) and word abbreviations like m8 (mate) and u (you) (Thurlow, 2003).",['effective'],"(1, ['effective'])","(0, [])"
"Aman, 2018","Another example of author-mobility analyses can be found in a bibliometric study to measure knowledge transfer (Aman, 2018).",[],"(0, [])","(0, [])"
BIBLIOMETRIC DATA SOURCE In 2004,"SCOPUS AS A BIBLIOMETRIC DATA SOURCE In 2004, Elsevier launched Scopus as a new search and discovery tool (Schotten, el Aisati, Meester, Steiginga, & Ross, 2017).","['new', 'bibliometric']","(0, [])","(0, [])"
BIS2013,Retrieved from https://www.elsevier.com/ research-intelligence/research-initiatives/ BIS2013 Elsevier.,"['researchintelligenceresearchinitiatives', 'httpswwwelseviercom']","(0, [])","(0, [])"
"Baas & Fennell, 2019","They have been used to evaluate the fate of rejected manuscripts (Bornmann et al., 2009), to investigate potential citation manipulation by reviewers (Baas & Fennell, 2019; Singh Chawla, 2019) and to study the development of multidisciplinarity (Levitt & Thelwall, 2008).",['potential'],"(0, [])","(0, [])"
"Berkvens, 2012","Scopus indexes many different elements of scientific publications, obtained from external publishers, such as publication title, abstract, keywords, author names and linked affiliations, references, and drug terms (Berkvens, 2012).","['abstract', 'such', 'many', 'affiliations', 'external', 'different', 'scientific']","(0, [])","(0, [])"
"Bornmann & Waltman, 2011","Another form of common analysis performed using Scopus data is around network visualization and spatial bibliometrics (Bornmann & De Moya Aneg n, 2019; Bornmann & Waltman, 2011; Leydesdorff & Persson, 2010; Mutz, Bornmann, de Moya Aneg n, & Stefaner, 2014) as well as research building new visualization techniques (Leydesdorff, 2010; Mischo & Schlembach, 2018).","['new', 'common', 'spatial']","(0, [])","(0, [])"
"Bornmann et al., 2009","They have been used to evaluate the fate of rejected manuscripts (Bornmann et al., 2009), to investigate potential citation manipulation by reviewers (Baas & Fennell, 2019; Singh Chawla, 2019) and to study the development of multidisciplinarity (Levitt & Thelwall, 2008).",['potential'],"(0, [])","(0, [])"
"CWTS, 2019","Research groups working with bulk Scopus data include CWTS (CWTS, 2019), SciMago (Scimago Lab, 2019), DZHW (DZHW, 2019), SciTech Strategies (SciTech Strategies, 2018), and others through tailored agreements that have been established between these groups and Elsevier.","['tailored', 'bulk', 'cwts', 'strategies']","(0, [])","(0, [])"
"DZHW, 2019","Research groups working with bulk Scopus data include CWTS (CWTS, 2019), SciMago (Scimago Lab, 2019), DZHW (DZHW, 2019), SciTech Strategies (SciTech Strategies, 2018), and others through tailored agreements that have been established between these groups and Elsevier.","['tailored', 'bulk', 'cwts', 'strategies']","(0, [])","(0, [])"
"Elsevier, 2011","The UK department of Business, Innovation and Skills (BIS) commissioned a report that entailed a comparative study of the UK s international research base, in 2011 (Elsevier, 2011) and 2013 (Elsevier, 2013).","['international', 'comparative']","(0, [])","(0, [])"
"Elsevier, 2013","The UK department of Business, Innovation and Skills (BIS) commissioned a report that entailed a comparative study of the UK s international research base, in 2011 (Elsevier, 2011) and 2013 (Elsevier, 2013).","['international', 'comparative']","(0, [])","(0, [])"
"Elsevier, 2016","In 2016, another refresh of this report was issued by the newly renamed Department for Business, Energy, & Industrial Strategy (BEIS) (Elsevier, 2016).",['industrial'],"(0, [])","(0, [])"
"Elsevier, 2017","This feature strengthens the disambiguation of authors and allows, for instance, gender-based longitudinal analyses that leverage first names (Elsevier, 2017; Lerchenmueller & Sorenson, 2018).","['instance', 'longitudinal', 'first', 'genderbased']","(0, [])","(0, [])"
"Elsevier, 2019","The ultimate decision to (de)select content lies with the external and independent Scopus CSAB (for full details, please see Elsevier, 2019b; Holland, Brimblecombe, Meester, & Steiginga, 2019). Since 2014, application programming interfaces (APIs) have taken over the role of providing access to raw data, allowing free use for scientific purposes, such as the text-and-data-mining resources (Elsevier, 2019c) and Scopus APIs for academic research purposes (Elsevier, 2019a).","['content', 'elsevier', 'such', 'free', 'independent', 'external', 'academic', 'ultimate', 'scientific', 'full', 'textanddatamining']","(1, ['free'])","(0, [])"
"Follett & Strezov, 2015","Scopus data were also used to analyze initiatives in open science, particularly open access (Solomon, Laakso, & Bj rk, 2013), citizen science (Follett & Strezov, 2015) and new tools in the scientific space, such as ResearchGate (Thelwall & Kousha, 2017).","['new', 'scientific', 'such', 'open']","(0, [])","(0, [])"
"Holland, Brimblecombe, Meester, & Steiginga, 2019","The ultimate decision to (de)select content lies with the external and independent Scopus CSAB (for full details, please see Elsevier, 2019b; Holland, Brimblecombe, Meester, & Steiginga, 2019).","['content', 'elsevier', 'independent', 'external', 'ultimate', 'full']","(0, [])","(0, [])"
ISSI 2019,"ISSI 2019, September 2 5, 2019, Rome, Italy https://www.issi2019.org/.",[],"(0, [])","(0, [])"
In 2016,"In 2016, another refresh of this report was issued by the newly renamed Department for Business, Energy, & Industrial Strategy (BEIS) (Elsevier, 2016).",['industrial'],"(0, [])","(0, [])"
In June 2019,"In June 2019, the International Center for the Study of Research was launched, with an advisory board consisting of bibliometricians, aiming to work with the scientometric research community and offering a virtual laboratory where researchers will be able to utilize Scopus data. In June 2019, the ICSR (International Center for the Study of Research, 2019) was launched, with a wide-ranging brief and the support of an advisory board, including experts in research policy, research evaluation, and bibliometrics, to be a Quantitative Science Studies 384 l D o w n o a d e d f r o m h t t p : / / d i r e c t .","['scientometric', 'virtual', 'quantitative', 'advisory', 'scopus', 'able', 'international', 'icsr', 'wideranging']","(0, [])","(0, [])"
"Ioannidis, Baas, Klavans, & Boyack, 2019","In addition, Scopus author profiles have been used to study the recent phenomenon of hyperprolific authorships (Ioannidis, Klavans, & Boyack, 2018) and for an author database of highly cited researchers (Ioannidis, Baas, Klavans, & Boyack, 2019; Van Noorden & Singh Chawla, 2019).","['addition', 'singh', 'noorden', 'hyperprolific', 'recent']","(0, [])","(0, [])"
"Ioannidis, Klavans, & Boyack, 2018","In addition, Scopus author profiles have been used to study the recent phenomenon of hyperprolific authorships (Ioannidis, Klavans, & Boyack, 2018) and for an author database of highly cited researchers (Ioannidis, Baas, Klavans, & Boyack, 2019; Van Noorden & Singh Chawla, 2019).","['addition', 'singh', 'noorden', 'hyperprolific', 'recent']","(0, [])","(0, [])"
July 2019,"Quantitative Science Studies, 1(1), 377 386. https://doi.org/10.1162/ qss_a_00019 DOI: https://doi.org/10.1162/qss_a_00019 Received: 04 July 2019 Accepted: 26 October 2019 Corresponding Author: Jeroen Baas j.baas@elsevier.com Handling Editors: Ludo Waltman and Vincent Larivi re Copyright: 2020 Jeroen Baas, Michiel Schotten, Andrew Plume, Gr goire C t , and Reza Karimi. All above efforts combined have led to approximately 1.8 million Scopus author profiles that have been manually enhanced (Scopus index, July 2019).","['author', 'quantitative', 'plume', 'editors', 'ludo']","(0, [])","(0, [])"
"Klavans & Boyack, 2017","There are also examples of studies using the full Scopus database to build new algorithms: Richard Klavans and Kevin Boyack developed algorithms on top of the database, resulting in Topics of Prominence (Klavans & Boyack, 2017), which are now prominently displayed in Elsevier s SciVal research performance product (which uses Scopus data as one of its data sources).","['algorithms', 'new', 'scival', 'elsevier', 'developed', 'which', 'full']","(0, [])","(0, [])"
"Lee, 2012","For instance, there are studies on mobility, using Scopus unique historic author-affiliation records, such as by Caroline Wagner and Koen Jonkers on international collaboration, mobility, and openness (Wagner & Jonkers, 2017), funding and collaboration (Leydesdorff, Bornmann, & Wagner, 2019), and author (Pina, Barac, Buljan, Grimaldo, & Maru ic, 2019) and institutional (Lee, 2012) collaboration networks.","['institutional', 'such', 'scopus', 'unique', 'international', 'historic']","(0, [])","(0, [])"
"Lerchenmueller & Sorenson, 2018","This feature strengthens the disambiguation of authors and allows, for instance, gender-based longitudinal analyses that leverage first names (Elsevier, 2017; Lerchenmueller & Sorenson, 2018). In addition, Scopus availability of author first names historically, combined with author profiling, enables studies using author gender assignments: for example, The gender gap in early-career transitions in the life sciences (Lerchenmueller & Sorenson, 2018) and Gender differences in research areas, methods and topics: Can people and thing orientations explain the results?","['instance', 'addition', 'earlycareer', 'scopus', 'longitudinal', 'first', 'genderbased']","(0, [])","(0, [])"
"Levitt & Thelwall, 2008","They have been used to evaluate the fate of rejected manuscripts (Bornmann et al., 2009), to investigate potential citation manipulation by reviewers (Baas & Fennell, 2019; Singh Chawla, 2019) and to study the development of multidisciplinarity (Levitt & Thelwall, 2008).",['potential'],"(0, [])","(0, [])"
"Leydesdorff & Persson, 2010","Another form of common analysis performed using Scopus data is around network visualization and spatial bibliometrics (Bornmann & De Moya Aneg n, 2019; Bornmann & Waltman, 2011; Leydesdorff & Persson, 2010; Mutz, Bornmann, de Moya Aneg n, & Stefaner, 2014) as well as research building new visualization techniques (Leydesdorff, 2010; Mischo & Schlembach, 2018).","['new', 'common', 'spatial']","(0, [])","(0, [])"
"Leydesdorff, 2010","Another form of common analysis performed using Scopus data is around network visualization and spatial bibliometrics (Bornmann & De Moya Aneg n, 2019; Bornmann & Waltman, 2011; Leydesdorff & Persson, 2010; Mutz, Bornmann, de Moya Aneg n, & Stefaner, 2014) as well as research building new visualization techniques (Leydesdorff, 2010; Mischo & Schlembach, 2018).","['new', 'common', 'spatial']","(0, [])","(0, [])"
"Leydesdorff, Bornmann, & Wagner, 2019","For instance, there are studies on mobility, using Scopus unique historic author-affiliation records, such as by Caroline Wagner and Koen Jonkers on international collaboration, mobility, and openness (Wagner & Jonkers, 2017), funding and collaboration (Leydesdorff, Bornmann, & Wagner, 2019), and author (Pina, Barac, Buljan, Grimaldo, & Maru ic, 2019) and institutional (Lee, 2012) collaboration networks.","['institutional', 'such', 'scopus', 'unique', 'international', 'historic']","(0, [])","(0, [])"
"Maflahi & Thelwall, 2016","Scopus as a curated, high-quality bibliometric data source on indicators (Thelwall, 2019; Thelwall & Fairclough, 2015), on correlation between citations and Mendeley readership (Maflahi & Thelwall, 2016; Thelwall & Wilson, 2016), on journal usage (Schloegl & Gorraiz, 2010), and studies revisiting bibliometric laws (Thelwall & Wilson, 2014).","['journal', 'curated', 'bibliometric']","(0, [])","(0, [])"
"Mischo & Schlembach, 2018","Another form of common analysis performed using Scopus data is around network visualization and spatial bibliometrics (Bornmann & De Moya Aneg n, 2019; Bornmann & Waltman, 2011; Leydesdorff & Persson, 2010; Mutz, Bornmann, de Moya Aneg n, & Stefaner, 2014) as well as research building new visualization techniques (Leydesdorff, 2010; Mischo & Schlembach, 2018).","['new', 'common', 'spatial']","(0, [])","(0, [])"
"National Science Board, 2016","Scopus as a curated, high-quality bibliometric data source Engineering Indicators (SEI), for the 2016 (National Science Board, 2016) and 2018 (National Science Board, 2018) editions, and will be used in future editions of the SEI reports up to 2022.","['curated', 'future', 'national']","(0, [])","(0, [])"
"National Science Board, 2018","Scopus as a curated, high-quality bibliometric data source Engineering Indicators (SEI), for the 2016 (National Science Board, 2016) and 2018 (National Science Board, 2018) editions, and will be used in future editions of the SEI reports up to 2022.","['curated', 'future', 'national']","(0, [])","(0, [])"
October 2019,"Quantitative Science Studies, 1(1), 377 386. https://doi.org/10.1162/ qss_a_00019 DOI: https://doi.org/10.1162/qss_a_00019 Received: 04 July 2019 Accepted: 26 October 2019 Corresponding Author: Jeroen Baas j.baas@elsevier.com Handling Editors: Ludo Waltman and Vincent Larivi re Copyright: 2020 Jeroen Baas, Michiel Schotten, Andrew Plume, Gr goire C t , and Reza Karimi.","['author', 'quantitative', 'plume', 'editors', 'ludo']","(0, [])","(0, [])"
"Preziosi et al., 2019","The mobility analysis using Scopus author profiles also informs the research policy of governments, such as through the European Commission s Joint Research Center (JRC) report on the rise of China as an industrial and innovation powerhouse (Preziosi et al., 2019).","['such', 'scopus', 'european', 'industrial', 'joint']","(0, [])","(0, [])"
REF 2014,"The first edition of the Research Excellence Framework (REF 2014) national assessment in the UK also used Scopus data. The REF 2014 was held by the Higher Education Funding Council for England (HEFCE) and the funding bodies for Scotland, Wales, and Northern Ireland. Prior to the announcement of the REF 2014 assessment results by HEFCE, the REF Results Analysis Tool provided by Elsevier allowed the UK s HEIs to compare and evaluate their own REF performance across several benchmarks and metrics.","['higher', 'northern', 'national', 'own', 'several', 'first', 'scotland']","(0, [])","(0, [])"
"Schloegl & Gorraiz, 2010","Scopus as a curated, high-quality bibliometric data source on indicators (Thelwall, 2019; Thelwall & Fairclough, 2015), on correlation between citations and Mendeley readership (Maflahi & Thelwall, 2016; Thelwall & Wilson, 2016), on journal usage (Schloegl & Gorraiz, 2010), and studies revisiting bibliometric laws (Thelwall & Wilson, 2014).","['journal', 'curated', 'bibliometric']","(0, [])","(0, [])"
"SciTech Strategies, 2018","Research groups working with bulk Scopus data include CWTS (CWTS, 2019), SciMago (Scimago Lab, 2019), DZHW (DZHW, 2019), SciTech Strategies (SciTech Strategies, 2018), and others through tailored agreements that have been established between these groups and Elsevier.","['tailored', 'bulk', 'cwts', 'strategies']","(0, [])","(0, [])"
"Science-Metrix, 2014","Scopus data are also the source of bibliometric indicators for the European Research Area in the context of the 2010 2014 study Analysis and Regular Update of Bibliometric Indicators for the European Commission (Science-Metrix, 2014) and have recently been selected for the continuation and improvement of this study, now called Provision and Analysis of Key Indicators in Research and Innovation, for the three coming years.","['key', 'sciencemetrix', 'regular', 'european', 'bibliometric']","(0, [])","(0, [])"
"Scimago Lab, 2019","Research groups working with bulk Scopus data include CWTS (CWTS, 2019), SciMago (Scimago Lab, 2019), DZHW (DZHW, 2019), SciTech Strategies (SciTech Strategies, 2018), and others through tailored agreements that have been established between these groups and Elsevier.","['tailored', 'bulk', 'cwts', 'strategies']","(0, [])","(0, [])"
Since 2014,"Since 2014, application programming interfaces (APIs) have taken over the role of providing access to raw data, allowing free use for scientific purposes, such as the text-and-data-mining resources (Elsevier, 2019c) and Scopus APIs for academic research purposes (Elsevier, 2019a).","['such', 'free', 'academic', 'scientific', 'textanddatamining']","(1, ['free'])","(0, [])"
"Singh Chawla, 2019","In addition, Scopus author profiles have been used to study the recent phenomenon of hyperprolific authorships (Ioannidis, Klavans, & Boyack, 2018) and for an author database of highly cited researchers (Ioannidis, Baas, Klavans, & Boyack, 2019; Van Noorden & Singh Chawla, 2019). They have been used to evaluate the fate of rejected manuscripts (Bornmann et al., 2009), to investigate potential citation manipulation by reviewers (Baas & Fennell, 2019; Singh Chawla, 2019) and to study the development of multidisciplinarity (Levitt & Thelwall, 2008).","['addition', 'singh', 'noorden', 'potential', 'hyperprolific', 'recent']","(0, [])","(0, [])"
"Stefaner, 2014","Another form of common analysis performed using Scopus data is around network visualization and spatial bibliometrics (Bornmann & De Moya Aneg n, 2019; Bornmann & Waltman, 2011; Leydesdorff & Persson, 2010; Mutz, Bornmann, de Moya Aneg n, & Stefaner, 2014) as well as research building new visualization techniques (Leydesdorff, 2010; Mischo & Schlembach, 2018).","['new', 'common', 'spatial']","(0, [])","(0, [])"
"The Lisbon Council, CWTS, & Esade, 2018","At present, Scopus data are used for bibliometric analysis to inform the EU Open Science Monitor (The Lisbon Council, CWTS, & Esade, 2018).","['present', 'bibliometric', 'open']","(0, [])","(0, [])"
The REF 2014,"The REF 2014 was held by the Higher Education Funding Council for England (HEFCE) and the funding bodies for Scotland, Wales, and Northern Ireland.","['higher', 'northern', 'scotland']","(0, [])","(0, [])"
"Thelwall & Fairclough, 2015","Scopus as a curated, high-quality bibliometric data source on indicators (Thelwall, 2019; Thelwall & Fairclough, 2015), on correlation between citations and Mendeley readership (Maflahi & Thelwall, 2016; Thelwall & Wilson, 2016), on journal usage (Schloegl & Gorraiz, 2010), and studies revisiting bibliometric laws (Thelwall & Wilson, 2014).","['journal', 'curated', 'bibliometric']","(0, [])","(0, [])"
"Thelwall & Kousha, 2017","Scopus data were also used to analyze initiatives in open science, particularly open access (Solomon, Laakso, & Bj rk, 2013), citizen science (Follett & Strezov, 2015) and new tools in the scientific space, such as ResearchGate (Thelwall & Kousha, 2017).","['new', 'scientific', 'such', 'open']","(0, [])","(0, [])"
"Thelwall & Wilson, 2014","Scopus as a curated, high-quality bibliometric data source on indicators (Thelwall, 2019; Thelwall & Fairclough, 2015), on correlation between citations and Mendeley readership (Maflahi & Thelwall, 2016; Thelwall & Wilson, 2016), on journal usage (Schloegl & Gorraiz, 2010), and studies revisiting bibliometric laws (Thelwall & Wilson, 2014).","['journal', 'curated', 'bibliometric']","(0, [])","(0, [])"
"Thelwall & Wilson, 2016","Scopus as a curated, high-quality bibliometric data source on indicators (Thelwall, 2019; Thelwall & Fairclough, 2015), on correlation between citations and Mendeley readership (Maflahi & Thelwall, 2016; Thelwall & Wilson, 2016), on journal usage (Schloegl & Gorraiz, 2010), and studies revisiting bibliometric laws (Thelwall & Wilson, 2014).","['journal', 'curated', 'bibliometric']","(0, [])","(0, [])"
"Thelwall, 2019","Scopus as a curated, high-quality bibliometric data source on indicators (Thelwall, 2019; Thelwall & Fairclough, 2015), on correlation between citations and Mendeley readership (Maflahi & Thelwall, 2016; Thelwall & Wilson, 2016), on journal usage (Schloegl & Gorraiz, 2010), and studies revisiting bibliometric laws (Thelwall & Wilson, 2014).","['journal', 'curated', 'bibliometric']","(0, [])","(0, [])"
"Thelwall, Bailey, Tobin, & Bradshaw, 2019","(Thelwall, Bailey, Tobin, & Bradshaw, 2019).",['thelwall'],"(0, [])","(0, [])"
Until 2014,"Until 2014, Elsevier supported bibliometricians with data using the Elsevier Bibliometric Research Program (EBRP).","['bibliometric', 'elsevier']","(0, [])","(0, [])"
"Van Noorden & Singh Chawla, 2019","In addition, Scopus author profiles have been used to study the recent phenomenon of hyperprolific authorships (Ioannidis, Klavans, & Boyack, 2018) and for an author database of highly cited researchers (Ioannidis, Baas, Klavans, & Boyack, 2019; Van Noorden & Singh Chawla, 2019).","['addition', 'singh', 'noorden', 'hyperprolific', 'recent']","(0, [])","(0, [])"
"Wagner & Jonkers, 2017","For instance, there are studies on mobility, using Scopus unique historic author-affiliation records, such as by Caroline Wagner and Koen Jonkers on international collaboration, mobility, and openness (Wagner & Jonkers, 2017), funding and collaboration (Leydesdorff, Bornmann, & Wagner, 2019), and author (Pina, Barac, Buljan, Grimaldo, & Maru ic, 2019) and institutional (Lee, 2012) collaboration networks.","['institutional', 'such', 'scopus', 'unique', 'international', 'historic']","(0, [])","(0, [])"
and 2013,"The UK department of Business, Innovation and Skills (BIS) commissioned a report that entailed a comparative study of the UK s international research base, in 2011 (Elsevier, 2011) and 2013 (Elsevier, 2013).","['international', 'comparative']","(0, [])","(0, [])"
and 2015,"The first national assessment supported by Scopus was the Excellence in Research for Australia (ERA) of the Australian Research Council (ARC) in 2010, later repeated in 2012 and 2015.","['first', 'australian', 'australia', 'national']","(0, [])","(0, [])"
and 2018,"About 9.9% of the serial titles (i.e., journals and book series) in Scopus are published by Elsevier (this amounts to an article share in Scopus of 17.4% between 2012 and 2018); the other 90.1% of serial titles (and 82.6% of articles, respectively) are produced by an extensive list of global publishers (Figure 1a). More examples of national assessments where Scopus data were used include the 2013 2014 assessment in Portugal held by the FCT ( Funda o para a Ci ncia e a Technologia ), the ASN ( Abilitazione Scientifica Nazionale ) national accreditation rounds (2012 2013, 2016 2018, and 2018 2020), VQR ( Valutazione della Qualit della Ricerca ) national assessment in Italy (2012 2013, 2016 2017), and National University Corporation Evaluation (NUCE) national assessment in Japan held in 2016 2017 and to be held in 2020 by the National Institution for Academic Degrees and Quality Enhancement of Higher Education (NIAD-QE). Scopus as a curated, high-quality bibliometric data source Engineering Indicators (SEI), for the 2016 (National Science Board, 2016) and 2018 (National Science Board, 2018) editions, and will be used in future editions of the SEI reports up to 2022.","['more', 'elsevier', 'niadqe', 'other', 'extensive', 'portugal', 'italy', 'valutazione', 'future', 'global', 'higher', 'national', 'curated', 'academic', 'funda', 'serial']","(0, [])","(0, [])"
base 2011,International comparative performance of the UK research base 2011.,"['comparative', 'international']","(0, [])","(0, [])"
base 2013,International comparative performance of the UK research base 2013.,"['comparative', 'international']","(0, [])","(0, [])"
base 2016,International comparative performance of the UK research base 2016.,"['comparative', 'international']","(0, [])","(0, [])"
beis2016,Retrieved from https://www.elsevier.com/ research-intelligence/research-initiatives/ beis2016 Elsevier.,"['researchintelligenceresearchinitiatives', 'httpswwwelseviercom']","(0, [])","(0, [])"
between 1995,"An important aspect of the Scopus database is the high coverage and availability of first names, even for relatively old records: from 25% of authorships in 1970 1974 and 52% between 1995 1999 to 82% of authorships in 2015 2019 (Figure 1).","['important', 'old', 'first', 'high']","(1, ['important'])","(0, [])"
between 2012,"About 9.9% of the serial titles (i.e., journals and book series) in Scopus are published by Elsevier (this amounts to an article share in Scopus of 17.4% between 2012 and 2018); the other 90.1% of serial titles (and 82.6% of articles, respectively) are produced by an extensive list of global publishers (Figure 1a).","['elsevier', 'other', 'extensive', 'global', 'serial']","(0, [])","(0, [])"
"el Aisati, Meester, Steiginga, & Ross, 2017","SCOPUS AS A BIBLIOMETRIC DATA SOURCE In 2004, Elsevier launched Scopus as a new search and discovery tool (Schotten, el Aisati, Meester, Steiginga, & Ross, 2017).","['new', 'bibliometric']","(0, [])","(0, [])"
"ic, 2019","For instance, there are studies on mobility, using Scopus unique historic author-affiliation records, such as by Caroline Wagner and Koen Jonkers on international collaboration, mobility, and openness (Wagner & Jonkers, 2017), funding and collaboration (Leydesdorff, Bornmann, & Wagner, 2019), and author (Pina, Barac, Buljan, Grimaldo, & Maru ic, 2019) and institutional (Lee, 2012) collaboration networks.","['institutional', 'such', 'scopus', 'unique', 'international', 'historic']","(0, [])","(0, [])"
in 1970,"An important aspect of the Scopus database is the high coverage and availability of first names, even for relatively old records: from 25% of authorships in 1970 1974 and 52% between 1995 1999 to 82% of authorships in 2015 2019 (Figure 1).","['important', 'old', 'first', 'high']","(1, ['important'])","(0, [])"
in 2004,"SUPPORT FOR LARGE-SCALE ANALYSES Since its official launch in 2004, Scopus has been used globally in many large-scale analyses.","['largescale', 'official', 'many']","(0, [])","(0, [])"
in 2010,"The first national assessment supported by Scopus was the Excellence in Research for Australia (ERA) of the Australian Research Council (ARC) in 2010, later repeated in 2012 and 2015.","['first', 'australian', 'australia', 'national']","(0, [])","(0, [])"
in 2011,"The UK department of Business, Innovation and Skills (BIS) commissioned a report that entailed a comparative study of the UK s international research base, in 2011 (Elsevier, 2011) and 2013 (Elsevier, 2013).","['international', 'comparative']","(0, [])","(0, [])"
in 2012,"ORCID is managed by a non-profit organization with the same name established in 2012. The first national assessment supported by Scopus was the Excellence in Research for Australia (ERA) of the Australian Research Council (ARC) in 2010, later repeated in 2012 and 2015.","['nonprofit', 'national', 'same', 'australia', 'australian', 'first']","(0, [])","(0, [])"
in 2015,"An important aspect of the Scopus database is the high coverage and availability of first names, even for relatively old records: from 25% of authorships in 1970 1974 and 52% between 1995 1999 to 82% of authorships in 2015 2019 (Figure 1).","['important', 'old', 'first', 'high']","(1, ['important'])","(0, [])"
in 2016,"More examples of national assessments where Scopus data were used include the 2013 2014 assessment in Portugal held by the FCT ( Funda o para a Ci ncia e a Technologia ), the ASN ( Abilitazione Scientifica Nazionale ) national accreditation rounds (2012 2013, 2016 2018, and 2018 2020), VQR ( Valutazione della Qualit della Ricerca ) national assessment in Italy (2012 2013, 2016 2017), and National University Corporation Evaluation (NUCE) national assessment in Japan held in 2016 2017 and to be held in 2020 by the National Institution for Academic Degrees and Quality Enhancement of Higher Education (NIAD-QE).","['italy', 'portugal', 'valutazione', 'higher', 'national', 'academic', 'funda']","(0, [])","(0, [])"
in 2020,"More examples of national assessments where Scopus data were used include the 2013 2014 assessment in Portugal held by the FCT ( Funda o para a Ci ncia e a Technologia ), the ASN ( Abilitazione Scientifica Nazionale ) national accreditation rounds (2012 2013, 2016 2018, and 2018 2020), VQR ( Valutazione della Qualit della Ricerca ) national assessment in Italy (2012 2013, 2016 2017), and National University Corporation Evaluation (NUCE) national assessment in Japan held in 2016 2017 and to be held in 2020 by the National Institution for Academic Degrees and Quality Enhancement of Higher Education (NIAD-QE).","['italy', 'portugal', 'valutazione', 'higher', 'national', 'academic', 'funda']","(0, [])","(0, [])"
in December 2018,"For instance, under this program, digital object identifier (DOI) completion rates went up from 87.8% at the start of the program to 99.8% in December 2018.","['doi', 'program', 'digital']","(0, [])","(0, [])"
"index, July 2019","All above efforts combined have led to approximately 1.8 million Scopus author profiles that have been manually enhanced (Scopus index, July 2019).",[],"(0, [])","(0, [])"
indicators 2016,Science and engineering indicators 2016.,[],"(0, [])","(0, [])"
indicators 2018,Science and engineering indicators 2018.,[],"(0, [])","(0, [])"
international-comparativeperformance-of-the-uk-research-base-2011,Retrieved from https://www.elsevier.com/ research-intelligence/resource-library/international-comparativeperformance-of-the-uk-research-base-2011 Elsevier.,"['httpswwwelseviercom', 'researchintelligenceresourcelibraryinternationalcomparativeperformanceoftheukresearchbase']","(0, [])","(0, [])"
issi2019,"ISSI 2019, September 2 5, 2019, Rome, Italy https://www.issi2019.org/.",[],"(0, [])","(0, [])"
nsb2016,Retrieved from https:// www.nsf.gov/statistics/2016/nsb20161/ National Science Board.,"['wwwnsfgovstatisticsnsb', 'national']","(0, [])","(0, [])"
nsb2018,"Retrieved from https:// www.nsf.gov/statistics/2018/nsb20181/ Pina, D. G., Barac, L., Buljan, I., Grimaldo, F., & Maru ic, A.",[],"(0, [])","(0, [])"
"of Research, 2019","At the moment of writing, this platform is not yet publicly available and will be announced through the ICSR website (International Center for the Study of Research, 2019). In June 2019, the ICSR (International Center for the Study of Research, 2019) was launched, with a wide-ranging brief and the support of an advisory board, including experts in research policy, research evaluation, and bibliometrics, to be a Quantitative Science Studies 384 l D o w n o a d e d f r o m h t t p : / / d i r e c t .","['website', 'quantitative', 'advisory', 'international', 'icsr', 'available', 'wideranging']","(1, ['available'])","(0, [])"
"rk, 2013","Scopus data were also used to analyze initiatives in open science, particularly open access (Solomon, Laakso, & Bj rk, 2013), citizen science (Follett & Strezov, 2015) and new tools in the scientific space, such as ResearchGate (Thelwall & Kousha, 2017).","['new', 'scientific', 'such', 'open']","(0, [])","(0, [])"
"see Elsevier, 2019","The ultimate decision to (de)select content lies with the external and independent Scopus CSAB (for full details, please see Elsevier, 2019b; Holland, Brimblecombe, Meester, & Steiginga, 2019).","['content', 'elsevier', 'independent', 'external', 'ultimate', 'full']","(0, [])","(0, [])"
since 2014,"These include the World University Rankings and its various derived Regional, Global Subject, Young University, and World Reputation Rankings, as well as the Wall Street Journal/THE College Rankings, which are all issued by Times Higher Education (THE, since 2014); and the World University Rankings and its various derived rankings issued by Quacquarelli Symonds (QS, since 2015); as well as various other regional and subjectspecific rankings, such as the Best Chinese Universities Ranking issued by ShanghaiRanking Consultancy (since 2015), Perspektywy in Poland, Maclean s in Canada, National Institutional Ranking Framework (NIRF) in India, the Financial Times Global MBA Ranking, and the Frankfurter Allgemeine Zeitung Economists Ranking in Germany.","['financial', 'regional', 'institutional', 'such', 'other', 'various', 'poland', 'global', 'higher', 'young', 'chinese', 'maclean', 'best', 'canada', 'subjectspecific', 'quacquarelli', 'national']","(1, ['best'])","(0, [])"
since 2015,"These include the World University Rankings and its various derived Regional, Global Subject, Young University, and World Reputation Rankings, as well as the Wall Street Journal/THE College Rankings, which are all issued by Times Higher Education (THE, since 2014); and the World University Rankings and its various derived rankings issued by Quacquarelli Symonds (QS, since 2015); as well as various other regional and subjectspecific rankings, such as the Best Chinese Universities Ranking issued by ShanghaiRanking Consultancy (since 2015), Perspektywy in Poland, Maclean s in Canada, National Institutional Ranking Framework (NIRF) in India, the Financial Times Global MBA Ranking, and the Frankfurter Allgemeine Zeitung Economists Ranking in Germany.","['financial', 'regional', 'institutional', 'such', 'other', 'various', 'poland', 'global', 'higher', 'young', 'chinese', 'maclean', 'best', 'canada', 'subjectspecific', 'quacquarelli', 'national']","(1, ['best'])","(0, [])"
the 2010,"Scopus data are also the source of bibliometric indicators for the European Research Area in the context of the 2010 2014 study Analysis and Regular Update of Bibliometric Indicators for the European Commission (Science-Metrix, 2014) and have recently been selected for the continuation and improvement of this study, now called Provision and Analysis of Key Indicators in Research and Innovation, for the three coming years.","['key', 'sciencemetrix', 'regular', 'european', 'bibliometric']","(0, [])","(0, [])"
the 2013,"More examples of national assessments where Scopus data were used include the 2013 2014 assessment in Portugal held by the FCT ( Funda o para a Ci ncia e a Technologia ), the ASN ( Abilitazione Scientifica Nazionale ) national accreditation rounds (2012 2013, 2016 2018, and 2018 2020), VQR ( Valutazione della Qualit della Ricerca ) national assessment in Italy (2012 2013, 2016 2017), and National University Corporation Evaluation (NUCE) national assessment in Japan held in 2016 2017 and to be held in 2020 by the National Institution for Academic Degrees and Quality Enhancement of Higher Education (NIAD-QE).","['italy', 'portugal', 'valutazione', 'higher', 'national', 'academic', 'funda']","(0, [])","(0, [])"
the 2016,"Scopus as a curated, high-quality bibliometric data source Engineering Indicators (SEI), for the 2016 (National Science Board, 2016) and 2018 (National Science Board, 2018) editions, and will be used in future editions of the SEI reports up to 2022.","['curated', 'future', 'national']","(0, [])","(0, [])"
the REF 2014,"Prior to the announcement of the REF 2014 assessment results by HEFCE, the REF Results Analysis Tool provided by Elsevier allowed the UK s HEIs to compare and evaluate their own REF performance across several benchmarks and metrics.","['own', 'several']","(0, [])","(0, [])"
to 2022,"Scopus as a curated, high-quality bibliometric data source Engineering Indicators (SEI), for the 2016 (National Science Board, 2016) and 2018 (National Science Board, 2018) editions, and will be used in future editions of the SEI reports up to 2022.","['curated', 'future', 'national']","(0, [])","(0, [])"
